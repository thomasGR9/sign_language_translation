{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"test_Im.png\"\n",
    "grimace_2_path = \"grimace_2.png\"\n",
    "grimace_3_path = \"grimace_3.png\"\n",
    "not_a_face_path = \"not_a_face.png\"\n",
    "without_face_path = \"without_face.png\"\n",
    "without_right_hand_path = \"without_right_hand.png\"\n",
    "without_left_hand_path = \"without_left_hand.png\"\n",
    "hand_model_path = \"hand_landmarker.task\"\n",
    "face_model_path = \"face_landmarker.task\"\n",
    "video_path = \"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1, 2, 3, 4, 5, 9, 10, 11, 12, 21, 22,23, 24, 25, 26, 27, 33, 39, 42, 43, 44, 45, 46, 47, 50, 51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0=all, 1=INFO, 2=WARNING, 3=ERROR\n",
    "logging.getLogger(\"mediapipe\").setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logging\n",
    "os.environ['GLOG_minloglevel'] = '3'      # Suppress Google logging (used by MediaPipe)\n",
    "os.environ['MEDIAPIPE_DISABLE_GPU'] = '1'  # Optional: Disable GPU logging messages\n",
    "logging.getLogger(\"mediapipe\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import time\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def detect(image_path, hand_model_path, face_model_path, min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, min_face_detection_confidence=0.5, min_face_presence_confidence=0.5, num_hands=2, dominand_hand='Right', visualize=False, output_face_blendshapes=True, adaptive_threshold=True, max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Detects hands and face in an image, extracts hand landmark coordinates and face blendshapes.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        min_hand_detection_confidence (float): Confidence threshold for hand detection (0.0-1.0)\n",
    "        min_hand_presence_confidence (float): Confidence threshold for hand presence (0.0-1.0)\n",
    "        num_hands (int): Maximum number of hands to detect\n",
    "        dominand_hand (str): Dominant hand preference ('Left' or 'Right')\n",
    "        visualize (bool): Whether to visualize the results\n",
    "        output_face_blendshapes (bool): Whether to detect and extract face blendshapes\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (dom_landmarks, non_dom_landmarks, wrists, confidence_scores, detection_status, \n",
    "                blendshape_scores, face_landmark_5, face_detected)\n",
    "               - dom_landmarks: NumPy array of shape [20, 3] with coordinates of dominant hand landmarks\n",
    "               - non_dom_landmarks: NumPy array of shape [20, 3] with coordinates of non-dominant hand landmarks\n",
    "               - wrists: NumPy array of shape [2, 2] with coordinates of both wrists [x, y]\n",
    "               - confidence_scores: NumPy array of shape [2] with confidence scores [dominant_hand, non_dominant_hand]\n",
    "               - detection_status: NumPy array of shape [2] with binary detection status [dominant_hand, non_dominant_hand]\n",
    "               - blendshape_scores: NumPy array of shape [26] with selected face blendshape scores\n",
    "               - face_landmark_5: NumPy array of shape [2] with coordinates of the 5th face landmark [x, y]\n",
    "               - face_detected: Binary value (1 if face detected, 0 if not)\n",
    "    \"\"\"\n",
    "    # Initialize output arrays for face detection\n",
    "    blendshape_scores = np.zeros(52)\n",
    "    nose_landmark = np.zeros(2)\n",
    "    left_eye_landmark = np.zeros(2)\n",
    "    right_eye_landmark = np.zeros(2)\n",
    "    face_detected = 0\n",
    "    \n",
    "    # PART 1: HAND LANDMARK DETECTION\n",
    "    # 1.1: Configure the hand landmarker\n",
    "    hand_base_options = python.BaseOptions(\n",
    "        model_asset_path=hand_model_path\n",
    "    )\n",
    "\n",
    "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "    # Configure detection options\n",
    "    hand_options = vision.HandLandmarkerOptions(\n",
    "        base_options=hand_base_options,\n",
    "        num_hands=num_hands,                             \n",
    "        min_hand_detection_confidence=min_hand_detection_confidence,       \n",
    "        min_hand_presence_confidence=min_hand_presence_confidence,        \n",
    "        min_tracking_confidence=0.5,             \n",
    "        running_mode=VisionRunningMode.IMAGE\n",
    "    )\n",
    "\n",
    "    # Create the hand detector\n",
    "    hand_detector = vision.HandLandmarker.create_from_options(hand_options)\n",
    "\n",
    "    # 1.2: Load the input image\n",
    "    image = mp.Image.create_from_file(image_path)\n",
    "\n",
    "    # 1.3: Detect hand landmarks\n",
    "    hand_detection_result = hand_detector.detect(image)\n",
    "    \n",
    "    # Initialize hand output arrays with zeros\n",
    "    dom_landmarks = np.zeros((20, 3))       # 20 landmarks (excluding wrist), [x,y,z]\n",
    "    non_dom_landmarks = np.zeros((20, 3))   # 20 landmarks (excluding wrist), [x,y,z]\n",
    "    wrists = np.zeros((2, 2))               # 2 wrists, [x,y]\n",
    "    confidence_scores = np.zeros(2)         # Confidence scores for [dominant, non-dominant]\n",
    "    interpolation_scores = np.zeros(2) #Interpolation scores for [dominant, non-dominant]. Used later.\n",
    "    detection_status = np.zeros(2, dtype=np.int32)  # Binary detection status [dominant, non-dominant]\n",
    "    nose_to_wrist_dist = np.zeros((2, 2))\n",
    "    \n",
    "    # 1.4: Process hand landmarks if hands are detected\n",
    "    if hand_detection_result.hand_landmarks and hand_detection_result.handedness:\n",
    "        dom_hand_found = False\n",
    "        non_dom_hand_found = False\n",
    "        \n",
    "        # First, find the dominant and non-dominant hands in detection results\n",
    "        for idx, handedness in enumerate(hand_detection_result.handedness):\n",
    "            hand_type = handedness[0].category_name  # 'Left' or 'Right'\n",
    "            hand_score = handedness[0].score  # Confidence score for the handedness classification\n",
    "            \n",
    "            if hand_type == dominand_hand:\n",
    "                # This is the dominant hand\n",
    "                dom_hand_found = True\n",
    "                detection_status[0] = 1  # Set detection status to 1 (detected)\n",
    "                confidence_scores[0] = hand_score  # Store confidence score\n",
    "                interpolation_scores[0] = 1\n",
    "                \n",
    "                # Store dominant hand wrist coordinates [x,y]\n",
    "                dom_hand_landmarks = hand_detection_result.hand_landmarks[idx]\n",
    "                wrists[0, 0] = dom_hand_landmarks[0].x\n",
    "                wrists[0, 1] = dom_hand_landmarks[0].y\n",
    "                \n",
    "                # Store all other dominant hand landmarks (excluding wrist)\n",
    "                for i in range(1, 21):  # Landmarks 1-20 (skipping wrist which is index 0)\n",
    "                    dom_landmarks[i-1, 0] = dom_hand_landmarks[i].x\n",
    "                    dom_landmarks[i-1, 1] = dom_hand_landmarks[i].y\n",
    "                    dom_landmarks[i-1, 2] = dom_hand_landmarks[i].z\n",
    "                    \n",
    "            elif hand_type != dominand_hand:\n",
    "                # This is the non-dominant hand\n",
    "                non_dom_hand_found = True\n",
    "                detection_status[1] = 1  # Set detection status to 1 (detected)\n",
    "                confidence_scores[1] = hand_score  # Store confidence score\n",
    "                interpolation_scores[1] = 1\n",
    "                \n",
    "                # Store non-dominant hand wrist coordinates [x,y]\n",
    "                non_dom_hand_landmarks = hand_detection_result.hand_landmarks[idx]\n",
    "                wrists[1, 0] = non_dom_hand_landmarks[0].x\n",
    "                wrists[1, 1] = non_dom_hand_landmarks[0].y\n",
    "                \n",
    "                # Store all other non-dominant hand landmarks (excluding wrist)\n",
    "                for i in range(1, 21):  # Landmarks 1-20 (skipping wrist)\n",
    "                    non_dom_landmarks[i-1, 0] = non_dom_hand_landmarks[i].x\n",
    "                    non_dom_landmarks[i-1, 1] = non_dom_hand_landmarks[i].y\n",
    "                    non_dom_landmarks[i-1, 2] = non_dom_hand_landmarks[i].z\n",
    "                    \n",
    "        # Log information about which hands were found\n",
    "        print(f\"Dominant hand ({dominand_hand}) detected: {dom_hand_found}\")\n",
    "        print(f\"Non-dominant hand detected: {non_dom_hand_found}\")\n",
    "    \n",
    "\n",
    "   # PART 2: FACE LANDMARK DETECTION (If requested)\n",
    "    if output_face_blendshapes:\n",
    "        try:\n",
    "            # 2.1: Configure the face landmarker\n",
    "            face_base_options = python.BaseOptions(\n",
    "                model_asset_path=face_model_path\n",
    "            )\n",
    "            \n",
    "            # Configure face detection options\n",
    "            face_options = vision.FaceLandmarkerOptions(\n",
    "                base_options=face_base_options,\n",
    "                min_face_detection_confidence=min_face_detection_confidence,\n",
    "                min_face_presence_confidence=min_face_presence_confidence,\n",
    "                output_face_blendshapes=True,\n",
    "                num_faces=1,\n",
    "                running_mode=VisionRunningMode.IMAGE\n",
    "            )\n",
    "            \n",
    "            # Create the face detector\n",
    "            face_detector = vision.FaceLandmarker.create_from_options(face_options)\n",
    "            \n",
    "            # 2.2: Detect face landmarks (reuse the same image)\n",
    "            face_detection_result = face_detector.detect(image)\n",
    "            \n",
    "            # 2.3: Process face blendshapes if face is detected\n",
    "            if (face_detection_result.face_blendshapes and len(face_detection_result.face_blendshapes) > 0 and\n",
    "                face_detection_result.face_landmarks and len(face_detection_result.face_landmarks) > 0):\n",
    "                \n",
    "                # Set face detected flag to 1\n",
    "                face_detected = 1\n",
    "                \n",
    "                # Get all blendshapes from the first face\n",
    "                all_blendshapes = face_detection_result.face_blendshapes[0]\n",
    "                \n",
    "                # Initialize blendshape_scores with the correct size to hold all blendshapes\n",
    "                # Assuming MediaPipe returns all 52 blendshapes\n",
    "                blendshape_scores = np.zeros(len(all_blendshapes))\n",
    "                \n",
    "                # Fill the blendshape_scores array with ALL scores\n",
    "                for i in range(len(all_blendshapes)):\n",
    "                    blendshape_scores[i] = all_blendshapes[i].score\n",
    "                \n",
    "                # Get nose coordinates\n",
    "                nose = face_detection_result.face_landmarks[0][4]\n",
    "                nose_landmark[0] = nose.x\n",
    "                nose_landmark[1] = nose.y\n",
    "    \n",
    "                # Get eye coordinates\n",
    "                left_eye = face_detection_result.face_landmarks[0][473]\n",
    "                left_eye_landmark[0] = left_eye.x\n",
    "                left_eye_landmark[1] = left_eye.y\n",
    "    \n",
    "                right_eye = face_detection_result.face_landmarks[0][468]\n",
    "                right_eye_landmark[0] = right_eye.x\n",
    "                right_eye_landmark[1] = right_eye.y\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during face detection: {e}\")\n",
    "            # Keep default zero values for face outputs if detection fails\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PART 3: VISUALIZATION\n",
    "    if visualize:\n",
    "        # Load the image with OpenCV for visualization\n",
    "        img_cv = cv2.imread(image_path)\n",
    "        img_height, img_width, _ = img_cv.shape\n",
    "\n",
    "        # 3.1: Draw hand landmarks if hands are detected\n",
    "        if hand_detection_result.hand_landmarks:\n",
    "            print(f\"Visualizing {len(hand_detection_result.hand_landmarks)} hands\")\n",
    "            \n",
    "            # Define connections between landmarks for hand skeleton\n",
    "            connections = [\n",
    "                # Thumb connections\n",
    "                (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "                # Index finger connections\n",
    "                (0, 5), (5, 6), (6, 7), (7, 8),\n",
    "                # Middle finger connections\n",
    "                (0, 9), (9, 10), (10, 11), (11, 12),\n",
    "                # Ring finger connections\n",
    "                (0, 13), (13, 14), (14, 15), (15, 16),\n",
    "                # Pinky finger connections\n",
    "                (0, 17), (17, 18), (18, 19), (19, 20),\n",
    "                # Palm connections\n",
    "                (0, 5), (5, 9), (9, 13), (13, 17)\n",
    "            ]\n",
    "            \n",
    "            for idx, hand_landmarks in enumerate(hand_detection_result.hand_landmarks):\n",
    "                # Determine if this is the dominant hand\n",
    "                is_dominant = False\n",
    "                if hand_detection_result.handedness:\n",
    "                    hand_type = hand_detection_result.handedness[idx][0].category_name\n",
    "                    is_dominant = (hand_type == dominand_hand)\n",
    "                \n",
    "                # Use different colors for dominant vs non-dominant hand\n",
    "                hand_color = (0, 0, 255) if is_dominant else (255, 0, 0)  # Blue for dominant, Red for non-dominant\n",
    "                \n",
    "                # Draw all landmark points\n",
    "                for landmark in hand_landmarks:\n",
    "                    # Convert normalized coordinates to pixel coordinates\n",
    "                    x = int(landmark.x * img_width)\n",
    "                    y = int(landmark.y * img_height)\n",
    "                    \n",
    "                    # Draw the landmark point\n",
    "                    cv2.circle(img_cv, (x, y), 5, hand_color, -1)\n",
    "                \n",
    "                # Draw connections between landmarks (hand skeleton)\n",
    "                for connection in connections:\n",
    "                    start_idx, end_idx = connection\n",
    "                    \n",
    "                    if start_idx < len(hand_landmarks) and end_idx < len(hand_landmarks):\n",
    "                        start_point = hand_landmarks[start_idx]\n",
    "                        end_point = hand_landmarks[end_idx]\n",
    "                        \n",
    "                        # Convert normalized coordinates to pixel coordinates\n",
    "                        start_x = int(start_point.x * img_width)\n",
    "                        start_y = int(start_point.y * img_height)\n",
    "                        end_x = int(end_point.x * img_width)\n",
    "                        end_y = int(end_point.y * img_height)\n",
    "                        \n",
    "                        # Draw the connection line\n",
    "                        cv2.line(img_cv, (start_x, start_y), (end_x, end_y), hand_color, 2)\n",
    "                \n",
    "                # Add hand type label (Left/Right, Dominant/Non-dominant)\n",
    "                if hand_detection_result.handedness:\n",
    "                    handedness = hand_detection_result.handedness[idx]\n",
    "                    hand_type = handedness[0].category_name  # 'Left' or 'Right'\n",
    "                    hand_score = handedness[0].score\n",
    "                    dom_status = \"Dominant\" if hand_type == dominand_hand else \"Non-dominant\"\n",
    "                    cv2.putText(img_cv, f\"{hand_type} Hand - {dom_status} ({hand_score:.2f})\", \n",
    "                            (10, 30 + idx * 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.8, hand_color, 2)\n",
    "                    \n",
    "                    # Calculate and draw a bounding box\n",
    "                    x_coords = [landmark.x for landmark in hand_landmarks]\n",
    "                    y_coords = [landmark.y for landmark in hand_landmarks]\n",
    "                    min_x, max_x = min(x_coords), max(x_coords)\n",
    "                    min_y, max_y = min(y_coords), max(y_coords)\n",
    "                    \n",
    "                    # Convert to pixel coordinates\n",
    "                    min_x, max_x = int(min_x * img_width), int(max_x * img_width)\n",
    "                    min_y, max_y = int(min_y * img_height), int(max_y * img_height)\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    cv2.rectangle(img_cv, (min_x, min_y), (max_x, max_y), hand_color, 2)\n",
    "\n",
    "        # 3.2: Draw Nose if face was detected\n",
    "        if face_detected == 1:\n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            face_x = int(nose_landmark[0] * img_width)\n",
    "            face_y = int(nose_landmark[1] * img_height)\n",
    "            \n",
    "            # Draw the Nose with a distinctive color and size\n",
    "            cv2.circle(img_cv, (face_x, face_y), 8, (0, 255, 255), -1)  # Yellow circle\n",
    "            cv2.putText(img_cv, \"Nose\", (face_x + 10, face_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            # Draw eyes\n",
    "            left_eye_x = int(left_eye_landmark[0] * img_width)\n",
    "            left_eye_y = int(left_eye_landmark[1] * img_height)\n",
    "            right_eye_x = int(right_eye_landmark[0] * img_width)\n",
    "            right_eye_y = int(right_eye_landmark[1] * img_height)\n",
    "            \n",
    "            cv2.circle(img_cv, (left_eye_x, left_eye_y), 6, (255, 255, 0), -1)  # Cyan circle\n",
    "            cv2.circle(img_cv, (right_eye_x, right_eye_y), 6, (255, 255, 0), -1)  # Cyan circle\n",
    "            cv2.line(img_cv, (left_eye_x, left_eye_y), (right_eye_x, right_eye_y), (255, 255, 0), 2)\n",
    "        # 3.3: Add detection status information to visualization\n",
    "        y_pos = img_height - 80\n",
    "        hand_status_text = f\"Hand Detection: Dom={detection_status[0]}, Non-Dom={detection_status[1]}\"\n",
    "        hand_conf_text = f\"Hand Confidence: Dom={confidence_scores[0]:.2f}, Non-Dom={confidence_scores[1]:.2f}\"\n",
    "        face_status_text = f\"Face Detection: {face_detected}\"\n",
    "        \n",
    "        cv2.putText(img_cv, hand_status_text, (10, y_pos), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(img_cv, hand_conf_text, (10, y_pos + 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(img_cv, face_status_text, (10, y_pos + 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        # 3.4: Display the result\n",
    "        cv2.imshow('Hand and Face Landmarks', img_cv)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    if face_detected==1:\n",
    "        #Calculate distance between the eyes\n",
    "        eyes_diff = right_eye_landmark-left_eye_landmark\n",
    "        eyes_distance = np.sqrt(eyes_diff.dot(eyes_diff))\n",
    "        if detection_status[0]==1 and detection_status[1]==1:\n",
    "            nose_to_wrist_dist = (wrists-nose_landmark) / eyes_distance\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the eye's distance\n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / eyes_distance\n",
    "            non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[1, :]) / eyes_distance\n",
    "        elif detection_status[0]==1 and detection_status[1]==0:\n",
    "            nose_to_wrist_dist[0, :] = (wrists[0, :]-nose_landmark) / eyes_distance\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the eye's distance\n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / eyes_distance\n",
    "        elif detection_status[0]==0 and detection_status[1]==1:\n",
    "            nose_to_wrist_dist[1,:] = (wrists[1,:]-nose_landmark) / eyes_distance\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the eye's distance\n",
    "            non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[0, :]) / eyes_distance\n",
    "        \n",
    "    elif face_detected==0 and detection_status[0]==1:\n",
    "        #Calculate palm width distance as fallback scaling factor\n",
    "        palm_width_diff = dom_landmarks[5, :]- dom_landmarks[17, :]\n",
    "        palm_width_dist = np.sqrt(palm_width_diff.dot(palm_width_diff))\n",
    "        if detection_status[1]==1:\n",
    "            nose_to_wrist_dist = (wrists-nose_landmark) / palm_width_dist\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the palm width \n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / palm_width_dist\n",
    "            non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[1, :]) / palm_width_dist\n",
    "        elif detection_status[1]==0:\n",
    "            nose_to_wrist_dist[0,:] = (wrists[0,:]-nose_landmark) / palm_width_dist\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the palm width \n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / palm_width_dist\n",
    "    elif face_detected==0 and detection_status[0]==0 and detection_status[1]==1:\n",
    "        #Calculate palm width distance as fallback scaling factor\n",
    "        palm_width_diff = non_dom_landmarks[5, :]- non_dom_landmarks[17, :]\n",
    "        palm_width_dist = np.sqrt(palm_width_diff.dot(palm_width_diff))\n",
    "        nose_to_wrist_dist[1,:] = (wrists[1,:]-nose_landmark) / palm_width_dist\n",
    "        #Make every hand's landmark potision relative to the wrist, and scaled by the palm width \n",
    "        non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[1, :]) / palm_width_dist\n",
    "    \n",
    "\n",
    "    \n",
    "    # Return all requested outputs\n",
    "    return dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742824825.617509    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824825.620415  282728 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824825.856196  282729 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824825.881208  282730 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824825.948322    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824825.952441  282744 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824825.953249    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824825.961192  282746 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824825.988733  282749 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Left) detected: True\n",
      "Non-dominant hand detected: True\n",
      "Visualizing 2 hands\n"
     ]
    }
   ],
   "source": [
    "lol = detect(grimace_2_path, hand_model_path, face_model_path, min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, num_hands=2, dominand_hand='Left', visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lol[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.22157899, -0.47131054, -0.03073101],\n",
       "        [-0.17301513, -0.94633667, -0.04778747],\n",
       "        [ 0.09016798, -1.17645313, -0.06066544],\n",
       "        [ 0.44656346, -1.2285489 , -0.07052706],\n",
       "        [ 0.75239831, -1.00154878, -0.03440262],\n",
       "        [ 0.74546371, -0.32252427, -0.05854694],\n",
       "        [ 0.52926255,  0.01389155, -0.07399104],\n",
       "        [ 0.3284734 ,  0.18489803, -0.08165359],\n",
       "        [ 0.96142811, -0.83551715, -0.02785412],\n",
       "        [ 0.733497  , -0.12437514, -0.05066952],\n",
       "        [ 0.38909197,  0.19143662, -0.05764463],\n",
       "        [ 0.1054417 ,  0.3583336 , -0.05927849],\n",
       "        [ 1.04701376, -0.64099421, -0.02452194],\n",
       "        [ 0.80774103, -0.04213003, -0.04881671],\n",
       "        [ 0.46820677,  0.20524576, -0.04839684],\n",
       "        [ 0.19587368,  0.31181122, -0.04229698],\n",
       "        [ 1.07308434, -0.42637636, -0.02360797],\n",
       "        [ 1.01975656, -0.01941465, -0.04110365],\n",
       "        [ 0.78549988,  0.19136538, -0.03911975],\n",
       "        [ 0.56846131,  0.24917491, -0.03242829]]),\n",
       " array([[ 0.43443525, -0.28010929, -0.01027886],\n",
       "        [ 0.80353707, -0.54089751, -0.0247014 ],\n",
       "        [ 0.97556812, -0.65599555, -0.03816538],\n",
       "        [ 1.01942988, -0.56354025, -0.05229027],\n",
       "        [ 0.86045716, -0.13682166, -0.03400054],\n",
       "        [ 1.31591499,  0.24062976, -0.04829271],\n",
       "        [ 1.60218625,  0.43870974, -0.05713674],\n",
       "        [ 1.81017121,  0.57159162, -0.06226961],\n",
       "        [ 0.61163023,  0.19540783, -0.03670957],\n",
       "        [ 1.09116728,  0.50590183, -0.04773441],\n",
       "        [ 1.4089959 ,  0.66185109, -0.05110947],\n",
       "        [ 1.64211591,  0.76527366, -0.05398791],\n",
       "        [ 0.37204199,  0.52394618, -0.03922421],\n",
       "        [ 0.87258241,  0.80436906, -0.0487699 ],\n",
       "        [ 1.172205  ,  0.94312534, -0.04679542],\n",
       "        [ 1.3891072 ,  1.00824313, -0.04479555],\n",
       "        [ 0.14446114,  0.84810335, -0.04231404],\n",
       "        [ 0.57520175,  1.08297814, -0.05030103],\n",
       "        [ 0.84108896,  1.15069684, -0.04695994],\n",
       "        [ 1.05146618,  1.16495436, -0.04323559]]),\n",
       " array([0.84230059, 0.72651029]),\n",
       " array([1., 1.]),\n",
       " array([1, 1], dtype=int32),\n",
       " array([5.13106784e-07, 2.02846597e-03, 3.18804756e-03, 5.41452050e-01,\n",
       "        7.69849420e-02, 3.81750800e-02, 1.87551632e-05, 3.96643820e-08,\n",
       "        2.66600040e-07, 3.10787767e-01, 3.27007324e-01, 3.97320539e-01,\n",
       "        3.99153769e-01, 1.49953105e-02, 5.87362051e-01, 5.51258922e-01,\n",
       "        2.45020236e-03, 3.55305187e-02, 3.04265637e-02, 4.82355088e-01,\n",
       "        5.29462278e-01, 4.21624212e-03, 2.38157995e-03, 6.42919476e-05,\n",
       "        1.46195479e-03, 3.30839418e-02, 7.51869346e-04, 9.70096048e-03,\n",
       "        8.69681120e-01, 8.20557177e-01, 7.09664860e-09, 2.41063027e-08,\n",
       "        2.43527279e-03, 4.74228486e-02, 2.91958713e-04, 1.99188435e-04,\n",
       "        3.98596115e-02, 1.40069559e-01, 1.56948388e-01, 7.12577777e-04,\n",
       "        1.05726868e-01, 7.86331594e-01, 1.80265668e-03, 3.23777436e-04,\n",
       "        1.01934398e-04, 2.63166294e-04, 7.19477441e-07, 1.26338258e-04,\n",
       "        9.95448863e-06, 5.62861487e-06, 3.39345775e-07, 4.37951542e-08]),\n",
       " 1,\n",
       " array([[ 3.81955315,  4.40232786],\n",
       "        [-3.99970874,  4.21392517]]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_detect(image_path, hand_model_path, face_model_path, min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, \n",
    "                   min_face_detection_confidence=0.5, min_face_presence_confidence=0.5, \n",
    "                   num_hands=2, dominand_hand='Right', visualize=False, output_face_blendshapes=True,\n",
    "                   max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Adaptively detects hands and face by progressively lowering detection thresholds\n",
    "    for undetected body parts.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        min_hand_detection_confidence (float): Initial confidence threshold for hand detection\n",
    "        min_hand_presence_confidence (float): Initial confidence threshold for hand presence\n",
    "        min_face_detection_confidence (float): Initial confidence threshold for face detection\n",
    "        min_face_presence_confidence (float): Initial confidence threshold for face presence\n",
    "        num_hands (int): Maximum number of hands to detect\n",
    "        dominand_hand (str): Dominant hand preference ('Left' or 'Right')\n",
    "        visualize (bool): Whether to visualize the final results\n",
    "        output_face_blendshapes (bool): Whether to detect and extract face blendshapes\n",
    "        max_attempts (int): Maximum number of detection attempts with lowered thresholds\n",
    "        threshold_reduction_factor (float): Factor to multiply thresholds by on each attempt (0-1)\n",
    "        min_threshold (float): Minimum threshold to prevent excessive lowering\n",
    "        \n",
    "    Returns:\n",
    "        Same output as the detect() function\n",
    "    \"\"\"\n",
    "    # Import the original detect function\n",
    "    #from your_module import detect  # Replace with actual module name\n",
    "    \n",
    "    # Store original thresholds\n",
    "    orig_hand_detection_conf = min_hand_detection_confidence\n",
    "    orig_hand_presence_conf = min_hand_presence_confidence\n",
    "    orig_face_detection_conf = min_face_detection_confidence\n",
    "    orig_face_presence_conf = min_face_presence_confidence\n",
    "    \n",
    "    # Initialize best results and detection status\n",
    "    best_results = None\n",
    "    best_detection_status = [0, 0]  # [dom_hand, non_dom_hand]\n",
    "    best_face_detected = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    # Try detection with progressively lower thresholds\n",
    "    for attempt in range(max_attempts):\n",
    "        print(f\"\\n--- Attempt {attempt+1}/{max_attempts} ---\")\n",
    "        \n",
    "        # Calculate current thresholds\n",
    "        if attempt > 0:\n",
    "            # Only lower thresholds for undetected parts\n",
    "            # For hands\n",
    "            if best_detection_status[0] == 0:  # Dominant hand not detected\n",
    "                hand_detection_conf_dom = max(orig_hand_detection_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                hand_presence_conf_dom = max(orig_hand_presence_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                print(f\"Lowering dominant hand thresholds: {hand_detection_conf_dom:.3f}, {hand_presence_conf_dom:.3f}\")\n",
    "            else:\n",
    "                hand_detection_conf_dom = orig_hand_detection_conf\n",
    "                hand_presence_conf_dom = orig_hand_presence_conf\n",
    "                \n",
    "            if best_detection_status[1] == 0:  # Non-dominant hand not detected\n",
    "                hand_detection_conf_non_dom = max(orig_hand_detection_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                hand_presence_conf_non_dom = max(orig_hand_presence_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                print(f\"Lowering non-dominant hand thresholds: {hand_detection_conf_non_dom:.3f}, {hand_presence_conf_non_dom:.3f}\")\n",
    "            else:\n",
    "                hand_detection_conf_non_dom = orig_hand_detection_conf\n",
    "                hand_presence_conf_non_dom = orig_hand_presence_conf\n",
    "            \n",
    "            # Use the minimum of the two calculated thresholds (MediaPipe doesn't support per-hand thresholds)\n",
    "            current_hand_detection_conf = min(hand_detection_conf_dom, hand_detection_conf_non_dom)\n",
    "            current_hand_presence_conf = min(hand_presence_conf_dom, hand_presence_conf_non_dom)\n",
    "            \n",
    "            # For face\n",
    "            if output_face_blendshapes and best_face_detected == 0:  # Face not detected\n",
    "                current_face_detection_conf = max(orig_face_detection_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                current_face_presence_conf = max(orig_face_presence_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                print(f\"Lowering face thresholds: {current_face_detection_conf:.3f}, {current_face_presence_conf:.3f}\")\n",
    "            else:\n",
    "                current_face_detection_conf = orig_face_detection_conf\n",
    "                current_face_presence_conf = orig_face_presence_conf\n",
    "        else:\n",
    "            # Use original thresholds for first attempt\n",
    "            current_hand_detection_conf = orig_hand_detection_conf\n",
    "            current_hand_presence_conf = orig_hand_presence_conf\n",
    "            current_face_detection_conf = orig_face_detection_conf\n",
    "            current_face_presence_conf = orig_face_presence_conf\n",
    "            print(f\"Using original thresholds: hands={current_hand_detection_conf}, face={current_face_detection_conf}\")\n",
    "        \n",
    "        # Call detect with current thresholds (don't visualize intermediate attempts)\n",
    "        results = detect(image_path,  hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                        min_hand_detection_confidence=current_hand_detection_conf,\n",
    "                        min_hand_presence_confidence=current_hand_presence_conf,\n",
    "                        min_face_detection_confidence=current_face_detection_conf,\n",
    "                        min_face_presence_confidence=current_face_presence_conf,\n",
    "                        num_hands=num_hands,\n",
    "                        dominand_hand=dominand_hand,\n",
    "                        visualize=False,\n",
    "                        output_face_blendshapes=output_face_blendshapes)\n",
    "        \n",
    "        # Unpack results\n",
    "        dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = results\n",
    "        \n",
    "        # Compare with best results so far\n",
    "        current_detection_count = detection_status[0] + detection_status[1] + face_detected\n",
    "        best_detection_count = best_detection_status[0] + best_detection_status[1] + best_face_detected\n",
    "        \n",
    "        if best_results is None or current_detection_count > best_detection_count:\n",
    "            best_results = results\n",
    "            best_detection_status = [detection_status[0], detection_status[1]]\n",
    "            best_face_detected = face_detected\n",
    "            \n",
    "            print(f\"New best detection: dominant hand={detection_status[0]}, \"\n",
    "                  f\"non-dominant hand={detection_status[1]}, face={face_detected}\")\n",
    "            \n",
    "            # If everything is detected, we can stop early\n",
    "            if detection_status[0] == 1 and detection_status[1] == 1 and (face_detected == 1 or not output_face_blendshapes):\n",
    "                print(\"All body parts detected. Stopping early.\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"No improvement in detection. Continuing to next attempt.\")\n",
    "    \n",
    "    # Run final detection with visualization if requested\n",
    "    if visualize:\n",
    "        print(\"\\n--- Visualizing final results ---\")\n",
    "        # Call detect one more time with the parameters that gave best results, but with visualize=True\n",
    "        # For simplicity, we'll just use the best thresholds we found\n",
    "        # This is slightly inefficient (one extra detection) but keeps the code clean\n",
    "        \n",
    "        # Determine which thresholds gave the best results\n",
    "        if best_detection_status[0] == 0:  # If dominant hand not detected in best result\n",
    "            hand_detection_conf = min_threshold\n",
    "            hand_presence_conf = min_threshold\n",
    "        else:\n",
    "            hand_detection_conf = orig_hand_detection_conf\n",
    "            hand_presence_conf = orig_hand_presence_conf\n",
    "            \n",
    "        if output_face_blendshapes and best_face_detected == 0:  # If face not detected in best result\n",
    "            face_detection_conf = min_threshold\n",
    "            face_presence_conf = min_threshold\n",
    "        else:\n",
    "            face_detection_conf = orig_face_detection_conf\n",
    "            face_presence_conf = orig_face_presence_conf\n",
    "        \n",
    "        # Run final detection with visualization\n",
    "        final_results = detect(image_path, hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                              min_hand_detection_confidence=hand_detection_conf,\n",
    "                              min_hand_presence_confidence=hand_presence_conf, \n",
    "                              min_face_detection_confidence=face_detection_conf,\n",
    "                              min_face_presence_confidence=face_presence_conf,\n",
    "                              num_hands=num_hands,\n",
    "                              dominand_hand=dominand_hand,\n",
    "                              visualize=True,\n",
    "                              output_face_blendshapes=output_face_blendshapes)\n",
    "        \n",
    "        # Use these results if they're better than our best so far\n",
    "        dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = final_results\n",
    "        current_detection_count = detection_status[0] + detection_status[1] + face_detected\n",
    "        best_detection_count = best_detection_status[0] + best_detection_status[1] + best_face_detected\n",
    "        \n",
    "        if current_detection_count > best_detection_count:\n",
    "            best_results = final_results\n",
    "    \n",
    "    # Print final detection summary\n",
    "    print(\"\\n=== Detection Summary ===\")\n",
    "    dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = best_results\n",
    "    print(f\"Dominant hand detected: {detection_status[0] == 1} (confidence: {confidence_scores[0]:.3f})\")\n",
    "    print(f\"Non-dominant hand detected: {detection_status[1] == 1} (confidence: {confidence_scores[1]:.3f})\")\n",
    "    if output_face_blendshapes:\n",
    "        print(f\"Face detected: {face_detected == 1}\")\n",
    "    print(f\"Total detection attempts: {attempt+1}\")\n",
    "    return best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=0, non-dominant hand=1, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering dominant hand thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742824986.936870    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824986.940818  284930 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.039888  284934 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.056971  284940 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.133708    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.135590  284946 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.136250    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.142800  284947 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.160368  284950 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.199556    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.202131  284962 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.238721  284964 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.252189  284966 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering dominant hand thresholds: 0.245, 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742824987.304140    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.307504  284978 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.308167    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.314875  284980 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.507001  284979 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.543464    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.547164  284994 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.568495  284996 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.686856  285000 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Visualizing final results ---\n",
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742824987.738748    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.741043  285010 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.741756    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.750388  285011 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.779803  285022 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.819273    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.822941  285026 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.853940  285027 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.874366  285035 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.927914    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.931627  285064 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.932330    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.944897  285072 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.965721  285078 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing 1 hands\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: False (confidence: 0.000)\n",
      "Non-dominant hand detected: True (confidence: 0.948)\n",
      "Face detected: True\n",
      "Total detection attempts: 3\n"
     ]
    }
   ],
   "source": [
    "best_results = adaptive_detect(without_left_hand_path, hand_model_path=hand_model_path, face_model_path=face_model_path,  min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, num_hands=2, dominand_hand='Left', visualize=True,output_face_blendshapes=True,max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dom_landmarks, non_dom_landmarks, confidence_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " array([[ 4.4302598 ,  5.79258936, -0.01529764],\n",
       "        [ 4.97843194,  5.60716573, -0.03023903],\n",
       "        [ 5.4227688 ,  5.474167  , -0.04531926],\n",
       "        [ 5.6396736 ,  5.29133956, -0.06161126],\n",
       "        [ 5.46952226,  5.95203357, -0.02546122],\n",
       "        [ 6.14746077,  5.96317265, -0.03837759],\n",
       "        [ 6.5033938 ,  5.98504281, -0.04724246],\n",
       "        [ 6.77242064,  5.99687042, -0.05398038],\n",
       "        [ 5.45199885,  6.19957023, -0.02953801],\n",
       "        [ 6.20066676,  6.22105431, -0.03755009],\n",
       "        [ 6.60851154,  6.23570749, -0.04424638],\n",
       "        [ 6.9013028 ,  6.24974116, -0.05119639],\n",
       "        [ 5.33187311,  6.40705239, -0.03495561],\n",
       "        [ 6.02315108,  6.45053573, -0.04479358],\n",
       "        [ 6.42136374,  6.46895391, -0.05380662],\n",
       "        [ 6.71558972,  6.47136295, -0.0608963 ],\n",
       "        [ 5.14666546,  6.58524524, -0.04154579],\n",
       "        [ 5.66482483,  6.65936167, -0.04902381],\n",
       "        [ 5.98583324,  6.67587705, -0.05188949],\n",
       "        [ 6.25919546,  6.67568786, -0.0540517 ]]),\n",
       " array([0.       , 0.9484275]),\n",
       " array([0., 1.]),\n",
       " array([0, 1], dtype=int32),\n",
       " array([2.92115374e-07, 1.33861089e-02, 1.24196718e-02, 2.88109779e-01,\n",
       "        5.75697683e-02, 3.07354219e-02, 1.32326995e-05, 1.58878031e-08,\n",
       "        8.72999664e-08, 3.63642573e-01, 4.11365360e-01, 6.62605762e-01,\n",
       "        6.69030905e-01, 2.73421267e-03, 5.51178098e-01, 5.63342750e-01,\n",
       "        1.03895655e-02, 1.23140477e-02, 8.84756818e-03, 2.24526033e-01,\n",
       "        2.50775576e-01, 4.66695800e-03, 1.89312676e-03, 3.73961666e-05,\n",
       "        1.19879853e-03, 7.60920672e-03, 4.57036338e-04, 1.92889536e-03,\n",
       "        8.89772832e-01, 8.59930277e-01, 8.38296987e-10, 1.49412671e-09,\n",
       "        1.53606525e-02, 1.33757144e-02, 1.26740182e-04, 8.43084490e-05,\n",
       "        7.94648603e-02, 9.92558002e-02, 8.17362487e-01, 1.14337606e-02,\n",
       "        1.67473480e-02, 3.32397074e-01, 3.43104475e-03, 1.09493383e-03,\n",
       "        1.44784761e-04, 2.09721227e-04, 8.35517653e-07, 5.79597008e-06,\n",
       "        3.15646721e-05, 2.39465880e-05, 5.11401367e-07, 3.26468843e-08]),\n",
       " 1,\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [-1.39355698,  4.85907125]]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_video(video_path, adaptive_detect_func, hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                 min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5,\n",
    "                 min_face_detection_confidence=0.5, min_face_presence_confidence=0.5,\n",
    "                 num_hands=2, output_face_blendshapes=True,\n",
    "                 max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2, \n",
    "                 frame_step=1, start_time_seconds=0, end_time_seconds=None,\n",
    "                 save_failure_screenshots=False):\n",
    "    \"\"\"\n",
    "    Process a video frame-by-frame using the adaptive_detect function and save results.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the video file\n",
    "        adaptive_detect_func: The adaptive detection function to use\n",
    "        min_hand_detection_confidence (float): Initial confidence threshold for hand detection\n",
    "        min_hand_presence_confidence (float): Initial confidence threshold for hand presence\n",
    "        min_face_detection_confidence (float): Initial confidence threshold for face detection\n",
    "        min_face_presence_confidence (float): Initial confidence threshold for face presence\n",
    "        num_hands (int): Maximum number of hands to detect\n",
    "        dominand_hand (str): Dominant hand preference ('Left' or 'Right')\n",
    "        output_face_blendshapes (bool): Whether to detect face blendshapes\n",
    "        max_attempts (int): Maximum detection attempts for adaptive detection\n",
    "        threshold_reduction_factor (float): Factor to reduce thresholds by\n",
    "        min_threshold (float): Minimum threshold limit\n",
    "        frame_step (int): Process every Nth frame (1 = all frames)\n",
    "        start_time_seconds (float): Time in seconds to start processing from\n",
    "        end_time_seconds (float): Time in seconds to end processing (None = process until end)\n",
    "        save_failure_screenshots (bool): Save screenshots for all frames with any detection failures\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the directory containing saved frame results\n",
    "    \"\"\"\n",
    "    # Extract video name for directory creation\n",
    "    video_path = Path(video_path)\n",
    "    video_name = video_path.stem  # Get filename without extension\n",
    "    \n",
    "    # Extract dominant hand information from filename\n",
    "    if video_name.endswith(\"_Right\"):\n",
    "        extracted_dominant_hand = \"Right\"\n",
    "    elif video_name.endswith(\"_Left\"):\n",
    "        extracted_dominant_hand = \"Left\"\n",
    "    else:\n",
    "        # Default if not specified in filename\n",
    "        extracted_dominant_hand = \"Right\"\n",
    "        print(f\"Warning: Could not determine dominant hand from filename, using default: {dominand_hand}\")\n",
    "\n",
    "    # Use the extracted dominant hand instead of the parameter\n",
    "    dominand_hand = extracted_dominant_hand\n",
    "    print(f\"Detected dominant hand from filename: {dominand_hand}\")\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = Path(f\"{video_name}_landmarks\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create screenshots directory if screenshot option is enabled\n",
    "    screenshots_dir = None\n",
    "    if save_failure_screenshots:\n",
    "        screenshots_dir = output_dir / \"failure_screenshots\"\n",
    "        screenshots_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create a log file to track processing\n",
    "    log_file = output_dir / \"processing_log.txt\"\n",
    "    \n",
    "    # Create a detailed statistics file\n",
    "    stats_file = output_dir / \"detection_statistics.json\"\n",
    "    \n",
    "    # Initialize statistics tracking\n",
    "    stats = {\n",
    "        \"video_info\": {\n",
    "            \"name\": video_name,\n",
    "            \"path\": str(video_path),\n",
    "            \"total_frames\": 0,\n",
    "            \"processed_frames\": 0,\n",
    "            \"fps\": 0,\n",
    "            \"duration_seconds\": 0,\n",
    "            \"start_time\": start_time_seconds,\n",
    "            \"end_time\": end_time_seconds,\n",
    "            \"dominant_hand\": dominand_hand,\n",
    "            \"processing_started\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"processing_completed\": None\n",
    "        },\n",
    "        \"detection_rates\": {\n",
    "            \"dominant_hand\": {\n",
    "                \"detected\": 0,\n",
    "                \"failed\": 0,\n",
    "                \"detection_rate\": 0\n",
    "            },\n",
    "            \"non_dominant_hand\": {\n",
    "                \"detected\": 0,\n",
    "                \"failed\": 0,\n",
    "                \"detection_rate\": 0\n",
    "            },\n",
    "            \"face\": {\n",
    "                \"detected\": 0,\n",
    "                \"failed\": 0,\n",
    "                \"detection_rate\": 0\n",
    "            },\n",
    "            \"overall\": {\n",
    "                \"all_detected\": 0,\n",
    "                \"partial_detections\": 0,\n",
    "                \"no_detections\": 0,\n",
    "                \"success_rate\": 0\n",
    "            }\n",
    "        },\n",
    "        \"failed_frames\": {\n",
    "            \"dominant_hand_failures\": [],\n",
    "            \"non_dominant_hand_failures\": [],\n",
    "            \"face_failures\": [],\n",
    "            \"all_failures\": []\n",
    "        },\n",
    "        \"processing_performance\": {\n",
    "            \"average_processing_time_ms\": 0,\n",
    "            \"total_processing_time_seconds\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(log_file, \"w\") as log:\n",
    "        log.write(f\"Processing video: {video_path}\\n\")\n",
    "        log.write(f\"Started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        log.write(f\"Parameters:\\n\")\n",
    "        log.write(f\"  - frame_step: {frame_step}\\n\")\n",
    "        log.write(f\"  - start_time: {start_time_seconds} seconds\\n\")\n",
    "        if end_time_seconds is not None:\n",
    "            log.write(f\"  - end_time: {end_time_seconds} seconds\\n\")\n",
    "        log.write(f\"  - dominand_hand: {dominand_hand}\\n\")\n",
    "        log.write(f\"  - num_hands: {num_hands}\\n\")\n",
    "        log.write(f\"  - detection confidence thresholds: {min_hand_detection_confidence}, {min_face_detection_confidence}\\n\")\n",
    "        log.write(\"\\n--- Frame processing log ---\\n\")\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration_seconds = total_frames / fps if fps > 0 else 0\n",
    "    \n",
    "    # Update stats with video info\n",
    "    stats[\"video_info\"][\"total_frames\"] = total_frames\n",
    "    stats[\"video_info\"][\"fps\"] = fps\n",
    "    stats[\"video_info\"][\"duration_seconds\"] = duration_seconds\n",
    "    \n",
    "    # Convert time to frame indices\n",
    "    start_frame = int(max(0, start_time_seconds * fps))\n",
    "    \n",
    "    # Set end frame if specified\n",
    "    if end_time_seconds is not None:\n",
    "        end_frame = min(total_frames, int(end_time_seconds * fps))\n",
    "    else:\n",
    "        end_frame = total_frames\n",
    "    \n",
    "    print(f\"Video: {video_name}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    print(f\"Duration: {duration_seconds:.2f} seconds\")\n",
    "    print(f\"Processing frames {start_frame} to {end_frame} (time {start_time_seconds:.2f}s to {end_time_seconds if end_time_seconds is not None else duration_seconds:.2f}s)\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    \n",
    "    # Process frames\n",
    "    frame_idx = 0\n",
    "    processed_count = 0\n",
    "    total_processing_time = 0\n",
    "    \n",
    "    # Skip to start_frame\n",
    "    if start_frame > 0:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        frame_idx = start_frame\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        while frame_idx < end_frame:\n",
    "            # Read the next frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # End of video\n",
    "            \n",
    "            # Only process every frame_step frames\n",
    "            if (frame_idx - start_frame) % frame_step != 0:\n",
    "                frame_idx += 1\n",
    "                continue\n",
    "                \n",
    "            # Get timestamp in milliseconds\n",
    "            timestamp_ms = int(frame_idx * 1000 / fps)\n",
    "            timestamp_formatted = f\"{timestamp_ms//60000:02d}m{(timestamp_ms//1000)%60:02d}s{timestamp_ms%1000:03d}ms\"\n",
    "            \n",
    "            # Temporary frame path\n",
    "            temp_frame_path = Path(temp_dir) / f\"temp_frame_{frame_idx}.jpg\"\n",
    "            \n",
    "            # Save the current frame as an image\n",
    "            cv2.imwrite(str(temp_frame_path), frame)\n",
    "            \n",
    "            # Process the frame with adaptive_detect\n",
    "            print(f\"Processing frame {frame_idx}/{total_frames} (timestamp: {timestamp_formatted})\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                # Use adaptive_detect on the frame\n",
    "                results = adaptive_detect_func(\n",
    "                    str(temp_frame_path), hand_model_path, face_model_path,\n",
    "                    min_hand_detection_confidence=min_hand_detection_confidence,\n",
    "                    min_hand_presence_confidence=min_hand_presence_confidence,\n",
    "                    min_face_detection_confidence=min_face_detection_confidence,\n",
    "                    min_face_presence_confidence=min_face_presence_confidence,\n",
    "                    num_hands=num_hands,\n",
    "                    dominand_hand=dominand_hand,\n",
    "                    visualize=False,\n",
    "                    output_face_blendshapes=output_face_blendshapes,\n",
    "                    max_attempts=max_attempts,\n",
    "                    threshold_reduction_factor=threshold_reduction_factor,\n",
    "                    min_threshold=min_threshold\n",
    "                )\n",
    "                \n",
    "                # Calculate processing time\n",
    "                proc_time = time.time() - start_time\n",
    "                total_processing_time += proc_time\n",
    "                \n",
    "                # Unpack results\n",
    "                dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = results\n",
    "                \n",
    "                # Update detection statistics\n",
    "                dom_hand_detected = detection_status[0] == 1\n",
    "                non_dom_hand_detected = detection_status[1] == 1\n",
    "                face_was_detected = face_detected == 1\n",
    "                \n",
    "                if dom_hand_detected:\n",
    "                    stats[\"detection_rates\"][\"dominant_hand\"][\"detected\"] += 1\n",
    "                else:\n",
    "                    stats[\"detection_rates\"][\"dominant_hand\"][\"failed\"] += 1\n",
    "                    stats[\"failed_frames\"][\"dominant_hand_failures\"].append({\n",
    "                        \"frame\": frame_idx,\n",
    "                        \"timestamp_ms\": timestamp_ms,\n",
    "                        \"file\": f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}.npz\"\n",
    "                    })\n",
    "                \n",
    "                if non_dom_hand_detected:\n",
    "                    stats[\"detection_rates\"][\"non_dominant_hand\"][\"detected\"] += 1\n",
    "                else:\n",
    "                    stats[\"detection_rates\"][\"non_dominant_hand\"][\"failed\"] += 1\n",
    "                    stats[\"failed_frames\"][\"non_dominant_hand_failures\"].append({\n",
    "                        \"frame\": frame_idx,\n",
    "                        \"timestamp_ms\": timestamp_ms,\n",
    "                        \"file\": f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}.npz\"\n",
    "                    })\n",
    "                \n",
    "                if face_was_detected:\n",
    "                    stats[\"detection_rates\"][\"face\"][\"detected\"] += 1\n",
    "                else:\n",
    "                    stats[\"detection_rates\"][\"face\"][\"failed\"] += 1\n",
    "                    stats[\"failed_frames\"][\"face_failures\"].append({\n",
    "                        \"frame\": frame_idx,\n",
    "                        \"timestamp_ms\": timestamp_ms,\n",
    "                        \"file\": f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}.npz\"\n",
    "                    })\n",
    "                \n",
    "                # Track combined detection status\n",
    "                detection_count = dom_hand_detected + non_dom_hand_detected + face_was_detected\n",
    "                \n",
    "                if detection_count == 3:\n",
    "                    stats[\"detection_rates\"][\"overall\"][\"all_detected\"] += 1\n",
    "                elif detection_count == 0:\n",
    "                    stats[\"detection_rates\"][\"overall\"][\"no_detections\"] += 1\n",
    "                    stats[\"failed_frames\"][\"all_failures\"].append({\n",
    "                        \"frame\": frame_idx,\n",
    "                        \"timestamp_ms\": timestamp_ms,\n",
    "                        \"file\": f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}.npz\"\n",
    "                    })\n",
    "                else:\n",
    "                    stats[\"detection_rates\"][\"overall\"][\"partial_detections\"] += 1\n",
    "                \n",
    "                # Save screenshot if any detection failed and screenshots are enabled\n",
    "                if save_failure_screenshots and (not dom_hand_detected or not non_dom_hand_detected or not face_was_detected):\n",
    "                    # Create a detailed failure type description for the filename\n",
    "                    failure_type = []\n",
    "                    if not dom_hand_detected:\n",
    "                        failure_type.append(\"DomHand\")\n",
    "                    if not non_dom_hand_detected:\n",
    "                        failure_type.append(\"NonDomHand\")\n",
    "                    if not face_was_detected:\n",
    "                        failure_type.append(\"Face\")\n",
    "                    \n",
    "                    failure_str = \"_\".join(failure_type)\n",
    "                    screenshot_filename = f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}_missing_{failure_str}.jpg\"\n",
    "                    screenshot_path = screenshots_dir / screenshot_filename\n",
    "                    \n",
    "                    # Copy the frame to the screenshots directory\n",
    "                    cv2.imwrite(str(screenshot_path), frame)\n",
    "                    print(f\"Saved failure screenshot: {screenshot_filename}\")\n",
    "                \n",
    "                # Create output filename with frame info\n",
    "                output_filename = f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}.npz\"\n",
    "                output_path = output_dir / output_filename\n",
    "                \n",
    "                # Save all results in a single .npz file\n",
    "                np.savez(\n",
    "                    output_path,\n",
    "                    dom_landmarks=dom_landmarks,\n",
    "                    non_dom_landmarks=non_dom_landmarks,\n",
    "                    confidence_scores=confidence_scores,\n",
    "                    interpolation_scores=interpolation_scores,\n",
    "                    detection_status=detection_status,\n",
    "                    blendshape_scores=blendshape_scores,\n",
    "                    face_detected=face_detected,\n",
    "                    nose_to_wrist_dist=nose_to_wrist_dist,\n",
    "                    frame_idx=np.array([frame_idx]),\n",
    "                    timestamp_ms=np.array([timestamp_ms])\n",
    "                )\n",
    "                \n",
    "                # Update processing log\n",
    "                detection_summary = f\"Dom: {detection_status[0]}, Non-dom: {detection_status[1]}, Face: {face_detected}\"\n",
    "                log_entry = f\"Frame {frame_idx}: {detection_summary} (proc time: {proc_time:.2f}s)\\n\"\n",
    "                \n",
    "                with open(log_file, \"a\") as log:\n",
    "                    log.write(log_entry)\n",
    "                \n",
    "                processed_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame {frame_idx}: {e}\")\n",
    "                with open(log_file, \"a\") as log:\n",
    "                    log.write(f\"Error on frame {frame_idx}: {str(e)}\\n\")\n",
    "            \n",
    "            # Clean up temporary frame file\n",
    "            if temp_frame_path.exists():\n",
    "                temp_frame_path.unlink()\n",
    "                \n",
    "            frame_idx += 1\n",
    "    \n",
    "    # Close the video file\n",
    "    cap.release()\n",
    "    \n",
    "    # Update final statistics\n",
    "    stats[\"video_info\"][\"processed_frames\"] = processed_count\n",
    "    stats[\"video_info\"][\"processing_completed\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Calculate detection rates\n",
    "    if processed_count > 0:\n",
    "        stats[\"detection_rates\"][\"dominant_hand\"][\"detection_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"dominant_hand\"][\"detected\"] / processed_count * 100\n",
    "        )\n",
    "        stats[\"detection_rates\"][\"non_dominant_hand\"][\"detection_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"non_dominant_hand\"][\"detected\"] / processed_count * 100\n",
    "        )\n",
    "        stats[\"detection_rates\"][\"face\"][\"detection_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"face\"][\"detected\"] / processed_count * 100\n",
    "        )\n",
    "        stats[\"detection_rates\"][\"overall\"][\"success_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"overall\"][\"all_detected\"] / processed_count * 100\n",
    "        )\n",
    "    \n",
    "    # Calculate processing performance\n",
    "    if processed_count > 0:\n",
    "        stats[\"processing_performance\"][\"average_processing_time_ms\"] = (\n",
    "            total_processing_time / processed_count * 1000\n",
    "        )\n",
    "    stats[\"processing_performance\"][\"total_processing_time_seconds\"] = total_processing_time\n",
    "    \n",
    "    # Save statistics to JSON file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    \n",
    "    # Add summary statistics to log file\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(f\"\\n\\n===== PROCESSING SUMMARY =====\\n\")\n",
    "        log.write(f\"Completed at: {stats['video_info']['processing_completed']}\\n\")\n",
    "        log.write(f\"Frames processed: {processed_count} from {start_frame} to {min(end_frame, frame_idx-1)}\\n\\n\")\n",
    "        \n",
    "        log.write(\"DETECTION RATES:\\n\")\n",
    "        log.write(f\"  Dominant hand ({dominand_hand}): {stats['detection_rates']['dominant_hand']['detection_rate']:.1f}%\\n\")\n",
    "        log.write(f\"  Non-dominant hand: {stats['detection_rates']['non_dominant_hand']['detection_rate']:.1f}%\\n\")\n",
    "        log.write(f\"  Face: {stats['detection_rates']['face']['detection_rate']:.1f}%\\n\")\n",
    "        log.write(f\"  All parts detected: {stats['detection_rates']['overall']['success_rate']:.1f}%\\n\\n\")\n",
    "        \n",
    "        log.write(\"DETECTION FAILURES:\\n\")\n",
    "        log.write(f\"  Frames with dominant hand failures: {len(stats['failed_frames']['dominant_hand_failures'])}\\n\")\n",
    "        log.write(f\"  Frames with non-dominant hand failures: {len(stats['failed_frames']['non_dominant_hand_failures'])}\\n\")\n",
    "        log.write(f\"  Frames with face failures: {len(stats['failed_frames']['face_failures'])}\\n\")\n",
    "        log.write(f\"  Frames with all parts missing: {len(stats['failed_frames']['all_failures'])}\\n\\n\")\n",
    "        \n",
    "        log.write(\"PERFORMANCE:\\n\")\n",
    "        log.write(f\"  Average processing time per frame: {stats['processing_performance']['average_processing_time_ms']:.2f} ms\\n\")\n",
    "        log.write(f\"  Total processing time: {stats['processing_performance']['total_processing_time_seconds']:.2f} seconds\\n\")\n",
    "    \n",
    "    print(f\"\\n===== PROCESSING SUMMARY =====\")\n",
    "    print(f\"Processed {processed_count} frames\")\n",
    "    print(f\"Detection rates: Dom hand: {stats['detection_rates']['dominant_hand']['detection_rate']:.1f}%, \" +\n",
    "          f\"Non-dom hand: {stats['detection_rates']['non_dominant_hand']['detection_rate']:.1f}%, \" +\n",
    "          f\"Face: {stats['detection_rates']['face']['detection_rate']:.1f}%\")\n",
    "    print(f\"All parts detected in {stats['detection_rates']['overall']['success_rate']:.1f}% of frames\")\n",
    "    print(f\"Full statistics saved to: {stats_file}\")\n",
    "    print(f\"Results saved to: {output_dir}\")\n",
    "    \n",
    "    return str(output_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frame_data(npz_path):\n",
    "    \"\"\"\n",
    "    Load saved frame data from an NPZ file.\n",
    "    \n",
    "    Args:\n",
    "        npz_path (str): Path to the saved .npz file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: All the detection results for the frame\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    \n",
    "    # Extract all arrays from the npz file\n",
    "    dom_landmarks = data['dom_landmarks']\n",
    "    non_dom_landmarks = data['non_dom_landmarks']\n",
    "    confidence_scores = data['confidence_scores']\n",
    "    interpolation_scores = data['interpolation_scores']\n",
    "    detection_status = data['detection_status']\n",
    "    blendshape_scores = data['blendshape_scores']\n",
    "    face_detected = data['face_detected'].item()  # Convert 0-d array to scalar\n",
    "    nose_to_wrist_dist = data['nose_to_wrist_dist']\n",
    "    frame_idx = data['frame_idx'].item()\n",
    "    timestamp_ms = data['timestamp_ms'].item()\n",
    "    \n",
    "    return (dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores,\n",
    "            detection_status, blendshape_scores, face_detected, \n",
    "            nose_to_wrist_dist, frame_idx, timestamp_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected dominant hand from filename: Right\n",
      "Video: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right\n",
      "Total frames: 65\n",
      "FPS: 1.0\n",
      "Duration: 65.00 seconds\n",
      "Processing frames 30 to 60 (time 30.20s to 60.40s)\n",
      "Output directory: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Processing frame 30/65 (timestamp: 00m30s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "New best detection: dominant hand=1, non-dominant hand=0, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825052.746069    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825052.748711  285922 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825052.905120  285926 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825052.920770  285929 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825052.974667    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825052.977903  285963 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825052.978290    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825052.983690  285966 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.008988  285970 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825053.050857    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.053377  285979 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.076120  285984 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.088191  285989 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.974)\n",
      "Non-dominant hand detected: True (confidence: 0.996)\n",
      "Face detected: True\n",
      "Total detection attempts: 2\n",
      "Processing frame 31/65 (timestamp: 00m31s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825053.155234    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.157598  285995 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.158565    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825053.167968  285998 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.195131  286002 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825053.260700    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.263555  286011 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.284677  286021 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.302039  286014 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825053.378572    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.380666  286027 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.381026    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825053.385487  286039 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.402349  286038 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.980)\n",
      "Non-dominant hand detected: True (confidence: 0.998)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 32/65 (timestamp: 00m32s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.966)\n",
      "Non-dominant hand detected: True (confidence: 0.970)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825053.457154    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.461117  286043 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.481965  286045 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.502345  286047 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825053.566839    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.568952  286059 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.569473    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825053.588486  286061 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.612980  286068 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 33/65 (timestamp: 00m33s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=0\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering face thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825053.662359    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.665386  286075 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.687249  286079 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.720949  286078 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825053.787464    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.790880  286091 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.791811    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825053.801966  286095 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.827920  286100 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825053.863228    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825053.865633  286107 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825053.923506  286111 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825053.937012  286109 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering face thresholds: 0.245, 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825054.057932    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825054.065068  286123 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825054.066133    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825054.074088  286126 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825054.094653  286125 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825054.120179    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825054.122838  286139 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825054.163874  286144 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825054.237643  286142 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.997)\n",
      "Non-dominant hand detected: True (confidence: 0.997)\n",
      "Face detected: False\n",
      "Total detection attempts: 3\n",
      "Saved failure screenshot: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000033_00m33s000ms_missing_Face.jpg\n",
      "Processing frame 34/65 (timestamp: 00m34s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825054.333483    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825054.337156  286155 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825054.337746    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825054.344548  286158 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825054.366307  286162 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825054.437329    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825054.442179  286171 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825054.668853  286175 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825054.684868  286172 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825054.777628    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825054.781159  286187 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825054.781948    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825054.791387  286191 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825054.808377  286197 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825054.846045    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825054.849715  286203 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825054.873405  286212 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825054.888682  286210 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: False\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=0, non-dominant hand=1, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering dominant hand thresholds: 0.350, 0.350\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825054.973827    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825054.978387  286240 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825054.978935    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825054.984255  286250 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.003434  286242 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825055.066137    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.949)\n",
      "Non-dominant hand detected: True (confidence: 0.993)\n",
      "Face detected: True\n",
      "Total detection attempts: 2\n",
      "Processing frame 35/65 (timestamp: 00m35s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825055.069305  286258 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.163885  286264 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.182700  286265 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825055.299712    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825055.302991  286274 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.303639    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825055.312574  286278 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.330157  286281 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825055.393245    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825055.397097  286290 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.431320  286291 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.461527  286293 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.905)\n",
      "Non-dominant hand detected: True (confidence: 0.993)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 36/65 (timestamp: 00m36s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "New best detection: dominant hand=1, non-dominant hand=0, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.350, 0.350\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825055.524229    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825055.528899  286306 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.529512    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825055.535332  286309 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.557954  286307 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825055.595251    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825055.598313  286322 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.619623  286324 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.638120  286332 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825055.697781    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825055.700543  286338 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.701186    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825055.707962  286347 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.729124  286341 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.245, 0.245\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.968)\n",
      "Non-dominant hand detected: False (confidence: 0.000)\n",
      "Face detected: True\n",
      "Total detection attempts: 3\n",
      "Saved failure screenshot: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms_missing_NonDomHand.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825055.769985    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825055.773674  286354 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.796141  286356 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.808954  286361 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825055.913043    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825055.916314  286370 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825055.917039    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825055.926599  286372 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825055.945301  286371 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 37/65 (timestamp: 00m37s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=0\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering face thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825056.013985    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.017461  286386 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.054586  286393 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.071209  286388 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825056.147362    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.150670  286402 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.151317    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825056.160428  286406 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.182484  286405 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825056.207335    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.212845  286418 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.237379  286419 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.261723  286421 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.949)\n",
      "Non-dominant hand detected: True (confidence: 0.998)\n",
      "Face detected: True\n",
      "Total detection attempts: 2\n",
      "Processing frame 38/65 (timestamp: 00m38s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825056.342296    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.344839  286434 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.345421    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825056.349651  286438 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.375765  286443 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825056.429841    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.432106  286450 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.451083  286453 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.466543  286454 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825056.538562    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.542134  286466 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.542993    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825056.547994  286474 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.569577  286475 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.953)\n",
      "Non-dominant hand detected: True (confidence: 0.997)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 39/65 (timestamp: 00m39s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825056.630942    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.634580  286482 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.869609  286485 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.886141  286484 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825056.966339    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825056.969617  286498 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825056.970264    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825056.978979  286500 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825056.996410  286505 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825057.035896    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.039869  286526 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.067003  286533 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.092983  286527 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "New best detection: dominant hand=1, non-dominant hand=0, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.350, 0.350\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825057.154297    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.156455  286558 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.157239    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825057.162417  286561 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.180986  286559 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825057.214391    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.217427  286574 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.245688  286579 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.265034  286581 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825057.325348    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.327977  286590 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.328451    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825057.332887  286599 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.348863  286601 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.245, 0.245\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.993)\n",
      "Non-dominant hand detected: False (confidence: 0.000)\n",
      "Face detected: True\n",
      "Total detection attempts: 3\n",
      "Saved failure screenshot: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000039_00m39s000ms_missing_NonDomHand.jpg\n",
      "Processing frame 40/65 (timestamp: 00m40s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825057.403543    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.407054  286606 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.431896  286613 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.447929  286607 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825057.538476    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.542056  286622 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.542952    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825057.548060  286624 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.567292  286629 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825057.598056    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.600655  286638 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.628131  286642 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.642578  286647 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "New best detection: dominant hand=1, non-dominant hand=0, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.350, 0.350\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825057.725913    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.728471  286654 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.729349    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825057.734006  286657 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.749987  286655 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825057.781068    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.783447  286670 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.849744  286671 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.866821  286680 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.245, 0.245\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.928)\n",
      "Non-dominant hand detected: False (confidence: 0.000)\n",
      "Face detected: True\n",
      "Total detection attempts: 3\n",
      "Saved failure screenshot: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000040_00m40s000ms_missing_NonDomHand.jpg\n",
      "Processing frame 41/65 (timestamp: 00m41s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825057.955870    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825057.958690  286688 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825057.959331    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825057.964042  286689 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825057.979228  286691 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825058.036143    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.039889  286704 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.062000  286705 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.076718  286713 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825058.142373    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.145308  286720 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.146045    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825058.153995  286724 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.179540  286727 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.992)\n",
      "Non-dominant hand detected: True (confidence: 0.997)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 42/65 (timestamp: 00m42s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825058.246934    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.250282  286736 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.274573  286738 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.287531  286743 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825058.363081    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.366434  286752 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.366798    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825058.371419  286756 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.387814  286758 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825058.438748    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.442545  286768 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.468613  286770 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.486516  286777 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.991)\n",
      "Non-dominant hand detected: True (confidence: 0.990)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 43/65 (timestamp: 00m43s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825058.577789    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.579847  286784 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.580459    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825058.585595  286788 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.602220  286791 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.990)\n",
      "Non-dominant hand detected: True (confidence: 0.992)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 44/65 (timestamp: 00m44s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825058.653962    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.658841  286800 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.688171  286808 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.845580  286805 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825058.929897    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825058.933733  286816 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825058.934339    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825058.944602  286817 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825058.961889  286818 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825059.020001    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.988)\n",
      "Non-dominant hand detected: True (confidence: 0.988)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 45/65 (timestamp: 00m45s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825059.023598  286832 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.044596  286834 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.064032  286835 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825059.153523    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.157401  286858 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.158460    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825059.164606  286871 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.182190  286866 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825059.235823    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.238733  286891 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.261319  286895 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.274799  286899 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.992)\n",
      "Non-dominant hand detected: True (confidence: 0.990)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 46/65 (timestamp: 00m46s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.988)\n",
      "Non-dominant hand detected: True (confidence: 0.985)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825059.339292    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.342449  286907 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.343147    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825059.348777  286911 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.364177  286919 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825059.422118    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.426900  286923 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.454423  286924 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.472534  286925 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 47/65 (timestamp: 00m47s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=0\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering face thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825059.587978    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.593389  286939 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.594409    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825059.600327  286941 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.639542  286946 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825059.667441    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.671114  286955 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.704362  286961 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.720489  286957 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825059.786610    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.788934  286971 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.789353    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825059.794518  286974 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.813075  286975 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering face thresholds: 0.245, 0.245\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825059.863260    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.866336  286987 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.886584  286995 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825059.902265  286999 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825059.986809    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825059.990534  287003 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825059.991555    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825059.995816  287007 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.012015  287009 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825060.073183    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.076690  287019 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.097858  287024 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.116259  287028 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.978)\n",
      "Non-dominant hand detected: True (confidence: 0.975)\n",
      "Face detected: False\n",
      "Total detection attempts: 3\n",
      "Saved failure screenshot: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000047_00m47s000ms_missing_Face.jpg\n",
      "Processing frame 48/65 (timestamp: 00m48s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825060.208631    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.211819  287035 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.212313    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825060.217318  287039 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.235988  287041 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825060.287768    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.290744  287051 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.315771  287052 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.331616  287059 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.966)\n",
      "Non-dominant hand detected: True (confidence: 0.993)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 49/65 (timestamp: 00m49s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825060.417789    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.421599  287067 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.422657    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825060.430162  287071 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.445569  287069 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825060.496085    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.499771  287083 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.528783  287089 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.547314  287085 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825060.613915    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.616419  287099 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.616939    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825060.622522  287104 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.640555  287106 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.970)\n",
      "Non-dominant hand detected: True (confidence: 0.994)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 50/65 (timestamp: 00m50s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.962)\n",
      "Non-dominant hand detected: True (confidence: 0.996)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 51/65 (timestamp: 00m51s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "New best detection: dominant hand=1, non-dominant hand=0, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825060.692582    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.695545  287115 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.720297  287118 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.739717  287117 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825060.832222    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.836061  287131 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.836661    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825060.845378  287133 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.864966  287136 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825060.920776    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825060.925736  287147 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825060.948713  287151 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825060.966619  287154 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.245, 0.245\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825061.049395    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.051395  287163 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.051904    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825061.061456  287164 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.078009  287170 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825061.114608    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.118317  287179 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.138303  287180 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.154479  287181 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825061.248969    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.252835  287196 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.253365    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825061.260075  287199 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.279848  287205 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.988)\n",
      "Non-dominant hand detected: True (confidence: 0.556)\n",
      "Face detected: True\n",
      "Total detection attempts: 3\n",
      "Processing frame 52/65 (timestamp: 00m52s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "New best detection: dominant hand=1, non-dominant hand=0, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825061.351060    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.354418  287238 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.378016  287243 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.393709  287248 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825061.441881    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.444695  287254 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.445121    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825061.449953  287255 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.465009  287258 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825061.503092    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.507210  287270 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.532704  287274 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.549795  287272 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.909)\n",
      "Non-dominant hand detected: True (confidence: 0.983)\n",
      "Face detected: True\n",
      "Total detection attempts: 2\n",
      "Processing frame 53/65 (timestamp: 00m53s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825061.632487    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.634836  287286 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.635320    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825061.640775  287289 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.665220  287287 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825061.720292    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.723736  287302 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.749427  287309 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.770830  287305 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825061.852615    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.856002  287318 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.856655    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825061.865869  287321 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.892454  287325 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825061.912415    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825061.915567  287334 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825061.968558  287339 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825061.984441  287335 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=0\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering face thresholds: 0.350, 0.350\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.980)\n",
      "Non-dominant hand detected: True (confidence: 0.992)\n",
      "Face detected: True\n",
      "Total detection attempts: 2\n",
      "Processing frame 54/65 (timestamp: 00m54s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825062.084162    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.087679  287350 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.088192    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825062.095172  287352 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.111596  287356 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825062.163710    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.166647  287366 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.196848  287370 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.213375  287368 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825062.289082    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.292641  287382 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.293267    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825062.297564  287383 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.319350  287391 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "New best detection: dominant hand=1, non-dominant hand=0, face=0\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.350, 0.350\n",
      "Lowering face thresholds: 0.350, 0.350\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825062.361683    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.364260  287398 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.394221  287400 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.411820  287404 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825062.481787    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.483850  287414 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.484295    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825062.489771  287415 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.534717  287421 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering non-dominant hand thresholds: 0.245, 0.245\n",
      "Lowering face thresholds: 0.245, 0.245\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825062.581055    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.585991  287430 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.629586  287438 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.650439  287434 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825062.734926    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.739518  287446 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.740491    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825062.749437  287451 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.776484  287453 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.967)\n",
      "Non-dominant hand detected: False (confidence: 0.000)\n",
      "Face detected: False\n",
      "Total detection attempts: 3\n",
      "Saved failure screenshot: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000054_00m54s000ms_missing_NonDomHand_Face.jpg\n",
      "Processing frame 55/65 (timestamp: 00m55s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825062.847161    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.851309  287462 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.879209  287464 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825062.895742  287465 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825062.975950    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825062.978931  287478 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825062.979716    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825062.984257  287480 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.001008  287479 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.047109    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.934)\n",
      "Non-dominant hand detected: True (confidence: 0.984)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 56/65 (timestamp: 00m56s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825063.050091  287494 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.073890  287498 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.088094  287501 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.183553    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.185874  287510 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.186403    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825063.193205  287513 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.215821  287516 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.269980    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.273001  287526 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.295186  287529 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.308607  287533 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.949)\n",
      "Non-dominant hand detected: True (confidence: 0.983)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n",
      "Processing frame 57/65 (timestamp: 00m57s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.955)\n",
      "Non-dominant hand detected: True (confidence: 0.972)\n",
      "Face detected: True\n",
      "Total detection attempts: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825063.387805    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.392395  287547 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.393567    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825063.398016  287548 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.417266  287549 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.460876    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.463378  287586 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.486472  287590 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.505846  287594 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.596827    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 58/65 (timestamp: 00m58s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=0\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering face thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825063.599401  287602 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.599870    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825063.603851  287605 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.620698  287604 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.655245    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.660258  287618 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.683668  287619 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.699668  287621 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.786705    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.789995  287634 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.790889    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825063.797396  287635 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.817913  287641 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering face thresholds: 0.245, 0.245\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825063.848924    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.852334  287650 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.874700  287654 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825063.890546  287652 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825063.985541    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825063.987831  287666 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825063.988608    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825063.994123  287669 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825064.010278  287674 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.947)\n",
      "Non-dominant hand detected: True (confidence: 0.712)\n",
      "Face detected: False\n",
      "Total detection attempts: 3\n",
      "Saved failure screenshot: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000058_00m58s000ms_missing_Face.jpg\n",
      "Processing frame 59/65 (timestamp: 00m59s000ms)\n",
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Right) detected: False\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=0, non-dominant hand=1, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering dominant hand thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825064.067506    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825064.070320  287682 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825064.097727  287684 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825064.113356  287688 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825064.178247    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825064.180623  287698 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825064.181075    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825064.185879  287700 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825064.203347  287705 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742825064.241945    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825064.245200  287714 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825064.265617  287723 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825064.283065  287722 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=1, non-dominant hand=1, face=1\n",
      "All body parts detected. Stopping early.\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: True (confidence: 0.979)\n",
      "Non-dominant hand detected: True (confidence: 0.992)\n",
      "Face detected: True\n",
      "Total detection attempts: 2\n",
      "\n",
      "===== PROCESSING SUMMARY =====\n",
      "Processed 30 frames\n",
      "Detection rates: Dom hand: 100.0%, Non-dom hand: 86.7%, Face: 86.7%\n",
      "All parts detected in 0.0% of frames\n",
      "Full statistics saved to: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/detection_statistics.json\n",
      "Results saved to: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742825064.376159    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742825064.378534  287730 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742825064.379035    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742825064.383217  287731 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742825064.400715  287739 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_video(video_path=video_path, adaptive_detect_func=adaptive_detect, hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                 min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5,\n",
    "                 min_face_detection_confidence=0.5, min_face_presence_confidence=0.5,\n",
    "                 num_hands=2, output_face_blendshapes=True,\n",
    "                 max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2, \n",
    "                 frame_step=1, start_time_seconds=30.2, end_time_seconds=60.4,\n",
    "                 save_failure_screenshots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = load_frame_data(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.78225894e-01, -1.12051611e+00,  5.50700526e-04],\n",
       "        [ 9.23391210e-01, -1.69236467e+00,  2.34009814e-03],\n",
       "        [ 1.46009249e+00, -1.71132881e+00,  4.30999184e-03],\n",
       "        [ 1.74048902e+00, -1.47164944e+00,  7.10542547e-03],\n",
       "        [ 1.49123479e+00, -8.30840850e-01,  2.45598587e-03],\n",
       "        [ 2.06346240e+00, -1.09711661e+00,  6.16572937e-03],\n",
       "        [ 2.29248242e+00, -1.23134490e+00,  1.00170448e-02],\n",
       "        [ 2.45311100e+00, -1.34790413e+00,  1.21544152e-02],\n",
       "        [ 1.50366696e+00, -9.97311730e-02,  2.38017133e-03],\n",
       "        [ 2.11294367e+00, -5.01373676e-01,  5.33142872e-03],\n",
       "        [ 2.35172676e+00, -7.40329178e-01,  7.30238575e-03],\n",
       "        [ 2.48626698e+00, -9.21343310e-01,  8.04091245e-03],\n",
       "        [ 1.42495309e+00,  4.93358436e-01,  2.41103559e-03],\n",
       "        [ 2.01319802e+00,  1.53102934e-01,  3.15418793e-03],\n",
       "        [ 2.29482777e+00, -9.26280119e-02,  3.09186196e-03],\n",
       "        [ 2.46820044e+00, -3.51395239e-01,  2.83384765e-03],\n",
       "        [ 1.27861771e+00,  9.91722120e-01,  2.59961025e-03],\n",
       "        [ 1.75536130e+00,  9.07970099e-01,  3.09095299e-03],\n",
       "        [ 2.01417722e+00,  7.35556885e-01,  3.50766769e-03],\n",
       "        [ 2.20831187e+00,  5.17613422e-01,  3.85514018e-03]]),\n",
       " array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " array([0.96831143, 0.        ]),\n",
       " array([1., 0.]),\n",
       " array([1, 0], dtype=int32),\n",
       " array([3.89331660e-07, 6.59370199e-02, 3.07529010e-02, 3.94524960e-03,\n",
       "        1.33815706e-01, 4.20857109e-02, 4.79124128e-06, 6.98092384e-09,\n",
       "        1.49434136e-08, 5.19186854e-01, 6.49316669e-01, 7.81828225e-01,\n",
       "        7.68505991e-01, 5.58714289e-03, 6.27394438e-01, 5.78723192e-01,\n",
       "        2.73099029e-03, 8.23191926e-03, 2.20236974e-03, 3.68438482e-01,\n",
       "        1.08378239e-01, 3.57891130e-03, 4.01785801e-04, 1.65319443e-06,\n",
       "        8.25532305e-04, 1.03109051e-03, 1.36425500e-04, 2.53144302e-04,\n",
       "        1.03865221e-01, 5.63669205e-01, 2.12032774e-07, 1.45632157e-07,\n",
       "        2.02249107e-03, 3.39190997e-02, 9.50012873e-06, 1.27252315e-06,\n",
       "        3.48293111e-02, 1.06384516e-01, 3.95396829e-01, 1.67541567e-03,\n",
       "        3.52382194e-03, 1.19923763e-02, 8.24288428e-01, 1.60771847e-01,\n",
       "        9.58534773e-04, 1.21539889e-03, 6.02621913e-05, 3.07644314e-06,\n",
       "        2.63699261e-03, 8.63122940e-03, 5.01809893e-07, 9.93437332e-09]),\n",
       " 1,\n",
       " array([[-0.44569474, 14.93033017],\n",
       "        [ 0.        ,  0.        ]]),\n",
       " 36,\n",
       " 36000)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interpolation_frames(x, nums_list):\n",
    "    \"\"\"\n",
    "    Returns integers in the range [x-5, x+5] that are not equal to x\n",
    "    and are not in nums_list.\n",
    "    \n",
    "    Args:\n",
    "        x (int): The reference integer\n",
    "        nums_list (list): A list of integers\n",
    "        \n",
    "    Returns:\n",
    "        list: Integers in [x-5, x+5] excluding x and elements in nums_list\n",
    "    \"\"\"\n",
    "    # Create the set of all integers in the range [x-5, x+5]\n",
    "    all_range = set(range(x-5, x+6))  # +6 because range is exclusive at upper bound\n",
    "    \n",
    "    # Remove x itself\n",
    "    all_range.discard(x)\n",
    "    \n",
    "    # Remove numbers that are in the input list\n",
    "    result = all_range - set(nums_list)\n",
    "    \n",
    "    # Convert back to a list and return\n",
    "    return sorted(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "def find_file_with_partial_name(partial_name, search_dir='.', recursive=False):\n",
    "    \"\"\"\n",
    "    Find files that start with the given partial name.\n",
    "    \n",
    "    Args:\n",
    "        partial_name (str): Partial file name to match\n",
    "        search_dir (str): Directory to search in (default: current directory)\n",
    "        recursive (bool): Whether to search in subdirectories\n",
    "        \n",
    "    Returns:\n",
    "        list: Complete paths of all matching files\n",
    "    \"\"\"\n",
    "    # Create a search pattern for files starting with the partial name\n",
    "    search_pattern = os.path.join(search_dir, f\"{partial_name}*\")\n",
    "    \n",
    "    # Use recursive glob if requested\n",
    "    if recursive:\n",
    "        matches = []\n",
    "        for root, _, _ in os.walk(search_dir):\n",
    "            matches.extend(glob.glob(os.path.join(root, f\"{os.path.basename(partial_name)}*\")))\n",
    "        return matches\n",
    "    else:\n",
    "        return glob.glob(search_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_numbers_on_both_sides(x, missing_numbers):\n",
    "    \"\"\"\n",
    "    Checks if the list of missing numbers has at least one number smaller than x\n",
    "    AND at least one number larger than x.\n",
    "    \n",
    "    Args:\n",
    "        x (int): The reference integer\n",
    "        missing_numbers (list): Output from find_missing_numbers(x, nums_list)\n",
    "        \n",
    "    Returns:\n",
    "        bool: False if all numbers are either all smaller or all larger than x.\n",
    "              True if there's at least one smaller and one larger number.\n",
    "    \"\"\"\n",
    "    has_smaller = False\n",
    "    has_larger = False\n",
    "    \n",
    "    for num in missing_numbers:\n",
    "        if num < x:\n",
    "            has_smaller = True\n",
    "        elif num > x:\n",
    "            has_larger = True\n",
    "            \n",
    "        # Early exit if we found both smaller and larger numbers\n",
    "        if has_smaller and has_larger:\n",
    "            return True\n",
    "    \n",
    "    # If we get here, we didn't find both smaller and larger numbers\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def modify_npz_file(file_path, modifications):\n",
    "    \"\"\"\n",
    "    Load a .npz file, modify specific arrays, and save it back.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .npz file\n",
    "        modifications (dict): Dictionary with keys as array names and values as new arrays\n",
    "                             or functions that take the original array and return a modified version\n",
    "    \n",
    "    Example:\n",
    "        modify_npz_file('data.npz', {\n",
    "            'array1': np.array([1, 2, 3]),  # Replace completely\n",
    "            'array2': lambda arr: arr * 2    # Modify using a function\n",
    "        })\n",
    "    \"\"\"\n",
    "    # Load the npz file\n",
    "    with np.load(file_path) as data:\n",
    "        # Create a copy of all arrays\n",
    "        arrays = {name: data[name] for name in data.files}\n",
    "    \n",
    "    # Apply modifications\n",
    "    for name, modification in modifications.items():\n",
    "        if name in arrays:\n",
    "            if callable(modification):\n",
    "                # If the modification is a function, apply it to the original array\n",
    "                arrays[name] = modification(arrays[name])\n",
    "            else:\n",
    "                # Otherwise, replace the array\n",
    "                arrays[name] = modification\n",
    "        else:\n",
    "            print(f\"Warning: Array '{name}' not found in the original file\")\n",
    "    \n",
    "    # Save back to the file with same format\n",
    "    np.savez(file_path, **arrays)\n",
    "    \n",
    "    print(f\"Successfully modified and saved {len(modifications)} arrays in {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_undetected_hand_landmarks(directory_path):  \n",
    "    \"\"\"\n",
    "    Interpolate landmarks for frames where hand detection failed.\n",
    "    \"\"\"\n",
    "    print(f\"Starting interpolation for directory: {directory_path}\")\n",
    "    \n",
    "    # Load detection statistics JSON\n",
    "    with open(os.path.join(directory_path, 'detection_statistics.json')) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    first_frame_number = round(data['video_info']['fps'] * data['video_info']['start_time'])\n",
    "    final_frame_number = round(data['video_info']['fps'] * data['video_info']['end_time'])\n",
    "    \n",
    "    print(f\"Processing frames range: {first_frame_number} to {final_frame_number}\")\n",
    "    \n",
    "    # Maximum possible sum of weights for normalization (when all 10 frames are available)\n",
    "    MAX_WEIGHT_SUM = 2.92722222\n",
    "    \n",
    "    # Process non-dominant hand failures\n",
    "    print(\"Processing non-dominant hand failures...\")\n",
    "    missing_non_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['non_dominant_hand_failures']]\n",
    "    \n",
    "    non_dom_interpolated_count = 0\n",
    "    \n",
    "    for missing_frame in data['failed_frames']['non_dominant_hand_failures']:\n",
    "        frame_number = missing_frame['frame']\n",
    "        filepath = missing_frame['file']\n",
    "        \n",
    "        # Only interpolate frames not at the edges of the video\n",
    "        if (frame_number - 5) <= first_frame_number or (frame_number + 5) >= final_frame_number:\n",
    "            print(f\"Skipping frame {frame_number} - too close to video boundary\")\n",
    "            continue\n",
    "        \n",
    "        # Find frames with valid detections for interpolation\n",
    "        interpolation_frames = find_interpolation_frames(frame_number, missing_non_dominant_frame_list)\n",
    "        \n",
    "        if not interpolation_frames:\n",
    "            print(f\"No valid frames found for interpolating frame {frame_number}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate interpolated landmarks\n",
    "        interpolation_weights_sum = 0\n",
    "        interpolated_coordinates = np.zeros(shape=(20, 3))\n",
    "        interpolated_wrist_to_nost = np.zeros(shape=(1, 2))\n",
    "        \n",
    "        for interp_frame in interpolation_frames:\n",
    "            weight = 1 / ((frame_number - interp_frame) ** 2)\n",
    "            interpolation_weights_sum += weight\n",
    "            \n",
    "            # Find and load the reference frame\n",
    "            interp_partial_filename = data['video_info']['name'] + f\"_frame{interp_frame:06d}\"\n",
    "            try:\n",
    "                interp_files = find_file_with_partial_name(\n",
    "                    interp_partial_filename, \n",
    "                    search_dir=directory_path, \n",
    "                    recursive=False\n",
    "                )\n",
    "                \n",
    "                if not interp_files:\n",
    "                    print(f\"Warning: Could not find file for frame {interp_frame}\")\n",
    "                    continue\n",
    "                    \n",
    "                interp_filepath = interp_files[0]\n",
    "                \n",
    "                # Load the frame data - index 1 for non-dominant hand landmarks\n",
    "                frame_data = load_frame_data(interp_filepath)\n",
    "                non_dom_landmarks = frame_data[1]  # Correct index for non-dominant hand\n",
    "                \n",
    "                \n",
    "                # Add weighted contribution\n",
    "                interpolated_coordinates += weight * non_dom_landmarks\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame {interp_frame}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Normalize by sum of weights (crucial step!)\n",
    "        if interpolation_weights_sum > 0:\n",
    "            interpolated_coordinates /= interpolation_weights_sum\n",
    "            \n",
    "            # Calculate confidence based on weights and frame distribution\n",
    "            has_frames_on_both_sides = has_numbers_on_both_sides(frame_number, interpolation_frames)\n",
    "            \n",
    "            if has_frames_on_both_sides:\n",
    "                interpolation_confidence = interpolation_weights_sum / MAX_WEIGHT_SUM\n",
    "            else:\n",
    "                interpolation_confidence = (interpolation_weights_sum / MAX_WEIGHT_SUM) * 0.8\n",
    "                \n",
    "            print(f\"Frame {frame_number}: Interpolated with confidence {interpolation_confidence:.2f}\")\n",
    "            \n",
    "            # Update the file with interpolated data\n",
    "            def update_interp_scores(arr):\n",
    "                new_arr = arr.copy()\n",
    "                new_arr[1] = interpolation_confidence  # Index 1 for non-dominant hand\n",
    "                return new_arr\n",
    "                \n",
    "            modifications = {\n",
    "                'non_dom_landmarks': interpolated_coordinates,\n",
    "                'interpolation_scores': update_interp_scores\n",
    "            }\n",
    "            \n",
    "            modify_npz_file(\n",
    "                file_path=os.path.join(directory_path, filepath),\n",
    "                modifications=modifications\n",
    "            )\n",
    "            \n",
    "            non_dom_interpolated_count += 1\n",
    "    \n",
    "    # Process dominant hand failures\n",
    "    print(f\"Interpolated {non_dom_interpolated_count} non-dominant hand frames\")\n",
    "    print(\"Processing dominant hand failures...\")\n",
    "    \n",
    "    missing_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['dominant_hand_failures']]\n",
    "    \n",
    "    dom_interpolated_count = 0\n",
    "    \n",
    "    for missing_frame in data['failed_frames']['dominant_hand_failures']:\n",
    "        frame_number = missing_frame['frame']\n",
    "        filepath = missing_frame['file']\n",
    "        \n",
    "        # Only interpolate frames not at the edges of the video\n",
    "        if (frame_number - 5) <= first_frame_number or (frame_number + 5) >= final_frame_number:\n",
    "            continue\n",
    "        \n",
    "        # Find frames with valid detections for interpolation\n",
    "        interpolation_frames = find_interpolation_frames(frame_number, missing_dominant_frame_list)\n",
    "        \n",
    "        if not interpolation_frames:\n",
    "            continue\n",
    "        \n",
    "        # Calculate interpolated landmarks\n",
    "        interpolation_weights_sum = 0\n",
    "        interpolated_coordinates = np.zeros(shape=(20, 3))\n",
    "        \n",
    "        for interp_frame in interpolation_frames:\n",
    "            weight = 1 / ((frame_number - interp_frame) ** 2)\n",
    "            interpolation_weights_sum += weight\n",
    "            \n",
    "            # Find and load the reference frame\n",
    "            interp_partial_filename = data['video_info']['name'] + f\"_frame{interp_frame:06d}\"\n",
    "            try:\n",
    "                interp_files = find_file_with_partial_name(\n",
    "                    interp_partial_filename, \n",
    "                    search_dir=directory_path, \n",
    "                    recursive=False\n",
    "                )\n",
    "                \n",
    "                if not interp_files:\n",
    "                    continue\n",
    "                    \n",
    "                interp_filepath = interp_files[0]\n",
    "                \n",
    "                # Load the frame data - index 0 for dominant hand landmarks\n",
    "                frame_data = load_frame_data(interp_filepath)\n",
    "                dom_landmarks = frame_data[0]  # Correct index for dominant hand\n",
    "                \n",
    "                # Add weighted contribution\n",
    "                interpolated_coordinates += weight * dom_landmarks\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing frame {interp_frame}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Normalize by sum of weights\n",
    "        if interpolation_weights_sum > 0:\n",
    "            interpolated_coordinates /= interpolation_weights_sum\n",
    "            \n",
    "            # Calculate confidence based on weights and frame distribution\n",
    "            has_frames_on_both_sides = has_numbers_on_both_sides(frame_number, interpolation_frames)\n",
    "            \n",
    "            if has_frames_on_both_sides:\n",
    "                interpolation_confidence = interpolation_weights_sum / MAX_WEIGHT_SUM\n",
    "            else:\n",
    "                interpolation_confidence = (interpolation_weights_sum / MAX_WEIGHT_SUM) * 0.8\n",
    "            \n",
    "            # Update the file with interpolated data\n",
    "            def update_interp_scores(arr):\n",
    "                new_arr = arr.copy()\n",
    "                new_arr[0] = interpolation_confidence  # Index 0 for dominant hand\n",
    "                return new_arr\n",
    "                \n",
    "            modifications = {\n",
    "                'dom_landmarks': interpolated_coordinates,\n",
    "                'interpolation_scores': update_interp_scores\n",
    "            }\n",
    "            \n",
    "            modify_npz_file(\n",
    "                file_path=os.path.join(directory_path, filepath),\n",
    "                modifications=modifications\n",
    "            )\n",
    "            \n",
    "            dom_interpolated_count += 1\n",
    "    \n",
    "    print(f\"Interpolated {dom_interpolated_count} dominant hand frames\")\n",
    "    print(f\"Total interpolated: {non_dom_interpolated_count + dom_interpolated_count} frames\")\n",
    "    \n",
    "    return non_dom_interpolated_count + dom_interpolated_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interpolation for directory: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Processing frames range: 30 to 60\n",
      "Processing non-dominant hand failures...\n",
      "Frame 36: Interpolated with confidence 0.94\n",
      "Successfully modified and saved 2 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\n",
      "Frame 39: Interpolated with confidence 0.62\n",
      "Successfully modified and saved 2 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000039_00m39s000ms.npz\n",
      "Frame 40: Interpolated with confidence 0.64\n",
      "Successfully modified and saved 2 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000040_00m40s000ms.npz\n",
      "Frame 54: Interpolated with confidence 1.00\n",
      "Successfully modified and saved 2 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000054_00m54s000ms.npz\n",
      "Interpolated 4 non-dominant hand frames\n",
      "Processing dominant hand failures...\n",
      "Interpolated 0 dominant hand frames\n",
      "Total interpolated: 4 frames\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolate_undetected_hand_landmarks(directory_path=\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = load_frame_data(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
