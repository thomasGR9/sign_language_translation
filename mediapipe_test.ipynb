{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_model_path = \"hand_landmarker.task\"\n",
    "face_model_path = \"face_landmarker.task\"\n",
    "photo_path = \"Screenshot from 2025-04-01 10-02-44.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "import tempfile\n",
    "\n",
    "class SuppressOutput:\n",
    "    \"\"\"\n",
    "    A context manager that suppresses stdout and stderr from C/C++ libraries.\n",
    "    This is a more aggressive approach than just Python's logging or environment variables.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Create a temporary file to redirect output\n",
    "        self.null_fds = [tempfile.TemporaryFile(mode='w+b') for _ in range(2)]\n",
    "        # Save the original file descriptors to restore later\n",
    "        self.save_fds = [os.dup(1), os.dup(2)]\n",
    "        \n",
    "    def __enter__(self):\n",
    "        # Redirect stdout and stderr to the null files\n",
    "        os.dup2(self.null_fds[0].fileno(), 1)\n",
    "        os.dup2(self.null_fds[1].fileno(), 2)\n",
    "        # Also redirect Python-level stdout/stderr\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        sys.stderr = open(os.devnull, 'w')\n",
    "        return self\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        # Restore normal stdout and stderr\n",
    "        for fd in self.null_fds:\n",
    "            fd.close()\n",
    "        for fd in range(2):\n",
    "            os.dup2(self.save_fds[fd], fd + 1)\n",
    "        for fd in self.save_fds:\n",
    "            os.close(fd)\n",
    "        # Restore Python-level stdout/stderr\n",
    "        sys.stdout = sys.__stdout__\n",
    "        sys.stderr = sys.__stderr__\n",
    "\n",
    "try:\n",
    "    import ctypes\n",
    "    libc = ctypes.CDLL(None)\n",
    "    # Attempt to get C's stdout/stderr file descriptor\n",
    "    c_stdout = ctypes.c_void_p.in_dll(libc, 'stdout')\n",
    "    c_stderr = ctypes.c_void_p.in_dll(libc, 'stderr')\n",
    "    devnull = open(os.devnull, 'w')\n",
    "    os.dup2(devnull.fileno(), c_stdout.value)\n",
    "    os.dup2(devnull.fileno(), c_stderr.value)\n",
    "except:\n",
    "    # If this approach fails, continue with other methods\n",
    "    pass\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0=all, 1=INFO, 2=WARNING, 3=ERROR\n",
    "logging.getLogger(\"mediapipe\").setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logging\n",
    "os.environ['GLOG_minloglevel'] = '3'      # Suppress Google logging (used by MediaPipe)\n",
    "os.environ['MEDIAPIPE_DISABLE_GPU'] = '1'  # Optional: Disable GPU logging messages\n",
    "\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = '0'\n",
    "# ABSL specific flags\n",
    "os.environ['ABSL_LOGGING_LEVEL'] = '50'  # Higher than any level that should be output\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "logging.getLogger(\"mediapipe\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"absl\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\\\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import time\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import glob\n",
    "import hashlib\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed, ThreadPoolExecutor\n",
    "from tqdm import tqdm \n",
    "import multiprocessing\n",
    "import psutil\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image_path, hand_model_path, face_model_path, min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, min_face_detection_confidence=0.5, min_face_presence_confidence=0.5, num_hands=2, dominand_hand='Right', visualize=False, output_face_blendshapes=True, adaptive_threshold=True, max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Detects hands and face in an image, extracts hand landmark coordinates and face blendshapes.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        min_hand_detection_confidence (float): Confidence threshold for hand detection (0.0-1.0)\n",
    "        min_hand_presence_confidence (float): Confidence threshold for hand presence (0.0-1.0)\n",
    "        num_hands (int): Maximum number of hands to detect\n",
    "        dominand_hand (str): Dominant hand preference ('Left' or 'Right')\n",
    "        visualize (bool): Whether to visualize the results\n",
    "        output_face_blendshapes (bool): Whether to detect and extract face blendshapes\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (dom_landmarks, non_dom_landmarks, wrists, confidence_scores, detection_status, \n",
    "                blendshape_scores, face_landmark_5, face_detected)\n",
    "               - dom_landmarks: NumPy array of shape [20, 3] with coordinates of dominant hand landmarks\n",
    "               - non_dom_landmarks: NumPy array of shape [20, 3] with coordinates of non-dominant hand landmarks\n",
    "               - wrists: NumPy array of shape [2, 2] with coordinates of both wrists [x, y]\n",
    "               - confidence_scores: NumPy array of shape [2] with confidence scores [dominant_hand, non_dominant_hand]\n",
    "               - detection_status: NumPy array of shape [2] with binary detection status [dominant_hand, non_dominant_hand]\n",
    "               - blendshape_scores: NumPy array of shape [26] with selected face blendshape scores\n",
    "               - face_landmark_5: NumPy array of shape [2] with coordinates of the 5th face landmark [x, y]\n",
    "               - face_detected: Binary value (1 if face detected, 0 if not)\n",
    "    \"\"\"\n",
    "    # Initialize output arrays for face detection\n",
    "    blendshape_scores = np.zeros(52)\n",
    "    nose_landmark = np.zeros(2)\n",
    "    left_eye_landmark = np.zeros(2)\n",
    "    right_eye_landmark = np.zeros(2)\n",
    "    face_detected = 0\n",
    "    \n",
    "    # PART 1: HAND LANDMARK DETECTION\n",
    "    # 1.1: Configure the hand landmarker\n",
    "    hand_base_options = python.BaseOptions(\n",
    "        model_asset_path=hand_model_path\n",
    "    )\n",
    "\n",
    "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "    # Configure detection options\n",
    "    hand_options = vision.HandLandmarkerOptions(\n",
    "        base_options=hand_base_options,\n",
    "        num_hands=num_hands,                             \n",
    "        min_hand_detection_confidence=min_hand_detection_confidence,       \n",
    "        min_hand_presence_confidence=min_hand_presence_confidence,        \n",
    "        min_tracking_confidence=0.5,             \n",
    "        running_mode=VisionRunningMode.IMAGE\n",
    "    )\n",
    "\n",
    "    # Create the hand detector\n",
    "    hand_detector = vision.HandLandmarker.create_from_options(hand_options)\n",
    "\n",
    "    # 1.2: Load the input image\n",
    "    image = mp.Image.create_from_file(image_path)\n",
    "\n",
    "    # 1.3: Detect hand landmarks\n",
    "    hand_detection_result = hand_detector.detect(image)\n",
    "    \n",
    "    # Initialize hand output arrays with zeros\n",
    "    dom_landmarks = np.zeros((20, 3))       # 20 landmarks (excluding wrist), [x,y,z]\n",
    "    non_dom_landmarks = np.zeros((20, 3))   # 20 landmarks (excluding wrist), [x,y,z]\n",
    "    wrists = np.zeros((2, 2))               # 2 wrists, [x,y]\n",
    "    confidence_scores = np.zeros(2)         # Confidence scores for [dominant, non-dominant]\n",
    "    interpolation_scores = np.zeros(2) #Interpolation scores for [dominant, non-dominant]. Used later.\n",
    "    detection_status = np.zeros(2, dtype=np.int32)  # Binary detection status [dominant, non-dominant]\n",
    "    nose_to_wrist_dist = np.zeros((2, 2))\n",
    "    \n",
    "    # 1.4: Process hand landmarks if hands are detected\n",
    "    if hand_detection_result.hand_landmarks and hand_detection_result.handedness:\n",
    "        dom_hand_found = False\n",
    "        non_dom_hand_found = False\n",
    "        \n",
    "        # First, find the dominant and non-dominant hands in detection results\n",
    "        for idx, handedness in enumerate(hand_detection_result.handedness):\n",
    "            hand_type = handedness[0].category_name  # 'Left' or 'Right'\n",
    "            hand_score = handedness[0].score  # Confidence score for the handedness classification\n",
    "            \n",
    "            if hand_type == dominand_hand:\n",
    "                # This is the dominant hand\n",
    "                dom_hand_found = True\n",
    "                detection_status[0] = 1  # Set detection status to 1 (detected)\n",
    "                confidence_scores[0] = hand_score  # Store confidence score\n",
    "                interpolation_scores[0] = 1\n",
    "                \n",
    "                # Store dominant hand wrist coordinates [x,y]\n",
    "                dom_hand_landmarks = hand_detection_result.hand_landmarks[idx]\n",
    "                wrists[0, 0] = dom_hand_landmarks[0].x\n",
    "                wrists[0, 1] = dom_hand_landmarks[0].y\n",
    "                \n",
    "                # Store all other dominant hand landmarks (excluding wrist)\n",
    "                for i in range(1, 21):  # Landmarks 1-20 (skipping wrist which is index 0)\n",
    "                    dom_landmarks[i-1, 0] = dom_hand_landmarks[i].x\n",
    "                    dom_landmarks[i-1, 1] = dom_hand_landmarks[i].y\n",
    "                    dom_landmarks[i-1, 2] = dom_hand_landmarks[i].z\n",
    "                    \n",
    "            elif hand_type != dominand_hand:\n",
    "                # This is the non-dominant hand\n",
    "                non_dom_hand_found = True\n",
    "                detection_status[1] = 1  # Set detection status to 1 (detected)\n",
    "                confidence_scores[1] = hand_score  # Store confidence score\n",
    "                interpolation_scores[1] = 1\n",
    "                \n",
    "                # Store non-dominant hand wrist coordinates [x,y]\n",
    "                non_dom_hand_landmarks = hand_detection_result.hand_landmarks[idx]\n",
    "                wrists[1, 0] = non_dom_hand_landmarks[0].x\n",
    "                wrists[1, 1] = non_dom_hand_landmarks[0].y\n",
    "                \n",
    "                # Store all other non-dominant hand landmarks (excluding wrist)\n",
    "                for i in range(1, 21):  # Landmarks 1-20 (skipping wrist)\n",
    "                    non_dom_landmarks[i-1, 0] = non_dom_hand_landmarks[i].x\n",
    "                    non_dom_landmarks[i-1, 1] = non_dom_hand_landmarks[i].y\n",
    "                    non_dom_landmarks[i-1, 2] = non_dom_hand_landmarks[i].z\n",
    "                    \n",
    "        # Log information about which hands were found\n",
    "        print(f\"Dominant hand ({dominand_hand}) detected: {dom_hand_found}\")\n",
    "        print(f\"Non-dominant hand detected: {non_dom_hand_found}\")\n",
    "    \n",
    "\n",
    "   # PART 2: FACE LANDMARK DETECTION (If requested)\n",
    "    if output_face_blendshapes:\n",
    "        try:\n",
    "            # 2.1: Configure the face landmarker\n",
    "            face_base_options = python.BaseOptions(\n",
    "                model_asset_path=face_model_path\n",
    "            )\n",
    "            \n",
    "            # Configure face detection options\n",
    "            face_options = vision.FaceLandmarkerOptions(\n",
    "                base_options=face_base_options,\n",
    "                min_face_detection_confidence=min_face_detection_confidence,\n",
    "                min_face_presence_confidence=min_face_presence_confidence,\n",
    "                output_face_blendshapes=True,\n",
    "                num_faces=1,\n",
    "                running_mode=VisionRunningMode.IMAGE\n",
    "            )\n",
    "            \n",
    "            # Create the face detector\n",
    "            face_detector = vision.FaceLandmarker.create_from_options(face_options)\n",
    "            \n",
    "            # 2.2: Detect face landmarks (reuse the same image)\n",
    "            face_detection_result = face_detector.detect(image)\n",
    "            \n",
    "            # 2.3: Process face blendshapes if face is detected\n",
    "            if (face_detection_result.face_blendshapes and len(face_detection_result.face_blendshapes) > 0 and\n",
    "                face_detection_result.face_landmarks and len(face_detection_result.face_landmarks) > 0):\n",
    "                \n",
    "                # Set face detected flag to 1\n",
    "                face_detected = 1\n",
    "                \n",
    "                # Get all blendshapes from the first face\n",
    "                all_blendshapes = face_detection_result.face_blendshapes[0]\n",
    "                \n",
    "                # Initialize blendshape_scores with the correct size to hold all blendshapes\n",
    "                # Assuming MediaPipe returns all 52 blendshapes\n",
    "                blendshape_scores = np.zeros(len(all_blendshapes))\n",
    "                \n",
    "                # Fill the blendshape_scores array with ALL scores\n",
    "                for i in range(len(all_blendshapes)):\n",
    "                    blendshape_scores[i] = all_blendshapes[i].score\n",
    "                \n",
    "                # Get nose coordinates\n",
    "                nose = face_detection_result.face_landmarks[0][4]\n",
    "                nose_landmark[0] = nose.x\n",
    "                nose_landmark[1] = nose.y\n",
    "    \n",
    "                # Get eye coordinates\n",
    "                left_eye = face_detection_result.face_landmarks[0][473]\n",
    "                left_eye_landmark[0] = left_eye.x\n",
    "                left_eye_landmark[1] = left_eye.y\n",
    "    \n",
    "                right_eye = face_detection_result.face_landmarks[0][468]\n",
    "                right_eye_landmark[0] = right_eye.x\n",
    "                right_eye_landmark[1] = right_eye.y\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during face detection: {e}\")\n",
    "            # Keep default zero values for face outputs if detection fails\n",
    "    \n",
    "    \n",
    "    \n",
    "    # PART 3: VISUALIZATION\n",
    "    if visualize:\n",
    "        # Load the image with OpenCV for visualization\n",
    "        img_cv = cv2.imread(image_path)\n",
    "        img_height, img_width, _ = img_cv.shape\n",
    "\n",
    "        # 3.1: Draw hand landmarks if hands are detected\n",
    "        if hand_detection_result.hand_landmarks:\n",
    "            print(f\"Visualizing {len(hand_detection_result.hand_landmarks)} hands\")\n",
    "            \n",
    "            # Define connections between landmarks for hand skeleton\n",
    "            connections = [\n",
    "                # Thumb connections\n",
    "                (0, 1), (1, 2), (2, 3), (3, 4),\n",
    "                # Index finger connections\n",
    "                (0, 5), (5, 6), (6, 7), (7, 8),\n",
    "                # Middle finger connections\n",
    "                (0, 9), (9, 10), (10, 11), (11, 12),\n",
    "                # Ring finger connections\n",
    "                (0, 13), (13, 14), (14, 15), (15, 16),\n",
    "                # Pinky finger connections\n",
    "                (0, 17), (17, 18), (18, 19), (19, 20),\n",
    "                # Palm connections\n",
    "                (0, 5), (5, 9), (9, 13), (13, 17)\n",
    "            ]\n",
    "            \n",
    "            for idx, hand_landmarks in enumerate(hand_detection_result.hand_landmarks):\n",
    "                # Determine if this is the dominant hand\n",
    "                is_dominant = False\n",
    "                if hand_detection_result.handedness:\n",
    "                    hand_type = hand_detection_result.handedness[idx][0].category_name\n",
    "                    is_dominant = (hand_type == dominand_hand)\n",
    "                \n",
    "                # Use different colors for dominant vs non-dominant hand\n",
    "                hand_color = (0, 0, 255) if is_dominant else (255, 0, 0)  # Blue for dominant, Red for non-dominant\n",
    "                \n",
    "                # Draw all landmark points\n",
    "                for landmark in hand_landmarks:\n",
    "                    # Convert normalized coordinates to pixel coordinates\n",
    "                    x = int(landmark.x * img_width)\n",
    "                    y = int(landmark.y * img_height)\n",
    "                    \n",
    "                    # Draw the landmark point\n",
    "                    cv2.circle(img_cv, (x, y), 5, hand_color, -1)\n",
    "                \n",
    "                # Draw connections between landmarks (hand skeleton)\n",
    "                for connection in connections:\n",
    "                    start_idx, end_idx = connection\n",
    "                    \n",
    "                    if start_idx < len(hand_landmarks) and end_idx < len(hand_landmarks):\n",
    "                        start_point = hand_landmarks[start_idx]\n",
    "                        end_point = hand_landmarks[end_idx]\n",
    "                        \n",
    "                        # Convert normalized coordinates to pixel coordinates\n",
    "                        start_x = int(start_point.x * img_width)\n",
    "                        start_y = int(start_point.y * img_height)\n",
    "                        end_x = int(end_point.x * img_width)\n",
    "                        end_y = int(end_point.y * img_height)\n",
    "                        \n",
    "                        # Draw the connection line\n",
    "                        cv2.line(img_cv, (start_x, start_y), (end_x, end_y), hand_color, 2)\n",
    "                \n",
    "                # Add hand type label (Left/Right, Dominant/Non-dominant)\n",
    "                if hand_detection_result.handedness:\n",
    "                    handedness = hand_detection_result.handedness[idx]\n",
    "                    hand_type = handedness[0].category_name  # 'Left' or 'Right'\n",
    "                    hand_score = handedness[0].score\n",
    "                    dom_status = \"Dominant\" if hand_type == dominand_hand else \"Non-dominant\"\n",
    "                    cv2.putText(img_cv, f\"{hand_type} Hand - {dom_status} ({hand_score:.2f})\", \n",
    "                            (10, 30 + idx * 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.8, hand_color, 2)\n",
    "                    \n",
    "                    # Calculate and draw a bounding box\n",
    "                    x_coords = [landmark.x for landmark in hand_landmarks]\n",
    "                    y_coords = [landmark.y for landmark in hand_landmarks]\n",
    "                    min_x, max_x = min(x_coords), max(x_coords)\n",
    "                    min_y, max_y = min(y_coords), max(y_coords)\n",
    "                    \n",
    "                    # Convert to pixel coordinates\n",
    "                    min_x, max_x = int(min_x * img_width), int(max_x * img_width)\n",
    "                    min_y, max_y = int(min_y * img_height), int(max_y * img_height)\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    cv2.rectangle(img_cv, (min_x, min_y), (max_x, max_y), hand_color, 2)\n",
    "\n",
    "        # 3.2: Draw Nose if face was detected\n",
    "        if face_detected == 1:\n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            face_x = int(nose_landmark[0] * img_width)\n",
    "            face_y = int(nose_landmark[1] * img_height)\n",
    "            \n",
    "            # Draw the Nose with a distinctive color and size\n",
    "            cv2.circle(img_cv, (face_x, face_y), 8, (0, 255, 255), -1)  # Yellow circle\n",
    "            cv2.putText(img_cv, \"Nose\", (face_x + 10, face_y), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            # Draw eyes\n",
    "            left_eye_x = int(left_eye_landmark[0] * img_width)\n",
    "            left_eye_y = int(left_eye_landmark[1] * img_height)\n",
    "            right_eye_x = int(right_eye_landmark[0] * img_width)\n",
    "            right_eye_y = int(right_eye_landmark[1] * img_height)\n",
    "            \n",
    "            cv2.circle(img_cv, (left_eye_x, left_eye_y), 6, (255, 255, 0), -1)  # Cyan circle\n",
    "            cv2.circle(img_cv, (right_eye_x, right_eye_y), 6, (255, 255, 0), -1)  # Cyan circle\n",
    "            cv2.line(img_cv, (left_eye_x, left_eye_y), (right_eye_x, right_eye_y), (255, 255, 0), 2)\n",
    "        # 3.3: Add detection status information to visualization\n",
    "        y_pos = img_height - 80\n",
    "        hand_status_text = f\"Hand Detection: Dom={detection_status[0]}, Non-Dom={detection_status[1]}\"\n",
    "        hand_conf_text = f\"Hand Confidence: Dom={confidence_scores[0]:.2f}, Non-Dom={confidence_scores[1]:.2f}\"\n",
    "        face_status_text = f\"Face Detection: {face_detected}\"\n",
    "        \n",
    "        cv2.putText(img_cv, hand_status_text, (10, y_pos), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(img_cv, hand_conf_text, (10, y_pos + 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        cv2.putText(img_cv, face_status_text, (10, y_pos + 60), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        # 3.4: Display the result\n",
    "        cv2.imshow('Hand and Face Landmarks', img_cv)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    if face_detected==1:\n",
    "        #Calculate distance between the eyes\n",
    "        eyes_diff = right_eye_landmark-left_eye_landmark\n",
    "        eyes_distance = np.sqrt(eyes_diff.dot(eyes_diff))\n",
    "        if detection_status[0]==1 and detection_status[1]==1:\n",
    "            nose_to_wrist_dist = (wrists-nose_landmark) / eyes_distance\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the eye's distance\n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / eyes_distance\n",
    "            non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[1, :]) / eyes_distance\n",
    "        elif detection_status[0]==1 and detection_status[1]==0:\n",
    "            nose_to_wrist_dist[0, :] = (wrists[0, :]-nose_landmark) / eyes_distance\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the eye's distance\n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / eyes_distance\n",
    "        elif detection_status[0]==0 and detection_status[1]==1:\n",
    "            nose_to_wrist_dist[1,:] = (wrists[1,:]-nose_landmark) / eyes_distance\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the eye's distance\n",
    "            non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[0, :]) / eyes_distance\n",
    "        \n",
    "    elif face_detected==0 and detection_status[0]==1:\n",
    "        #Calculate palm width distance as fallback scaling factor\n",
    "        palm_width_diff = dom_landmarks[5, :]- dom_landmarks[17, :]\n",
    "        palm_width_dist = np.sqrt(palm_width_diff.dot(palm_width_diff))\n",
    "        if detection_status[1]==1:\n",
    "            nose_to_wrist_dist = (wrists-nose_landmark) / palm_width_dist\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the palm width \n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / palm_width_dist\n",
    "            non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[1, :]) / palm_width_dist\n",
    "        elif detection_status[1]==0:\n",
    "            nose_to_wrist_dist[0,:] = (wrists[0,:]-nose_landmark) / palm_width_dist\n",
    "            #Make every hand's landmark potision relative to the wrist, and scaled by the palm width \n",
    "            dom_landmarks[:, 0:2] = (dom_landmarks[:, 0:2] - wrists[0, :]) / palm_width_dist\n",
    "    elif face_detected==0 and detection_status[0]==0 and detection_status[1]==1:\n",
    "        #Calculate palm width distance as fallback scaling factor\n",
    "        palm_width_diff = non_dom_landmarks[5, :]- non_dom_landmarks[17, :]\n",
    "        palm_width_dist = np.sqrt(palm_width_diff.dot(palm_width_diff))\n",
    "        nose_to_wrist_dist[1,:] = (wrists[1,:]-nose_landmark) / palm_width_dist\n",
    "        #Make every hand's landmark potision relative to the wrist, and scaled by the palm width \n",
    "        non_dom_landmarks[:, 0:2] = (non_dom_landmarks[:, 0:2] - wrists[1, :]) / palm_width_dist\n",
    "    \n",
    "\n",
    "    \n",
    "    # Return all requested outputs\n",
    "    return dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743496270.375183   15687 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743496270.474735   15725 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 560.28.03), renderer: NVIDIA GeForce RTX 3060/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1743496270.501183   15728 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743496270.518936   15734 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743496270.566415   15729 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "I0000 00:00:1743496270.566851   15687 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1743496270.646873   15739 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 560.28.03), renderer: NVIDIA GeForce RTX 3060/PCIe/SSE2\n",
      "W0000 00:00:1743496270.647184   15687 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1743496270.654167   15742 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1743496270.678560   15752 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: False\n",
      "Visualizing 1 hands\n"
     ]
    }
   ],
   "source": [
    "lol = detect(photo_path, hand_model_path, face_model_path, min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, num_hands=2, dominand_hand='Right', visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lol[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_detect(image_path, hand_model_path, face_model_path, min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, \n",
    "                   min_face_detection_confidence=0.5, min_face_presence_confidence=0.5, \n",
    "                   num_hands=2, dominand_hand='Right', visualize=False, output_face_blendshapes=True,\n",
    "                   max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Adaptively detects hands and face by progressively lowering detection thresholds\n",
    "    for undetected body parts.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        min_hand_detection_confidence (float): Initial confidence threshold for hand detection\n",
    "        min_hand_presence_confidence (float): Initial confidence threshold for hand presence\n",
    "        min_face_detection_confidence (float): Initial confidence threshold for face detection\n",
    "        min_face_presence_confidence (float): Initial confidence threshold for face presence\n",
    "        num_hands (int): Maximum number of hands to detect\n",
    "        dominand_hand (str): Dominant hand preference ('Left' or 'Right')\n",
    "        visualize (bool): Whether to visualize the final results\n",
    "        output_face_blendshapes (bool): Whether to detect and extract face blendshapes\n",
    "        max_attempts (int): Maximum number of detection attempts with lowered thresholds\n",
    "        threshold_reduction_factor (float): Factor to multiply thresholds by on each attempt (0-1)\n",
    "        min_threshold (float): Minimum threshold to prevent excessive lowering\n",
    "        \n",
    "    Returns:\n",
    "        Same output as the detect() function\n",
    "    \"\"\"\n",
    "    # Import the original detect function\n",
    "    #from your_module import detect  # Replace with actual module name\n",
    "    \n",
    "    # Store original thresholds\n",
    "    orig_hand_detection_conf = min_hand_detection_confidence\n",
    "    orig_hand_presence_conf = min_hand_presence_confidence\n",
    "    orig_face_detection_conf = min_face_detection_confidence\n",
    "    orig_face_presence_conf = min_face_presence_confidence\n",
    "    \n",
    "    # Initialize best results and detection status\n",
    "    best_results = None\n",
    "    best_detection_status = [0, 0]  # [dom_hand, non_dom_hand]\n",
    "    best_face_detected = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    # Try detection with progressively lower thresholds\n",
    "    for attempt in range(max_attempts):\n",
    "        print(f\"\\n--- Attempt {attempt+1}/{max_attempts} ---\")\n",
    "        \n",
    "        # Calculate current thresholds\n",
    "        if attempt > 0:\n",
    "            # Only lower thresholds for undetected parts\n",
    "            # For hands\n",
    "            if best_detection_status[0] == 0:  # Dominant hand not detected\n",
    "                hand_detection_conf_dom = max(orig_hand_detection_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                hand_presence_conf_dom = max(orig_hand_presence_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                print(f\"Lowering dominant hand thresholds: {hand_detection_conf_dom:.3f}, {hand_presence_conf_dom:.3f}\")\n",
    "            else:\n",
    "                hand_detection_conf_dom = orig_hand_detection_conf\n",
    "                hand_presence_conf_dom = orig_hand_presence_conf\n",
    "                \n",
    "            if best_detection_status[1] == 0:  # Non-dominant hand not detected\n",
    "                hand_detection_conf_non_dom = max(orig_hand_detection_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                hand_presence_conf_non_dom = max(orig_hand_presence_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                print(f\"Lowering non-dominant hand thresholds: {hand_detection_conf_non_dom:.3f}, {hand_presence_conf_non_dom:.3f}\")\n",
    "            else:\n",
    "                hand_detection_conf_non_dom = orig_hand_detection_conf\n",
    "                hand_presence_conf_non_dom = orig_hand_presence_conf\n",
    "            \n",
    "            # Use the minimum of the two calculated thresholds (MediaPipe doesn't support per-hand thresholds)\n",
    "            current_hand_detection_conf = min(hand_detection_conf_dom, hand_detection_conf_non_dom)\n",
    "            current_hand_presence_conf = min(hand_presence_conf_dom, hand_presence_conf_non_dom)\n",
    "            \n",
    "            # For face\n",
    "            if output_face_blendshapes and best_face_detected == 0:  # Face not detected\n",
    "                current_face_detection_conf = max(orig_face_detection_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                current_face_presence_conf = max(orig_face_presence_conf * (threshold_reduction_factor ** attempt), min_threshold)\n",
    "                print(f\"Lowering face thresholds: {current_face_detection_conf:.3f}, {current_face_presence_conf:.3f}\")\n",
    "            else:\n",
    "                current_face_detection_conf = orig_face_detection_conf\n",
    "                current_face_presence_conf = orig_face_presence_conf\n",
    "        else:\n",
    "            # Use original thresholds for first attempt\n",
    "            current_hand_detection_conf = orig_hand_detection_conf\n",
    "            current_hand_presence_conf = orig_hand_presence_conf\n",
    "            current_face_detection_conf = orig_face_detection_conf\n",
    "            current_face_presence_conf = orig_face_presence_conf\n",
    "            print(f\"Using original thresholds: hands={current_hand_detection_conf}, face={current_face_detection_conf}\")\n",
    "        \n",
    "        # Call detect with current thresholds (don't visualize intermediate attempts)\n",
    "        results = detect(image_path,  hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                        min_hand_detection_confidence=current_hand_detection_conf,\n",
    "                        min_hand_presence_confidence=current_hand_presence_conf,\n",
    "                        min_face_detection_confidence=current_face_detection_conf,\n",
    "                        min_face_presence_confidence=current_face_presence_conf,\n",
    "                        num_hands=num_hands,\n",
    "                        dominand_hand=dominand_hand,\n",
    "                        visualize=False,\n",
    "                        output_face_blendshapes=output_face_blendshapes)\n",
    "        \n",
    "        # Unpack results\n",
    "        dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = results\n",
    "        \n",
    "        # Compare with best results so far\n",
    "        current_detection_count = detection_status[0] + detection_status[1] + face_detected\n",
    "        best_detection_count = best_detection_status[0] + best_detection_status[1] + best_face_detected\n",
    "        \n",
    "        if best_results is None or current_detection_count > best_detection_count:\n",
    "            best_results = results\n",
    "            best_detection_status = [detection_status[0], detection_status[1]]\n",
    "            best_face_detected = face_detected\n",
    "            \n",
    "            print(f\"New best detection: dominant hand={detection_status[0]}, \"\n",
    "                  f\"non-dominant hand={detection_status[1]}, face={face_detected}\")\n",
    "            \n",
    "            # If everything is detected, we can stop early\n",
    "            if detection_status[0] == 1 and detection_status[1] == 1 and (face_detected == 1 or not output_face_blendshapes):\n",
    "                print(\"All body parts detected. Stopping early.\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"No improvement in detection. Continuing to next attempt.\")\n",
    "    \n",
    "    # Run final detection with visualization if requested\n",
    "    if visualize:\n",
    "        print(\"\\n--- Visualizing final results ---\")\n",
    "        # Call detect one more time with the parameters that gave best results, but with visualize=True\n",
    "        # For simplicity, we'll just use the best thresholds we found\n",
    "        # This is slightly inefficient (one extra detection) but keeps the code clean\n",
    "        \n",
    "        # Determine which thresholds gave the best results\n",
    "        if best_detection_status[0] == 0:  # If dominant hand not detected in best result\n",
    "            hand_detection_conf = min_threshold\n",
    "            hand_presence_conf = min_threshold\n",
    "        else:\n",
    "            hand_detection_conf = orig_hand_detection_conf\n",
    "            hand_presence_conf = orig_hand_presence_conf\n",
    "            \n",
    "        if output_face_blendshapes and best_face_detected == 0:  # If face not detected in best result\n",
    "            face_detection_conf = min_threshold\n",
    "            face_presence_conf = min_threshold\n",
    "        else:\n",
    "            face_detection_conf = orig_face_detection_conf\n",
    "            face_presence_conf = orig_face_presence_conf\n",
    "        \n",
    "        # Run final detection with visualization\n",
    "        final_results = detect(image_path, hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                              min_hand_detection_confidence=hand_detection_conf,\n",
    "                              min_hand_presence_confidence=hand_presence_conf, \n",
    "                              min_face_detection_confidence=face_detection_conf,\n",
    "                              min_face_presence_confidence=face_presence_conf,\n",
    "                              num_hands=num_hands,\n",
    "                              dominand_hand=dominand_hand,\n",
    "                              visualize=True,\n",
    "                              output_face_blendshapes=output_face_blendshapes)\n",
    "        \n",
    "        # Use these results if they're better than our best so far\n",
    "        dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = final_results\n",
    "        current_detection_count = detection_status[0] + detection_status[1] + face_detected\n",
    "        best_detection_count = best_detection_status[0] + best_detection_status[1] + best_face_detected\n",
    "        \n",
    "        if current_detection_count > best_detection_count:\n",
    "            best_results = final_results\n",
    "    \n",
    "    # Print final detection summary\n",
    "    print(\"\\n=== Detection Summary ===\")\n",
    "    dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = best_results\n",
    "    print(f\"Dominant hand detected: {detection_status[0] == 1} (confidence: {confidence_scores[0]:.3f})\")\n",
    "    print(f\"Non-dominant hand detected: {detection_status[1] == 1} (confidence: {confidence_scores[1]:.3f})\")\n",
    "    if output_face_blendshapes:\n",
    "        print(f\"Face detected: {face_detected == 1}\")\n",
    "    print(f\"Total detection attempts: {attempt+1}\")\n",
    "    return best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Attempt 1/3 ---\n",
      "Using original thresholds: hands=0.5, face=0.5\n",
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n",
      "New best detection: dominant hand=0, non-dominant hand=1, face=1\n",
      "\n",
      "--- Attempt 2/3 ---\n",
      "Lowering dominant hand thresholds: 0.350, 0.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742824986.936870    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824986.940818  284930 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.039888  284934 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.056971  284940 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.133708    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.135590  284946 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.136250    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.142800  284947 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.160368  284950 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.199556    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.202131  284962 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.238721  284964 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.252189  284966 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Attempt 3/3 ---\n",
      "Lowering dominant hand thresholds: 0.245, 0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742824987.304140    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.307504  284978 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.308167    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.314875  284980 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.507001  284979 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.543464    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.547164  284994 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.568495  284996 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.686856  285000 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n",
      "No improvement in detection. Continuing to next attempt.\n",
      "\n",
      "--- Visualizing final results ---\n",
      "Dominant hand (Left) detected: False\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742824987.738748    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.741043  285010 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.741756    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.750388  285011 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.779803  285022 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.819273    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.822941  285026 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.853940  285027 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.874366  285035 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1742824987.927914    4103 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1742824987.931627  285064 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1742824987.932330    4103 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1742824987.944897  285072 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1742824987.965721  285078 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing 1 hands\n",
      "\n",
      "=== Detection Summary ===\n",
      "Dominant hand detected: False (confidence: 0.000)\n",
      "Non-dominant hand detected: True (confidence: 0.948)\n",
      "Face detected: True\n",
      "Total detection attempts: 3\n"
     ]
    }
   ],
   "source": [
    "best_results = adaptive_detect(without_left_hand_path, hand_model_path=hand_model_path, face_model_path=face_model_path,  min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5, num_hands=2, dominand_hand='Left', visualize=True,output_face_blendshapes=True,max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dom_landmarks, non_dom_landmarks, confidence_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]),\n",
       " array([[ 4.4302598 ,  5.79258936, -0.01529764],\n",
       "        [ 4.97843194,  5.60716573, -0.03023903],\n",
       "        [ 5.4227688 ,  5.474167  , -0.04531926],\n",
       "        [ 5.6396736 ,  5.29133956, -0.06161126],\n",
       "        [ 5.46952226,  5.95203357, -0.02546122],\n",
       "        [ 6.14746077,  5.96317265, -0.03837759],\n",
       "        [ 6.5033938 ,  5.98504281, -0.04724246],\n",
       "        [ 6.77242064,  5.99687042, -0.05398038],\n",
       "        [ 5.45199885,  6.19957023, -0.02953801],\n",
       "        [ 6.20066676,  6.22105431, -0.03755009],\n",
       "        [ 6.60851154,  6.23570749, -0.04424638],\n",
       "        [ 6.9013028 ,  6.24974116, -0.05119639],\n",
       "        [ 5.33187311,  6.40705239, -0.03495561],\n",
       "        [ 6.02315108,  6.45053573, -0.04479358],\n",
       "        [ 6.42136374,  6.46895391, -0.05380662],\n",
       "        [ 6.71558972,  6.47136295, -0.0608963 ],\n",
       "        [ 5.14666546,  6.58524524, -0.04154579],\n",
       "        [ 5.66482483,  6.65936167, -0.04902381],\n",
       "        [ 5.98583324,  6.67587705, -0.05188949],\n",
       "        [ 6.25919546,  6.67568786, -0.0540517 ]]),\n",
       " array([0.       , 0.9484275]),\n",
       " array([0., 1.]),\n",
       " array([0, 1], dtype=int32),\n",
       " array([2.92115374e-07, 1.33861089e-02, 1.24196718e-02, 2.88109779e-01,\n",
       "        5.75697683e-02, 3.07354219e-02, 1.32326995e-05, 1.58878031e-08,\n",
       "        8.72999664e-08, 3.63642573e-01, 4.11365360e-01, 6.62605762e-01,\n",
       "        6.69030905e-01, 2.73421267e-03, 5.51178098e-01, 5.63342750e-01,\n",
       "        1.03895655e-02, 1.23140477e-02, 8.84756818e-03, 2.24526033e-01,\n",
       "        2.50775576e-01, 4.66695800e-03, 1.89312676e-03, 3.73961666e-05,\n",
       "        1.19879853e-03, 7.60920672e-03, 4.57036338e-04, 1.92889536e-03,\n",
       "        8.89772832e-01, 8.59930277e-01, 8.38296987e-10, 1.49412671e-09,\n",
       "        1.53606525e-02, 1.33757144e-02, 1.26740182e-04, 8.43084490e-05,\n",
       "        7.94648603e-02, 9.92558002e-02, 8.17362487e-01, 1.14337606e-02,\n",
       "        1.67473480e-02, 3.32397074e-01, 3.43104475e-03, 1.09493383e-03,\n",
       "        1.44784761e-04, 2.09721227e-04, 8.35517653e-07, 5.79597008e-06,\n",
       "        3.15646721e-05, 2.39465880e-05, 5.11401367e-07, 3.26468843e-08]),\n",
       " 1,\n",
       " array([[ 0.        ,  0.        ],\n",
       "        [-1.39355698,  4.85907125]]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(frame_idx, total_frames, timestamp_formatted):\n",
    "    # Get terminal width to clear the entire line\n",
    "    terminal_width = shutil.get_terminal_size().columns\n",
    "    \n",
    "    # Create progress message\n",
    "    progress = f\"Processing frame {frame_idx}/{total_frames} (timestamp: {timestamp_formatted})\"\n",
    "    \n",
    "    # Pad with spaces to ensure previous text is overwritten\n",
    "    padded_progress = progress.ljust(terminal_width)\n",
    "    \n",
    "    # Print with carriage return and no newline\n",
    "    print(f\"\\r{padded_progress}\", end='', flush=True)\n",
    "    \n",
    "    # Print a newline when done (call this separately at the end)\n",
    "    if frame_idx == total_frames:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frame_data(npz_path):\n",
    "    \"\"\"\n",
    "    Load saved frame data from an NPZ file.\n",
    "    \n",
    "    Args:\n",
    "        npz_path (str): Path to the saved .npz file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: All the detection results for the frame\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    \n",
    "    # Extract all arrays from the npz file\n",
    "    dom_landmarks = data['dom_landmarks']\n",
    "    non_dom_landmarks = data['non_dom_landmarks']\n",
    "    confidence_scores = data['confidence_scores']\n",
    "    interpolation_scores = data['interpolation_scores']\n",
    "    detection_status = data['detection_status']\n",
    "    blendshape_scores = data['blendshape_scores']\n",
    "    face_detected = data['face_detected'].item()  # Convert 0-d array to scalar\n",
    "    nose_to_wrist_dist = data['nose_to_wrist_dist']\n",
    "    frame_idx = data['frame_idx'].item()\n",
    "    timestamp_ms = data['timestamp_ms'].item()\n",
    "    \n",
    "    return (dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores,\n",
    "            detection_status, blendshape_scores, face_detected, \n",
    "            nose_to_wrist_dist, frame_idx, timestamp_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = load_frame_data(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol[7][1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interpolation_frames(x, nums_list):\n",
    "    \"\"\"\n",
    "    Returns integers in the range [x-5, x+5] that are not equal to x\n",
    "    and are not in nums_list.\n",
    "    \n",
    "    Args:\n",
    "        x (int): The reference integer\n",
    "        nums_list (list): A list of integers\n",
    "        \n",
    "    Returns:\n",
    "        list: Integers in [x-5, x+5] excluding x and elements in nums_list\n",
    "    \"\"\"\n",
    "    # Create the set of all integers in the range [x-5, x+5]\n",
    "    all_range = set(range(x-5, x+6))  # +6 because range is exclusive at upper bound\n",
    "    \n",
    "    # Remove x itself\n",
    "    all_range.discard(x)\n",
    "    \n",
    "    # Remove numbers that are in the input list\n",
    "    result = all_range - set(nums_list)\n",
    "    \n",
    "    # Convert back to a list and return\n",
    "    return sorted(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def find_file_with_partial_name(partial_name, search_dir='.', recursive=False):\n",
    "    \"\"\"\n",
    "    Find files that start with the given partial name.\n",
    "    \n",
    "    Args:\n",
    "        partial_name (str): Partial file name to match\n",
    "        search_dir (str): Directory to search in (default: current directory)\n",
    "        recursive (bool): Whether to search in subdirectories\n",
    "        \n",
    "    Returns:\n",
    "        list: Complete paths of all matching files\n",
    "    \"\"\"\n",
    "    # Create a search pattern for files starting with the partial name\n",
    "    search_pattern = os.path.join(search_dir, f\"{partial_name}*\")\n",
    "    \n",
    "    # Use recursive glob if requested\n",
    "    if recursive:\n",
    "        matches = []\n",
    "        for root, _, _ in os.walk(search_dir):\n",
    "            matches.extend(glob.glob(os.path.join(root, f\"{os.path.basename(partial_name)}*\")))\n",
    "        return matches\n",
    "    else:\n",
    "        return glob.glob(search_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_numbers_on_both_sides(x, missing_numbers):\n",
    "    \"\"\"\n",
    "    Checks if the list of missing numbers has at least one number smaller than x\n",
    "    AND at least one number larger than x.\n",
    "    \n",
    "    Args:\n",
    "        x (int): The reference integer\n",
    "        missing_numbers (list): Output from find_missing_numbers(x, nums_list)\n",
    "        \n",
    "    Returns:\n",
    "        bool: False if all numbers are either all smaller or all larger than x.\n",
    "              True if there's at least one smaller and one larger number.\n",
    "    \"\"\"\n",
    "    has_smaller = False\n",
    "    has_larger = False\n",
    "    \n",
    "    for num in missing_numbers:\n",
    "        if num < x:\n",
    "            has_smaller = True\n",
    "        elif num > x:\n",
    "            has_larger = True\n",
    "            \n",
    "        # Early exit if we found both smaller and larger numbers\n",
    "        if has_smaller and has_larger:\n",
    "            return True\n",
    "    \n",
    "    # If we get here, we didn't find both smaller and larger numbers\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_npz_file(file_path, modifications):\n",
    "    \"\"\"\n",
    "    Load a .npz file, modify existing arrays and add new ones, then save it back.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the .npz file\n",
    "        modifications (dict): Dictionary with keys as array names and values as new arrays\n",
    "                             or functions that take the original array and return a modified version\n",
    "    \"\"\"\n",
    "    # Load the npz file\n",
    "    with np.load(file_path) as data:\n",
    "        # Create a copy of all arrays\n",
    "        arrays = {name: data[name] for name in data.files}\n",
    "    \n",
    "    # Apply modifications and add new arrays\n",
    "    for name, modification in modifications.items():\n",
    "        if name in arrays:\n",
    "            if callable(modification):\n",
    "                # If the modification is a function, apply it to the original array\n",
    "                arrays[name] = modification(arrays[name])\n",
    "            else:\n",
    "                # Otherwise, replace the array\n",
    "                arrays[name] = modification\n",
    "        else:\n",
    "            # Add new array\n",
    "            arrays[name] = modification\n",
    "            print(f\"Adding new array '{name}' to the file\")\n",
    "    \n",
    "    # Save back to the file with same format\n",
    "    np.savez(file_path, **arrays)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_undetected_hand_landmarks_new(directory_path):  \n",
    "    \"\"\"\n",
    "    Interpolate landmarks for frames where hand detection failed.\n",
    "    Optimized version for faster CPU processing.\n",
    "    \"\"\"\n",
    "    print(f\"Starting interpolation for directory: {directory_path}\")\n",
    "    \n",
    "    # Load detection statistics JSON\n",
    "    with open(os.path.join(directory_path, 'detection_statistics.json')) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    first_frame_number = round(data['video_info']['fps'] * data['video_info']['start_time'])\n",
    "    final_frame_number = round(data['video_info']['fps'] * data['video_info']['end_time'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Maximum possible sum of weights for normalization (when all 10 frames are available)\n",
    "    MAX_WEIGHT_SUM = 2.92722222\n",
    "    \n",
    "    # Create a cache for loaded frame data to avoid reloading the same frames\n",
    "    frame_data_cache = {}\n",
    "    \n",
    "    # Helper function to process either dominant or non-dominant hand\n",
    "    def process_hand_frames(failures, missing_frames_list, is_dominant):\n",
    "        hand_index = 0 if is_dominant else 1\n",
    "        hand_type = \"dominant\" if is_dominant else \"non-dominant\"\n",
    "        landmarks_key = 'dom_landmarks' if is_dominant else 'non_dom_landmarks'\n",
    "        \n",
    "        \n",
    "        interpolated_count = 0\n",
    "        \n",
    "        for missing_frame in failures:\n",
    "            frame_number = missing_frame['frame']\n",
    "            filepath = missing_frame['file']\n",
    "            \n",
    "            # Only interpolate frames not at the edges of the video\n",
    "            if (frame_number - 5) <= first_frame_number or (frame_number + 5) >= final_frame_number:\n",
    "                continue\n",
    "            \n",
    "            # Find frames with valid detections for interpolation\n",
    "            interpolation_frames = find_interpolation_frames(frame_number, missing_frames_list)\n",
    "            \n",
    "            if not interpolation_frames:\n",
    "                continue\n",
    "            \n",
    "            # Calculate interpolated landmarks\n",
    "            interpolation_weights_sum = 0\n",
    "            interpolated_coordinates = np.zeros(shape=(20, 3))\n",
    "            interpolated_wrist_to_nose = np.zeros(2)\n",
    "            \n",
    "            for interp_frame in interpolation_frames:\n",
    "                weight = 1 / ((frame_number - interp_frame) ** 2)\n",
    "                interpolation_weights_sum += weight\n",
    "                \n",
    "                # Find and load the reference frame - use cached version if available\n",
    "                cache_key = f\"{interp_frame}\"\n",
    "                if cache_key in frame_data_cache:\n",
    "                    frame_data = frame_data_cache[cache_key]\n",
    "                else:\n",
    "                    # Format the filename following the same pattern as the original code\n",
    "                    interp_partial_filename = data['video_info']['name'] + f\"_frame{interp_frame:06d}\"\n",
    "                    try:\n",
    "                        interp_files = find_file_with_partial_name(\n",
    "                            interp_partial_filename, \n",
    "                            search_dir=directory_path, \n",
    "                            recursive=False\n",
    "                        )\n",
    "                        \n",
    "                        if not interp_files:\n",
    "                            print(f\"Warning: Could not find file for frame {interp_frame}\")\n",
    "                            sys.exit(1)\n",
    "                            \n",
    "                        interp_filepath = interp_files[0]\n",
    "                        \n",
    "                        # Load and cache the frame data\n",
    "                        frame_data = load_frame_data(interp_filepath)\n",
    "                        frame_data_cache[cache_key] = frame_data\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing frame {interp_frame}: {e}\")\n",
    "                        sys.exit(1)\n",
    "                \n",
    "                # Get landmarks and nose-to-wrist distance for this hand type\n",
    "                landmarks = frame_data[hand_index]\n",
    "                nose_to_wrist = frame_data[7][hand_index, :]\n",
    "                \n",
    "                # Add weighted contribution\n",
    "                interpolated_coordinates += weight * landmarks\n",
    "                interpolated_wrist_to_nose += weight * nose_to_wrist\n",
    "            \n",
    "            # Normalize by sum of weights\n",
    "            if interpolation_weights_sum > 0:\n",
    "                interpolated_coordinates /= interpolation_weights_sum\n",
    "                interpolated_wrist_to_nose /= interpolation_weights_sum\n",
    "                \n",
    "                # Calculate confidence based on weights and frame distribution\n",
    "                has_frames_on_both_sides = has_numbers_on_both_sides(frame_number, interpolation_frames)\n",
    "                \n",
    "                if has_frames_on_both_sides:\n",
    "                    interpolation_confidence = interpolation_weights_sum / MAX_WEIGHT_SUM\n",
    "                else:\n",
    "                    interpolation_confidence = (interpolation_weights_sum / MAX_WEIGHT_SUM) * 0.8\n",
    "                    \n",
    "\n",
    "                \n",
    "                # Update the file with interpolated data\n",
    "                def update_interp_scores(arr):\n",
    "                    new_arr = arr.copy()\n",
    "                    new_arr[hand_index] = interpolation_confidence\n",
    "                    return new_arr\n",
    "                \n",
    "                def update_nose_to_wrist_scores(matrix):\n",
    "                    new_matrix = matrix.copy()\n",
    "                    new_matrix[hand_index, :] = interpolated_wrist_to_nose\n",
    "                    return new_matrix\n",
    "                    \n",
    "                modifications = {\n",
    "                    landmarks_key: interpolated_coordinates,\n",
    "                    'interpolation_scores': update_interp_scores,\n",
    "                    'nose_to_wrist_dist': update_nose_to_wrist_scores\n",
    "                }\n",
    "                \n",
    "                modify_npz_file(\n",
    "                    file_path=os.path.join(directory_path, filepath),\n",
    "                    modifications=modifications\n",
    "                )\n",
    "                \n",
    "                interpolated_count += 1\n",
    "                \n",
    "\n",
    "        return interpolated_count\n",
    "    \n",
    "    # Process non-dominant hand failures\n",
    "    missing_non_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['non_dominant_hand_failures']]\n",
    "    non_dom_count = process_hand_frames(\n",
    "        data['failed_frames']['non_dominant_hand_failures'],\n",
    "        missing_non_dominant_frame_list,\n",
    "        is_dominant=False\n",
    "    )\n",
    "    \n",
    "    # Process dominant hand failures\n",
    "    missing_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['dominant_hand_failures']]\n",
    "    dom_count = process_hand_frames(\n",
    "        data['failed_frames']['dominant_hand_failures'],\n",
    "        missing_dominant_frame_list,\n",
    "        is_dominant=True\n",
    "    )\n",
    "    \n",
    "    total_interpolated = non_dom_count + dom_count\n",
    "    print(f\"Total interpolated: {total_interpolated} frames\")\n",
    "    \n",
    "    return total_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_undetected_hand_landmarks_new_wrapper(directory_path):\n",
    "    gc.collect()\n",
    "    with open(os.path.join(directory_path, 'detection_statistics.json')) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    first_frame_number = round(data['video_info']['fps'] * data['video_info']['start_time'])\n",
    "    final_frame_number = round(data['video_info']['fps'] * data['video_info']['end_time'])\n",
    "\n",
    "    missing_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['dominant_hand_failures']]\n",
    "    missing_dominant_frame_list_with_interpolation_frames = [frame for frame in missing_dominant_frame_list if find_interpolation_frames(frame, missing_dominant_frame_list)]\n",
    "    missing_dominant_frame_list_no_edges = [frame for frame in missing_dominant_frame_list_with_interpolation_frames if (frame-5>=first_frame_number and frame+5<=final_frame_number)]\n",
    "    number_of_frames_to_interpolate_dom = len(missing_dominant_frame_list_no_edges)\n",
    "\n",
    "\n",
    "    missing_non_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['non_dominant_hand_failures']]\n",
    "    missing_non_dominant_frame_list_with_interpolation_frames = [frame for frame in missing_non_dominant_frame_list if find_interpolation_frames(frame, missing_non_dominant_frame_list)]\n",
    "    missing_non_dominant_frame_list_no_edges = [frame for frame in missing_non_dominant_frame_list_with_interpolation_frames if (frame-5>=first_frame_number and frame+5<=final_frame_number)]\n",
    "    number_of_frames_to_interpolate_non_dom = len(missing_non_dominant_frame_list_no_edges)\n",
    "\n",
    "    total_number_of_frames_to_interpolate = number_of_frames_to_interpolate_dom + number_of_frames_to_interpolate_non_dom\n",
    "    \n",
    "    \n",
    "    total_actually_interpolated = interpolate_undetected_hand_landmarks_new(directory_path)\n",
    "    \n",
    "    if total_number_of_frames_to_interpolate != total_actually_interpolated:\n",
    "        print(f\"The function missed some interpolations. Expected {total_number_of_frames_to_interpolate} but actually got {total_actually_interpolated} , exiting...\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        gc.collect()\n",
    "        return total_actually_interpolated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\", 'detection_statistics.json')) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "first_frame_number = round(data['video_info']['fps'] * data['video_info']['start_time'])\n",
    "final_frame_number = round(data['video_info']['fps'] * data['video_info']['end_time'])\n",
    "missing_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['dominant_hand_failures']]\n",
    "missing_dominant_frame_list_with_interpolation_frames = [frame for frame in missing_dominant_frame_list if find_interpolation_frames(frame, missing_dominant_frame_list)]\n",
    "missing_dominant_frame_list_no_edges = [frame for frame in missing_dominant_frame_list_with_interpolation_frames if (frame-5>=first_frame_number and frame+5<=final_frame_number)]\n",
    "number_of_frames_to_interpolate_dom = len(missing_dominant_frame_list_no_edges)\n",
    "missing_non_dominant_frame_list = [frame['frame'] for frame in data['failed_frames']['non_dominant_hand_failures']]\n",
    "missing_non_dominant_frame_list_with_interpolation_frames = [frame for frame in missing_non_dominant_frame_list if find_interpolation_frames(frame, missing_non_dominant_frame_list)]\n",
    "missing_non_dominant_frame_list_no_edges = [frame for frame in missing_non_dominant_frame_list_with_interpolation_frames if (frame-5>=first_frame_number and frame+5<=final_frame_number)]\n",
    "number_of_frames_to_interpolate_non_dom = len(missing_non_dominant_frame_list_no_edges)\n",
    "total_number_of_frames_to_interpolate = number_of_frames_to_interpolate_dom + number_of_frames_to_interpolate_non_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_number_of_frames_to_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolate_undetected_hand_landmarks_new_wrapper(directory_path=\"./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_data = load_frame_data(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores,\n",
    "            detection_status, blendshape_scores, face_detected, \n",
    "            nose_to_wrist_dist, frame_idx, timestamp_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(frame_data[8], int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_shapes_list = [(20, 3), (20, 3), (2,), (2,), (2,), (52,), 0, (2, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_data_frame_good(frame_data, expected_shapes_list=expected_shapes_list):\n",
    "    if len(frame_data)!=10:\n",
    "        print(f\"Expected 10 outputs but got {len(frame_data)}\")\n",
    "        return False\n",
    "    for i in range(8):\n",
    "        if i==6:\n",
    "            continue\n",
    "        if frame_data[i].shape != expected_shapes_list[i]:\n",
    "            print(f\"Dimensions problem in loaded frame, in intex {i}\")\n",
    "            return False\n",
    "    if (not isinstance(frame_data[8], int)):\n",
    "        print(f\"Frame idx is not an integer\")\n",
    "        return False\n",
    "    return True\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96831143, 0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_data[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frame_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_files = sorted(glob.glob(os.path.join(directory_path, \"*.npz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000000_00m00s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000001_00m01s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000002_00m02s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000003_00m03s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000004_00m04s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000005_00m05s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000006_00m06s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000007_00m07s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000008_00m08s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000009_00m09s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000010_00m10s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000011_00m11s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000012_00m12s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000013_00m13s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000014_00m14s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000015_00m15s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000016_00m16s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000017_00m17s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000018_00m18s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000019_00m19s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000020_00m20s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000021_00m21s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000022_00m22s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000023_00m23s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000024_00m24s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000025_00m25s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000026_00m26s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000027_00m27s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000028_00m28s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000029_00m29s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000030_00m30s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000031_00m31s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000032_00m32s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000033_00m33s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000034_00m34s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000035_00m35s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000037_00m37s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000038_00m38s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000039_00m39s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000040_00m40s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000041_00m41s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000042_00m42s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000043_00m43s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000044_00m44s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000045_00m45s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000046_00m46s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000047_00m47s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000048_00m48s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000049_00m49s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000050_00m50s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000051_00m51s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000052_00m52s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000053_00m53s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000054_00m54s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000055_00m55s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000056_00m56s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000057_00m57s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000058_00m58s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000059_00m59s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000060_01m00s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000061_01m01s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000062_01m02s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000063_01m03s000ms.npz',\n",
       " './youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000064_01m04s000ms.npz']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npz_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(directory_path, 'detection_statistics.json')) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['video_info']['total_frames'] == len(npz_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_to_file = {}\n",
    "for file_path in npz_files:\n",
    "    frame_data = load_frame_data(file_path)\n",
    "    if not is_data_frame_good(frame_data=frame_data, expected_shapes_list=expected_shapes_list):\n",
    "        print(f\"Wrong loaded frame data dimensions for frame with path {file_path}, exiting...\")\n",
    "        sys.exit(1)\n",
    "    frame_idx = frame_data[8]  # Index for frame_idx\n",
    "    frame_to_file[frame_idx] = file_path\n",
    "\n",
    "frame_indices = sorted(frame_to_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 170 (4151162464.py, line 171)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[80], line 171\u001b[0;36m\u001b[0m\n\u001b[0;31m    frame_idx = frame_data[8]  # Index for frame_idx\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 170\n"
     ]
    }
   ],
   "source": [
    "def is_data_frame_good(frame_data, expected_shapes_list=expected_shapes_list):\n",
    "    if len(frame_data)!=10:\n",
    "        print(f\"Expected 10 outputs but got {len(frame_data)}\")\n",
    "        return False\n",
    "    for i in range(8):\n",
    "        if i==6:\n",
    "            continue\n",
    "        if frame_data[i].shape != expected_shapes_list[i]:\n",
    "            print(f\"Dimensions problem in loaded frame, in intex {i}\")\n",
    "            return False\n",
    "    if (not isinstance(frame_data[8], int)):\n",
    "        print(f\"Frame idx is not an integer\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def is_valid_detection(frame_data, is_dominant_hand):\n",
    "    \"\"\"\n",
    "    Check if the frame has valid detection (not interpolated) for a specific hand.\n",
    "    \n",
    "    Args:\n",
    "        frame_data: The loaded frame data\n",
    "        is_dominant_hand: If True, check dominant hand; if False, check non-dominant hand;\n",
    "                         if None, check if either hand is detected\n",
    "    \n",
    "    Returns:\n",
    "        bool: Whether the specified hand(s) is/are detected\n",
    "    \"\"\"\n",
    "    detection_status = frame_data[4]\n",
    "    \n",
    "    if is_dominant_hand:\n",
    "        # Check specifically for dominant hand\n",
    "        return detection_status[0] == 1\n",
    "    else:\n",
    "        # Check specifically for non-dominant hand\n",
    "        return detection_status[1] == 1\n",
    "    \n",
    "\n",
    "\n",
    "def has_value(frame_data, is_dominant_hand):\n",
    "    \"\"\"Check if the frame exists and has any value (detection or interpolation)\"\"\"\n",
    "    detection_status = frame_data[4]\n",
    "    interpolation_scores = frame_data[3]\n",
    "    if is_dominant_hand:\n",
    "        return (detection_status[0]==1) or (interpolation_scores[0]>0)\n",
    "    else:\n",
    "        return (detection_status[1]==1) or (interpolation_scores[1]>0)\n",
    "    \n",
    "        \n",
    "\n",
    "def cartesian_to_spherical(velocities):\n",
    "    \"\"\"\n",
    "    Convert Cartesian velocities (ux, uy, uz) to spherical coordinate features.\n",
    "    \n",
    "    Args:\n",
    "        velocities: NumPy array of shape (20, 3) with Cartesian velocities\n",
    "        \n",
    "    Returns:\n",
    "        NumPy array of shape (20, 5) with spherical features:\n",
    "            [vmagnitude, sin, cos, sin, cos]\n",
    "    \"\"\"\n",
    "    num_landmarks = velocities.shape[0]\n",
    "    spherical_features = np.zeros((num_landmarks, 5))\n",
    "    \n",
    "    for i in range(num_landmarks):\n",
    "        ux, uy, uz = velocities[i]\n",
    "        \n",
    "        # Calculate velocity magnitude\n",
    "        vmagnitude = np.sqrt(ux**2 + uy**2 + uz**2)\n",
    "        spherical_features[i, 0] = vmagnitude\n",
    "        \n",
    "        # Handle edge cases to avoid division by zero\n",
    "        if vmagnitude == 0:\n",
    "            # If velocity is zero, set all angles to zero\n",
    "            spherical_features[i, 1:] = 0\n",
    "            continue\n",
    "        \n",
    "        # Calculate azimuth angle ()\n",
    "        phi = np.arctan2(uy, ux)\n",
    "        spherical_features[i, 1] = np.sin(phi)  # sin\n",
    "        spherical_features[i, 2] = np.cos(phi)  # cos\n",
    "        \n",
    "        # Calculate elevation angle ()\n",
    "        # Clamp uz/vmagnitude to range [-1, 1] to avoid numerical errors\n",
    "        cos_theta = np.clip(uz / vmagnitude, -1.0, 1.0)\n",
    "        theta = np.arccos(cos_theta)\n",
    "        spherical_features[i, 3] = np.sin(theta)  # sin\n",
    "        spherical_features[i, 4] = cos_theta      # cos (already calculated)\n",
    "    \n",
    "    return spherical_features\n",
    "\n",
    "\n",
    "\n",
    "def cartesian_to_polar_features(velocities):\n",
    "    \"\"\"\n",
    "    Convert Cartesian velocity coordinates to polar features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    velocities : numpy.ndarray\n",
    "        Array of shape (2, 2) where each row represents an object's [Ux, Uy]\n",
    "\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Array of shape (2, 3) with columns [magnitude, sin(direction), cos(direction)]\n",
    "    \"\"\"\n",
    "    # Calculate magnitude\n",
    "    magnitude = np.sqrt(np.sum(velocities**2, axis=1))\n",
    "    \n",
    "    # Initialize result array\n",
    "    result = np.zeros((velocities.shape[0], 3))\n",
    "    result[:, 0] = magnitude  # Set first column to magnitude\n",
    "    \n",
    "    # Create a mask for non-zero magnitudes\n",
    "    non_zero = magnitude > 0\n",
    "    \n",
    "    # For non-zero magnitudes, calculate direction components\n",
    "    if np.any(non_zero):\n",
    "        # Get direction for non-zero magnitudes\n",
    "        direction = np.arctan2(velocities[non_zero, 1], velocities[non_zero, 0])\n",
    "        \n",
    "        # Calculate sin and cos\n",
    "        result[non_zero, 1] = np.sin(direction)  # sin(direction)\n",
    "        result[non_zero, 2] = np.cos(direction)  # cos(direction)\n",
    "    \n",
    "    # Handle zero magnitudes \n",
    "    zero_indices = ~non_zero\n",
    "    if np.any(zero_indices):\n",
    "        result[zero_indices, 1] = 0.0\n",
    "        result[zero_indices, 2] = 0.0\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def sorted_npz_files_checked(directory_path):\n",
    "    if os.path.exists(directory_path) and os.path.isdir(directory_path):\n",
    "        # List all NPZ files in the directory\n",
    "        npz_files = sorted(glob.glob(os.path.join(directory_path, \"*.npz\")))\n",
    "    else:\n",
    "        print(f\"Directory path {directory_path} doesn't exist or it isn't a directory\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    \n",
    "    # Skip if no files found\n",
    "    if not npz_files:\n",
    "        print(f\"No NPZ files found in {directory_path}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(directory_path, 'detection_statistics.json')) as f:\n",
    "        statistics_file = json.load(f)\n",
    "    \n",
    "    if statistics_file['video_info']['total_frames'] != len(npz_files):\n",
    "        print(\"npz filepath list contain different amount of items than total frames\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    \n",
    "\n",
    "    expected_shapes_list = [(20, 3), (20, 3), (2,), (2,), (2,), (52,), 0, (2, 2)]\n",
    "    # Create a mapping of frame indices to file paths and check if all files are good\n",
    "    frame_to_file = {}\n",
    "    for file_path in npz_files:\n",
    "        try:\n",
    "            frame_data = load_frame_data(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading frame with path: {file_path}: {e}\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "        if not is_data_frame_good(frame_data=frame_data, expected_shapes_list=expected_shapes_list):\n",
    "            print(f\"Wrong loaded frame data dimensions for frame with path {file_path}, exiting...\")\n",
    "            sys.exit(1)\n",
    "        frame_idx = frame_data[8]  # Index for frame_idx\n",
    "        frame_to_file[frame_idx] = file_path\n",
    "\n",
    "    \n",
    "    frame_indices = sorted(frame_to_file.keys())\n",
    "    if not all(frame_indices[i+1] - frame_indices[i] == 1 for i in range(len(frame_indices) - 1)):\n",
    "        print(\"Consecutive frames are not different by one frame\")\n",
    "        sys.exit(1)\n",
    "    processed_count = 0\n",
    "    \n",
    "\n",
    "    min_frame = min(frame_indices)\n",
    "    max_frame = max(frame_indices)\n",
    "    return frame_to_file, frame_indices, min_frame, max_frame\n",
    "\n",
    "def compute_landmark_velocities(directory_path):\n",
    "    \"\"\"\n",
    "    Compute velocity features for hand landmarks using central differencing with two window sizes,\n",
    "    and convert to spherical coordinates.\n",
    "    \n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing frame NPZ files\n",
    "    \n",
    "    Returns:\n",
    "        int: Number of frames processed\n",
    "    \"\"\"\n",
    "    frame_to_file, frame_indices, min_frame, max_frame = sorted_npz_files_checked(directory_path=directory_path)\n",
    "    safe_margin = 5  # Skip processing frames within 5 frames of the edge\n",
    "    \n",
    "    # Process each frame\n",
    "    for i, curr_idx in enumerate(frame_indices):\n",
    "        if curr_idx < min_frame + safe_margin or curr_idx > max_frame - safe_margin:\n",
    "            dom_velocity_small = np.zeros((20, 5))\n",
    "            dom_velocity_large = np.zeros((20, 5))\n",
    "            non_dom_velocity_small = np.zeros((20, 5))\n",
    "            non_dom_velocity_large = np.zeros((20, 5))\n",
    "            \n",
    "            wrist_velocity_small = np.zeros((2, 3))  \n",
    "            wrist_velocity_large = np.zeros((2, 3))\n",
    "            \n",
    "            # Create zero confidence arrays\n",
    "            velocity_confidence = np.zeros(2)\n",
    "            velocity_calculation_confidence = np.zeros(2)\n",
    "            \n",
    "            # Save these zero arrays\n",
    "            modifications = {\n",
    "                'dom_velocity_small': dom_velocity_small,\n",
    "                'dom_velocity_large': dom_velocity_large,\n",
    "                'non_dom_velocity_small': non_dom_velocity_small,\n",
    "                'non_dom_velocity_large': non_dom_velocity_large,\n",
    "                'velocity_confidence': velocity_confidence,\n",
    "                'velocity_calculation_confidence': velocity_calculation_confidence,\n",
    "                'wrist_velocity_small': wrist_velocity_small,\n",
    "                'wrist_velocity_large': wrist_velocity_large,\n",
    "            }\n",
    "            \n",
    "            # Get the file path for this frame\n",
    "            current_file_path = frame_to_file[curr_idx]\n",
    "            modify_npz_file(current_file_path, modifications)\n",
    "            processed_count += 1\n",
    "            \n",
    "            # Log that we're skipping calculation\n",
    "            print(f\"Frame {curr_idx} too close to video boundary - setting zero velocities\")\n",
    "            continue\n",
    "        # Load current frame\n",
    "        current_file_path = frame_to_file[curr_idx]\n",
    "        try:\n",
    "            curr_frame_data = load_frame_data(current_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading frame {curr_idx}: {e}\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "        \n",
    "        # Store needed frames in a dictionary for easy access\n",
    "        frame_cache = {curr_idx: curr_frame_data}\n",
    "        \n",
    "        # Load all potentially needed frames in the -5 to +5 range\n",
    "        for offset in range(-5, 6):\n",
    "            if offset == 0:  # Skip current frame (already loaded)\n",
    "                continue\n",
    "            \n",
    "            check_idx = curr_idx + offset\n",
    "            if check_idx in frame_to_file:\n",
    "                try:\n",
    "                    frame_cache[check_idx] = load_frame_data(frame_to_file[check_idx])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading frame {check_idx}: {e}\")\n",
    "                    sys.exit(1)\n",
    "            else:\n",
    "                print(f\"Frame: {check_idx} not available\")\n",
    "                sys.exit(1)  # Mark as not available\n",
    "        \n",
    "        # Extract dominant and non-dominant hand landmarks from current frame\n",
    "        dom_landmarks = curr_frame_data[0]\n",
    "        non_dom_landmarks = curr_frame_data[1]\n",
    "        \n",
    "        # Initialize velocity arrays in Cartesian coordinates\n",
    "        dom_velocity_small_cart = np.zeros_like(dom_landmarks)\n",
    "        dom_velocity_large_cart = np.zeros_like(dom_landmarks)\n",
    "        non_dom_velocity_small_cart = np.zeros_like(non_dom_landmarks)\n",
    "        non_dom_velocity_large_cart = np.zeros_like(non_dom_landmarks)\n",
    "        \n",
    "        wrist_velocity_small = np.zeros((2, 2))  # 2 hands  [x, y] coordinates\n",
    "        wrist_velocity_large = np.zeros((2, 2))  # 2 hands  [x, y] coordinates\n",
    "        \n",
    "        # Initialize confidence and method weight tracking\n",
    "        dom_small_conf = 0.0\n",
    "        dom_large_conf = 0.0\n",
    "        non_dom_small_conf = 0.0\n",
    "        non_dom_large_conf = 0.0\n",
    "        \n",
    "        dom_small_method_weight = 0.0\n",
    "        dom_large_method_weight = 0.0\n",
    "        non_dom_small_method_weight = 0.0\n",
    "        non_dom_large_method_weight = 0.0\n",
    "        \n",
    "        dom_small_source_quality = 0.0\n",
    "        dom_large_source_quality = 0.0\n",
    "        non_dom_small_source_quality = 0.0\n",
    "        non_dom_large_source_quality = 0.0\n",
    "        \n",
    "        def satisfied_symmetric_windows_condition(positive_offset, negative_offset, is_dom_hand):\n",
    "            return (curr_idx + positive_offset in frame_cache and frame_cache[curr_idx + positive_offset] is not None and \n",
    "            is_valid_detection(frame_cache[curr_idx + positive_offset], is_dom_hand) and \n",
    "            curr_idx - negative_offset in frame_cache and frame_cache[curr_idx - negative_offset] is not None and \n",
    "            has_value(frame_cache[curr_idx - negative_offset], is_dom_hand))\n",
    "        \n",
    "        def single_positive_check(positive_offset, is_dom_hand):\n",
    "            return (curr_idx + positive_offset in frame_cache and frame_cache[curr_idx + positive_offset] is not None and \n",
    "            is_valid_detection(frame_cache[curr_idx + positive_offset], is_dom_hand))\n",
    "        \n",
    "        def negative_check(negative_offset, is_dom_hand):\n",
    "            return (curr_idx - negative_offset in frame_cache and frame_cache[curr_idx - negative_offset] is not None and \n",
    "            has_value(frame_cache[curr_idx - negative_offset], is_dom_hand))\n",
    "            \n",
    "        def velocity_and_confidence_calculations(positive_offset, negative_offset, is_dom_hand):\n",
    "            if is_dom_hand:\n",
    "                index=0\n",
    "            else:\n",
    "                index=1\n",
    "            distance_of_offsets = positive_offset + negative_offset\n",
    "            velocity_cart = (frame_cache[curr_idx + positive_offset][index] - frame_cache[curr_idx - negative_offset][index]) / distance_of_offsets\n",
    "            wrist_velocity = (frame_cache[curr_idx + positive_offset][7][index, :] - frame_cache[curr_idx - negative_offset][7][index, :]) / distance_of_offsets\n",
    "            conf = min(frame_cache[curr_idx + positive_offset][2][index], frame_cache[curr_idx - negative_offset][2][index])  \n",
    "            # Calculate source quality factor (average of interpolation confidences)\n",
    "            t_plus_1_interp = frame_cache[curr_idx + positive_offset][3][index]\n",
    "            t_minus_1_interp = frame_cache[curr_idx - negative_offset][3][index]\n",
    "            source_quality = (t_plus_1_interp + t_minus_1_interp) / 2.0\n",
    "            return velocity_cart, wrist_velocity, conf, source_quality\n",
    "        \n",
    "        # ===== DOMINANT HAND VELOCITY CALCULATION =====\n",
    "        \n",
    "        # Small window [-1, +1] velocity with fallbacks\n",
    "        if satisfied_symmetric_windows_condition(positive_offset=1, negative_offset=1, is_dom_hand=True):\n",
    "            # Ideal case: (t+1, t-1)\n",
    "            dom_velocity_small_cart = (frame_cache[curr_idx + 1][0] - frame_cache[curr_idx - 1][0]) / 2.0\n",
    "            wrist_velocity_small[0, :] = (frame_cache[curr_idx + 1][7][0, :] - frame_cache[curr_idx - 1][7][0, :]) / 2.0\n",
    "            dom_small_conf = min(frame_cache[curr_idx + 1][2][0], frame_cache[curr_idx - 1][2][0])  # Detection confidence of t+1 frame\n",
    "            dom_small_method_weight = 1.0  # Ideal frames\n",
    "            # Calculate source quality factor (average of interpolation confidences)\n",
    "            t_plus_1_interp = frame_cache[curr_idx + 1][3][0]\n",
    "            t_minus_1_interp = frame_cache[curr_idx - 1][3][0]\n",
    "            dom_small_source_quality = (t_plus_1_interp + t_minus_1_interp) / 2.0\n",
    "            # dom_velocity_small_cart, wrist_velocity_small[0, :], dom_small_conf, dom_small_source_quality = velocity_and_confidence_calculations(positive_offset=1, negative_offset=1, is_dom_hand=True)\n",
    "            \n",
    "        elif satisfied_symmetric_windows_condition(positive_offset=2, negative_offset=2, is_dom_hand=True):\n",
    "            # Fallback 1: (t+2, t-2)\n",
    "            dom_velocity_small_cart = (frame_cache[curr_idx + 2][0] - frame_cache[curr_idx - 2][0]) / 4.0\n",
    "            wrist_velocity_small[0, :] = (frame_cache[curr_idx + 2][7][0, :] - frame_cache[curr_idx - 2][7][0, :]) / 4.0\n",
    "            dom_small_conf = min(frame_cache[curr_idx + 2][2][0], frame_cache[curr_idx - 2][2][0])  # Detection confidence of t+2 frame\n",
    "            dom_small_method_weight = 0.8  # Wider symmetric window\n",
    "            # Calculate source quality factor\n",
    "            t_plus_2_interp = frame_cache[curr_idx + 2][3][0]\n",
    "            t_minus_2_interp = frame_cache[curr_idx - 2][3][0]\n",
    "            dom_small_source_quality = (t_plus_2_interp + t_minus_2_interp) / 2.0\n",
    "            # dom_velocity_small_cart, wrist_velocity_small[0, :], dom_small_conf, dom_small_source_quality = velocity_and_confidence_calculations(positive_offset=2, negative_offset=2, is_dom_hand=True)\n",
    "        elif single_positive_check(positive_offset=2, is_dom_hand=True):\n",
    "            if negative_check(negative_offset=1, is_dom_hand=True):\n",
    "                # Fallback 2: (t+2, t-1)\n",
    "                dom_velocity_small_cart = (frame_cache[curr_idx + 2][0] - frame_cache[curr_idx - 1][0]) / 3.0\n",
    "                wrist_velocity_small[0, :] = (frame_cache[curr_idx + 2][7][0, :] - frame_cache[curr_idx - 1][7][0, :]) / 3.0\n",
    "                dom_small_conf = min(frame_cache[curr_idx + 2][2][0], frame_cache[curr_idx - 1][2][0])  # Detection confidence of t+2 frame\n",
    "                dom_small_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_2_interp = frame_cache[curr_idx + 2][3][0]\n",
    "                t_minus_1_interp = frame_cache[curr_idx - 1][3][0]\n",
    "                dom_small_source_quality = (t_plus_2_interp + t_minus_1_interp) / 2.0\n",
    "                \n",
    "            elif is_valid_detection(curr_frame_data, True):\n",
    "                # Fallback 3: (t+2, t)\n",
    "                dom_velocity_small_cart = (frame_cache[curr_idx + 2][0] - curr_frame_data[0]) / 2.0\n",
    "                wrist_velocity_small[0, :] = (frame_cache[curr_idx + 2][7][0, :] - curr_frame_data[7][0, :]) / 2.0\n",
    "                dom_small_conf = min(frame_cache[curr_idx + 2][2][0], curr_frame_data[2][0])\n",
    "                dom_small_method_weight = 0.4  # One-sided derivative\n",
    "                # Calculate source quality factor\n",
    "                t_plus_2_interp = frame_cache[curr_idx + 2][3][0]\n",
    "                t_interp = curr_frame_data[3][0]\n",
    "                dom_small_source_quality = (t_plus_2_interp + t_interp) / 2.0\n",
    "                \n",
    "        elif is_valid_detection(curr_frame_data, True):\n",
    "            if negative_check(negative_offset=1, is_dom_hand=True):\n",
    "                # Fallback 4: (t, t-1)\n",
    "                dom_velocity_small_cart = (curr_frame_data[0] - frame_cache[curr_idx - 1][0])\n",
    "                wrist_velocity_small[0, :] = (curr_frame_data[7][0, :] - frame_cache[curr_idx - 1][7][0, :]) \n",
    "                dom_small_conf = min(curr_frame_data[2][0], frame_cache[curr_idx - 1][2][0])  # Detection confidence of current frame\n",
    "                dom_small_method_weight = 0.4  # One-sided derivative\n",
    "                # Calculate source quality factor\n",
    "                t_interp = curr_frame_data[3][0]\n",
    "                t_minus_1_interp = frame_cache[curr_idx - 1][3][0]\n",
    "                dom_small_source_quality = (t_interp + t_minus_1_interp) / 2.0\n",
    "                \n",
    "            elif negative_check(negative_offset=2, is_dom_hand=True):\n",
    "                # Fallback 5: (t, t-2)\n",
    "                dom_velocity_small_cart = (curr_frame_data[0] - frame_cache[curr_idx - 2][0]) / 2.0\n",
    "                wrist_velocity_small[0, :] = (curr_frame_data[7][0, :] - frame_cache[curr_idx - 2][7][0, :]) / 2.0\n",
    "                dom_small_conf = min(curr_frame_data[2][0], frame_cache[curr_idx - 2][2][0])  # Detection confidence of current frame\n",
    "                dom_small_method_weight = 0.4  # One-sided derivative\n",
    "                # Calculate source quality factor\n",
    "                t_interp = curr_frame_data[3][0]\n",
    "                t_minus_2_interp = frame_cache[curr_idx - 2][3][0]\n",
    "                dom_small_source_quality = (t_interp + t_minus_2_interp) / 2.0\n",
    "        \n",
    "        # Large window [-5, +5] velocity with fallbacks            \n",
    "        if satisfied_symmetric_windows_condition(positive_offset=5, negative_offset=5, is_dom_hand=True):\n",
    "            # Ideal case: (t+5, t-5)\n",
    "            dom_velocity_large_cart = (frame_cache[curr_idx + 5][0] - frame_cache[curr_idx - 5][0]) / 10.0\n",
    "            wrist_velocity_large[0, :] = (frame_cache[curr_idx + 5][7][0, :] - frame_cache[curr_idx - 5][7][0, :]) / 10.0\n",
    "            dom_large_conf = min(frame_cache[curr_idx + 5][2][0], frame_cache[curr_idx - 5][2][0])  # Detection confidence of t+5 frame\n",
    "            dom_large_method_weight = 1.0  # Ideal frames\n",
    "            # Calculate source quality factor\n",
    "            t_plus_5_interp = frame_cache[curr_idx + 5][3][0]\n",
    "            t_minus_5_interp = frame_cache[curr_idx - 5][3][0]\n",
    "            dom_large_source_quality = (t_plus_5_interp + t_minus_5_interp) / 2.0\n",
    "            \n",
    "        elif satisfied_symmetric_windows_condition(positive_offset=4, negative_offset=4, is_dom_hand=True):\n",
    "        # Fallback 1: (t+4, t-4)\n",
    "            dom_velocity_large_cart = (frame_cache[curr_idx + 4][0] - frame_cache[curr_idx - 4][0]) / 8.0\n",
    "            wrist_velocity_large[0, :] = (frame_cache[curr_idx + 4][7][0, :] - frame_cache[curr_idx - 4][7][0, :]) / 8.0\n",
    "            dom_large_conf = min(frame_cache[curr_idx + 4][2][0], frame_cache[curr_idx - 4][2][0]) # Detection confidence of t+4 frame\n",
    "            dom_large_method_weight = 0.8  # Wider symmetric window\n",
    "            # Calculate source quality factor\n",
    "            t_plus_4_interp = frame_cache[curr_idx + 4][3][0]\n",
    "            t_minus_4_interp = frame_cache[curr_idx - 4][3][0]\n",
    "            dom_large_source_quality = (t_plus_4_interp + t_minus_4_interp) / 2.0\n",
    "    \n",
    "        elif satisfied_symmetric_windows_condition(positive_offset=3, negative_offset=3, is_dom_hand=True):\n",
    "            # Fallback 2: (t+3, t-3)\n",
    "            dom_velocity_large_cart = (frame_cache[curr_idx + 3][0] - frame_cache[curr_idx - 3][0]) / 6.0\n",
    "            wrist_velocity_large[0, :] = (frame_cache[curr_idx + 3][7][0, :] - frame_cache[curr_idx - 3][7][0, :]) / 6.0\n",
    "            dom_large_conf = min(frame_cache[curr_idx + 3][2][0], frame_cache[curr_idx - 3][2][0])  # Detection confidence of t+3 frame\n",
    "            dom_large_method_weight = 0.8  # Wider symmetric window\n",
    "            # Calculate source quality factor\n",
    "            t_plus_3_interp = frame_cache[curr_idx + 3][3][0]\n",
    "            t_minus_3_interp = frame_cache[curr_idx - 3][3][0]\n",
    "            dom_large_source_quality = (t_plus_3_interp + t_minus_3_interp) / 2.0\n",
    "            \n",
    "        # Asymmetric fallbacks for large window\n",
    "        elif single_positive_check(positive_offset=5, is_dom_hand=True):\n",
    "            if negative_check(negative_offset=4, is_dom_hand=True):\n",
    "                # Fallback 3: (t+5, t-4)\n",
    "                dom_velocity_large_cart = (frame_cache[curr_idx + 5][0] - frame_cache[curr_idx - 4][0]) / 9.0\n",
    "                wrist_velocity_large[0, :] = (frame_cache[curr_idx + 5][7][0, :] - frame_cache[curr_idx - 4][7][0, :]) / 9.0\n",
    "                dom_large_conf = min(frame_cache[curr_idx + 5][2][0], frame_cache[curr_idx - 4][2][0])  # Detection confidence of t+5 frame\n",
    "                dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_5_interp = frame_cache[curr_idx + 5][3][0]\n",
    "                t_minus_4_interp = frame_cache[curr_idx - 4][3][0]\n",
    "                dom_large_source_quality = (t_plus_5_interp + t_minus_4_interp) / 2.0\n",
    "                \n",
    "            elif negative_check(negative_offset=3, is_dom_hand=True):\n",
    "                # Fallback 4: (t+5, t-3)\n",
    "                dom_velocity_large_cart = (frame_cache[curr_idx + 5][0] - frame_cache[curr_idx - 3][0]) / 8.0\n",
    "                wrist_velocity_large[0, :] = (frame_cache[curr_idx + 5][7][0, :] - frame_cache[curr_idx - 3][7][0, :]) / 8.0\n",
    "                dom_large_conf = min(frame_cache[curr_idx + 5][2][0], frame_cache[curr_idx - 3][2][0])  # Detection confidence of t+5 frame\n",
    "                dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_5_interp = frame_cache[curr_idx + 5][3][0]\n",
    "                t_minus_3_interp = frame_cache[curr_idx - 3][3][0]\n",
    "                dom_large_source_quality = (t_plus_5_interp + t_minus_3_interp) / 2.0\n",
    "        \n",
    "        elif single_positive_check(positive_offset=4, is_dom_hand=True):\n",
    "            if negative_check(negative_offset=5, is_dom_hand=True):\n",
    "                # Fallback 5: (t+4, t-5)\n",
    "                dom_velocity_large_cart = (frame_cache[curr_idx + 4][0] - frame_cache[curr_idx - 5][0]) / 9.0\n",
    "                wrist_velocity_large[0, :] = (frame_cache[curr_idx + 4][7][0, :] - frame_cache[curr_idx - 5][7][0, :]) / 9.0\n",
    "                dom_large_conf = min(frame_cache[curr_idx + 4][2][0], frame_cache[curr_idx - 5][2][0])  # Detection confidence of t+4 frame\n",
    "                dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_4_interp = frame_cache[curr_idx + 4][3][0]\n",
    "                t_minus_5_interp = frame_cache[curr_idx - 5][3][0]\n",
    "                dom_large_source_quality = (t_plus_4_interp + t_minus_5_interp) / 2.0\n",
    "                \n",
    "            elif negative_check(negative_offset=3, is_dom_hand=True):\n",
    "                # Fallback 6: (t+4, t-3)\n",
    "                dom_velocity_large_cart = (frame_cache[curr_idx + 4][0] - frame_cache[curr_idx - 3][0]) / 7.0\n",
    "                wrist_velocity_large[0, :] = (frame_cache[curr_idx + 4][7][0, :] - frame_cache[curr_idx - 3][7][0, :]) / 7.0\n",
    "                dom_large_conf = min(frame_cache[curr_idx + 4][2][0], frame_cache[curr_idx - 3][2][0])  # Detection confidence of t+4 frame\n",
    "                dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_4_interp = frame_cache[curr_idx + 4][3][0]\n",
    "                t_minus_3_interp = frame_cache[curr_idx - 3][3][0]\n",
    "                dom_large_source_quality = (t_plus_4_interp + t_minus_3_interp) / 2.0\n",
    "                \n",
    "        elif single_positive_check(positive_offset=3, is_dom_hand=True):\n",
    "            if negative_check(negative_offset=5, is_dom_hand=True):\n",
    "                # Fallback 7: (t+3, t-5)\n",
    "                dom_velocity_large_cart = (frame_cache[curr_idx + 3][0] - frame_cache[curr_idx - 5][0]) / 8.0\n",
    "                wrist_velocity_large[0, :] = (frame_cache[curr_idx + 3][7][0, :] - frame_cache[curr_idx - 5][7][0, :]) / 8.0\n",
    "                dom_large_conf = min(frame_cache[curr_idx + 3][2][0], frame_cache[curr_idx - 5][2][0])  # Detection confidence of t+3 frame\n",
    "                dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_3_interp = frame_cache[curr_idx + 3][3][0]\n",
    "                t_minus_5_interp = frame_cache[curr_idx - 5][3][0]\n",
    "                dom_large_source_quality = (t_plus_3_interp + t_minus_5_interp) / 2.0\n",
    "                \n",
    "            elif negative_check(negative_offset=4, is_dom_hand=True):\n",
    "                # Fallback 8: (t+3, t-4)\n",
    "                dom_velocity_large_cart = (frame_cache[curr_idx + 3][0] - frame_cache[curr_idx - 4][0]) / 7.0\n",
    "                wrist_velocity_large[0, :] = (frame_cache[curr_idx + 3][7][0, :] - frame_cache[curr_idx - 4][7][0, :]) / 7.0\n",
    "                dom_large_conf = min(frame_cache[curr_idx + 3][2][0], frame_cache[curr_idx - 4][2][0])  # Detection confidence of t+3 frame\n",
    "                dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_3_interp = frame_cache[curr_idx + 3][3][0]\n",
    "                t_minus_4_interp = frame_cache[curr_idx - 4][3][0]\n",
    "                dom_large_source_quality = (t_plus_3_interp + t_minus_4_interp) / 2.0\n",
    "\n",
    "        # ===== NON-DOMINANT HAND VELOCITY CALCULATION =====\n",
    "\n",
    "    # Small window [-1, +1] velocity with fallbacks for non-dominant hand\n",
    "        if satisfied_symmetric_windows_condition(positive_offset=1, negative_offset=1, is_dom_hand=False):\n",
    "            # Ideal case: (t+1, t-1)\n",
    "            non_dom_velocity_small_cart = (frame_cache[curr_idx + 1][1] - frame_cache[curr_idx - 1][1]) / 2.0\n",
    "            wrist_velocity_small[1, :] = (frame_cache[curr_idx + 1][7][1, :] - frame_cache[curr_idx - 1][7][1, :]) / 2.0\n",
    "            non_dom_small_conf = min(frame_cache[curr_idx + 1][2][1], frame_cache[curr_idx - 1][2][1])  # Detection confidence of t+1 frame\n",
    "            non_dom_small_method_weight = 1.0  # Ideal frames\n",
    "            # Calculate source quality factor\n",
    "            t_plus_1_interp = frame_cache[curr_idx + 1][3][1]\n",
    "            t_minus_1_interp = frame_cache[curr_idx - 1][3][1]\n",
    "            non_dom_small_source_quality = (t_plus_1_interp + t_minus_1_interp) / 2.0\n",
    "            \n",
    "        elif satisfied_symmetric_windows_condition(positive_offset=2, negative_offset=2, is_dom_hand=False):\n",
    "            # Fallback 1: (t+2, t-2)\n",
    "            non_dom_velocity_small_cart = (frame_cache[curr_idx + 2][1] - frame_cache[curr_idx - 2][1]) / 4.0\n",
    "            wrist_velocity_small[1, :] = (frame_cache[curr_idx + 2][7][1, :] - frame_cache[curr_idx - 2][7][1, :]) / 4.0\n",
    "            non_dom_small_conf = min(frame_cache[curr_idx + 2][2][1], frame_cache[curr_idx - 2][2][1]) \n",
    "            non_dom_small_method_weight = 0.8  # Wider symmetric window\n",
    "            # Calculate source quality factor\n",
    "            t_plus_2_interp = frame_cache[curr_idx + 2][3][1]\n",
    "            t_minus_2_interp = frame_cache[curr_idx - 2][3][1]\n",
    "            non_dom_small_source_quality = (t_plus_2_interp + t_minus_2_interp) / 2.0\n",
    "            \n",
    "        elif single_positive_check(positive_offset=2, is_dom_hand=False):\n",
    "            if negative_check(negative_offset=1, is_dom_hand=False):\n",
    "                # Fallback 2: (t+2, t-1)\n",
    "                non_dom_velocity_small_cart = (frame_cache[curr_idx + 2][1] - frame_cache[curr_idx - 1][1]) / 3.0\n",
    "                wrist_velocity_small[1, :] = (frame_cache[curr_idx + 2][7][1, :] - frame_cache[curr_idx - 1][7][1, :]) / 3.0\n",
    "                non_dom_small_conf = min(frame_cache[curr_idx + 2][2][1], frame_cache[curr_idx - 1][2][1])  \n",
    "                non_dom_small_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_2_interp = frame_cache[curr_idx + 2][3][1]\n",
    "                t_minus_1_interp = frame_cache[curr_idx - 1][3][1]\n",
    "                non_dom_small_source_quality = (t_plus_2_interp + t_minus_1_interp) / 2.0\n",
    "                \n",
    "            elif is_valid_detection(curr_frame_data, False):\n",
    "                # Fallback 3: (t+2, t)\n",
    "                non_dom_velocity_small_cart = (frame_cache[curr_idx + 2][1] - curr_frame_data[1]) / 2.0\n",
    "                wrist_velocity_small[1, :] = (frame_cache[curr_idx + 2][7][1, :] - curr_frame_data[7][1, :]) / 2.0\n",
    "                non_dom_small_conf = min(frame_cache[curr_idx + 2][2][1], curr_frame_data[2][1])\n",
    "                non_dom_small_method_weight = 0.4  # One-sided derivative\n",
    "                # Calculate source quality factor\n",
    "                t_plus_2_interp = frame_cache[curr_idx + 2][3][1]\n",
    "                t_interp = curr_frame_data[3][1]\n",
    "                non_dom_small_source_quality = (t_plus_2_interp + t_interp) / 2.0\n",
    "                \n",
    "        elif is_valid_detection(curr_frame_data, False):\n",
    "            if negative_check(negative_offset=1, is_dom_hand=False):\n",
    "                # Fallback 4: (t, t-1)\n",
    "                non_dom_velocity_small_cart = (curr_frame_data[1] - frame_cache[curr_idx - 1][1])\n",
    "                wrist_velocity_small[1, :] = (curr_frame_data[7][1, :] - frame_cache[curr_idx - 1][7][1, :]) \n",
    "                non_dom_small_conf = min(curr_frame_data[2][1], frame_cache[curr_idx - 1][2][1])  # Detection confidence of current frame\n",
    "                non_dom_small_method_weight = 0.4  # One-sided derivative\n",
    "                # Calculate source quality factor\n",
    "                t_interp = curr_frame_data[3][1]\n",
    "                t_minus_1_interp = frame_cache[curr_idx - 1][3][1]\n",
    "                non_dom_small_source_quality = (t_interp + t_minus_1_interp) / 2.0\n",
    "                \n",
    "            elif negative_check(negative_offset=2, is_dom_hand=False):\n",
    "                # Fallback 5: (t, t-2)\n",
    "                non_dom_velocity_small_cart = (curr_frame_data[1] - frame_cache[curr_idx - 2][1]) / 2.0\n",
    "                wrist_velocity_small[1, :] = (curr_frame_data[7][1, :] - frame_cache[curr_idx -2][7][1, :]) / 2.0\n",
    "                non_dom_small_conf = min(curr_frame_data[2][1], frame_cache[curr_idx -2][2][1])  # Detection confidence of current frame\n",
    "                non_dom_small_method_weight = 0.4  # One-sided derivative\n",
    "                # Calculate source quality factor\n",
    "                t_interp = curr_frame_data[3][1]\n",
    "                t_minus_2_interp = frame_cache[curr_idx - 2][3][1]\n",
    "                non_dom_small_source_quality = (t_interp + t_minus_2_interp) / 2.0\n",
    "    \n",
    "        # Large window [-5, +5] velocity with fallbacks for non-dominant hand\n",
    "        if satisfied_symmetric_windows_condition(positive_offset=5, negative_offset=5, is_dom_hand=False):\n",
    "            # Ideal case: (t+5, t-5)\n",
    "            non_dom_velocity_large_cart = (frame_cache[curr_idx + 5][1] - frame_cache[curr_idx - 5][1]) / 10.0\n",
    "            wrist_velocity_large[1, :] = (frame_cache[curr_idx + 5][7][1, :] - frame_cache[curr_idx - 5][7][1, :]) / 10.0\n",
    "            non_dom_large_conf = min(frame_cache[curr_idx + 5][2][1], frame_cache[curr_idx - 5][2][1])  \n",
    "            non_dom_large_method_weight = 1.0  # Ideal frames\n",
    "            # Calculate source quality factor\n",
    "            t_plus_5_interp = frame_cache[curr_idx + 5][3][1]\n",
    "            t_minus_5_interp = frame_cache[curr_idx - 5][3][1]\n",
    "            non_dom_large_source_quality = (t_plus_5_interp + t_minus_5_interp) / 2.0\n",
    "            \n",
    "        elif satisfied_symmetric_windows_condition(positive_offset=4, negative_offset=4, is_dom_hand=False):\n",
    "            # Fallback 1: (t+4, t-4)\n",
    "            non_dom_velocity_large_cart = (frame_cache[curr_idx + 4][1] - frame_cache[curr_idx - 4][1]) / 8.0\n",
    "            wrist_velocity_large[1, :] = (frame_cache[curr_idx + 4][7][1, :] - frame_cache[curr_idx - 4][7][1, :]) / 8.0\n",
    "            non_dom_large_conf = min(frame_cache[curr_idx + 4][2][1], frame_cache[curr_idx - 4][2][1])  \n",
    "            non_dom_large_method_weight = 0.8  # Wider symmetric window\n",
    "            # Calculate source quality factor\n",
    "            t_plus_4_interp = frame_cache[curr_idx + 4][3][1]\n",
    "            t_minus_4_interp = frame_cache[curr_idx - 4][3][1]\n",
    "            non_dom_large_source_quality = (t_plus_4_interp + t_minus_4_interp) / 2.0\n",
    "            \n",
    "        elif satisfied_symmetric_windows_condition(positive_offset=3, negative_offset=3, is_dom_hand=False):\n",
    "            # Fallback 2: (t+3, t-3)\n",
    "            non_dom_velocity_large_cart = (frame_cache[curr_idx + 3][1] - frame_cache[curr_idx - 3][1]) / 6.0\n",
    "            wrist_velocity_large[1, :] = (frame_cache[curr_idx + 3][7][1, :] - frame_cache[curr_idx - 3][7][1, :]) / 6.0\n",
    "            non_dom_large_conf = min(frame_cache[curr_idx + 3][2][1], frame_cache[curr_idx - 3][2][1])  # Detection confidence of t+3 frame\n",
    "            non_dom_large_method_weight = 0.8  # Wider symmetric window\n",
    "            # Calculate source quality factor\n",
    "            t_plus_3_interp = frame_cache[curr_idx + 3][3][1]\n",
    "            t_minus_3_interp = frame_cache[curr_idx - 3][3][1]\n",
    "            non_dom_large_source_quality = (t_plus_3_interp + t_minus_3_interp) / 2.0\n",
    "            \n",
    "        # Asymmetric fallbacks for large window\n",
    "        elif single_positive_check(positive_offset=5, is_dom_hand=False):\n",
    "            if negative_check(negative_offset=4, is_dom_hand=False):\n",
    "                # Fallback 3: (t+5, t-4)\n",
    "                non_dom_velocity_large_cart = (frame_cache[curr_idx + 5][1] - frame_cache[curr_idx - 4][1]) / 9.0\n",
    "                wrist_velocity_large[1, :] = (frame_cache[curr_idx + 5][7][1, :] - frame_cache[curr_idx - 4][7][1, :]) / 9.0\n",
    "                non_dom_large_conf = min(frame_cache[curr_idx + 5][2][1], frame_cache[curr_idx - 4][2][1])  # Detection confidence of t+5 frame\n",
    "                non_dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_5_interp = frame_cache[curr_idx + 5][3][1]\n",
    "                t_minus_4_interp = frame_cache[curr_idx - 4][3][1]\n",
    "                non_dom_large_source_quality = (t_plus_5_interp + t_minus_4_interp) / 2.0\n",
    "                \n",
    "            elif negative_check(negative_offset=3, is_dom_hand=False):\n",
    "                # Fallback 4: (t+5, t-3)\n",
    "                non_dom_velocity_large_cart = (frame_cache[curr_idx + 5][1] - frame_cache[curr_idx - 3][1]) / 8.0\n",
    "                wrist_velocity_large[1, :] = (frame_cache[curr_idx + 5][7][1, :] - frame_cache[curr_idx - 3][7][1, :]) / 8.0\n",
    "                non_dom_large_conf = min(frame_cache[curr_idx + 5][2][1], frame_cache[curr_idx - 3][2][1])  # Detection confidence of t+5 frame\n",
    "                non_dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_5_interp = frame_cache[curr_idx + 5][3][1]\n",
    "                t_minus_3_interp = frame_cache[curr_idx - 3][3][1]\n",
    "                non_dom_large_source_quality = (t_plus_5_interp + t_minus_3_interp) / 2.0\n",
    "                \n",
    "        elif single_positive_check(positive_offset=4, is_dom_hand=False):\n",
    "            if negative_check(negative_offset=5, is_dom_hand=False):\n",
    "                # Fallback 5: (t+4, t-5)\n",
    "                non_dom_velocity_large_cart = (frame_cache[curr_idx + 4][1] - frame_cache[curr_idx - 5][1]) / 9.0\n",
    "                wrist_velocity_large[1, :] = (frame_cache[curr_idx + 4][7][1, :] - frame_cache[curr_idx - 5][7][1, :]) / 9.0\n",
    "                non_dom_large_conf = min(frame_cache[curr_idx + 4][2][1], frame_cache[curr_idx - 5][2][1])  # Detection confidence of t+4 frame\n",
    "                non_dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_4_interp = frame_cache[curr_idx + 4][3][1]\n",
    "                t_minus_5_interp = frame_cache[curr_idx - 5][3][1]\n",
    "                non_dom_large_source_quality = (t_plus_4_interp + t_minus_5_interp) / 2.0\n",
    "                \n",
    "            elif negative_check(negative_offset=3, is_dom_hand=False):\n",
    "                # Fallback 6: (t+4, t-3)\n",
    "                non_dom_velocity_large_cart = (frame_cache[curr_idx + 4][1] - frame_cache[curr_idx - 3][1]) / 7.0\n",
    "                wrist_velocity_large[1, :] = (frame_cache[curr_idx + 4][7][1, :] - frame_cache[curr_idx - 3][7][1, :]) / 7.0\n",
    "                non_dom_large_conf = min(frame_cache[curr_idx + 4][2][1], frame_cache[curr_idx - 3][2][1])  # Detection confidence of t+4 frame\n",
    "                non_dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_4_interp = frame_cache[curr_idx + 4][3][1]\n",
    "                t_minus_3_interp = frame_cache[curr_idx - 3][3][1]\n",
    "                non_dom_large_source_quality = (t_plus_4_interp + t_minus_3_interp) / 2.0\n",
    "                \n",
    "        elif single_positive_check(positive_offset=3, is_dom_hand=False):\n",
    "            if negative_check(negative_offset=5, is_dom_hand=False):\n",
    "                # Fallback 7: (t+3, t-5)\n",
    "                non_dom_velocity_large_cart = (frame_cache[curr_idx + 3][1] - frame_cache[curr_idx - 5][1]) / 8.0\n",
    "                wrist_velocity_large[1, :] = (frame_cache[curr_idx + 3][7][1, :] - frame_cache[curr_idx - 5][7][1, :]) / 8.0\n",
    "                non_dom_large_conf = min(frame_cache[curr_idx + 3][2][1], frame_cache[curr_idx - 5][2][1])  # Detection confidence of t+3 frame\n",
    "                non_dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_3_interp = frame_cache[curr_idx + 3][3][1]\n",
    "                t_minus_5_interp = frame_cache[curr_idx - 5][3][1]\n",
    "                non_dom_large_source_quality = (t_plus_3_interp + t_minus_5_interp) / 2.0\n",
    "            \n",
    "            elif negative_check(negative_offset=4, is_dom_hand=False):\n",
    "                # Fallback 8: (t+3, t-4)\n",
    "                non_dom_velocity_large_cart = (frame_cache[curr_idx + 3][1] - frame_cache[curr_idx - 4][1]) / 7.0\n",
    "                wrist_velocity_large[1, :] = (frame_cache[curr_idx + 3][7][1, :] - frame_cache[curr_idx - 4][7][1, :]) / 7.0\n",
    "                non_dom_large_conf = min(frame_cache[curr_idx + 3][2][1], frame_cache[curr_idx - 4][2][1])  # Detection confidence of t+3 frame\n",
    "                non_dom_large_method_weight = 0.6  # Asymmetric window maintaining center point\n",
    "                # Calculate source quality factor\n",
    "                t_plus_3_interp = frame_cache[curr_idx + 3][3][1]\n",
    "                t_minus_4_interp = frame_cache[curr_idx - 4][3][1]\n",
    "                non_dom_large_source_quality = (t_plus_3_interp + t_minus_4_interp) / 2.0\n",
    "            \n",
    "\n",
    "        \n",
    "        # Convert Cartesian velocities to spherical/polar coordinates\n",
    "        dom_velocity_small = cartesian_to_spherical(dom_velocity_small_cart)\n",
    "        dom_velocity_large = cartesian_to_spherical(dom_velocity_large_cart)\n",
    "        non_dom_velocity_small = cartesian_to_spherical(non_dom_velocity_small_cart)\n",
    "        non_dom_velocity_large = cartesian_to_spherical(non_dom_velocity_large_cart)\n",
    "        \n",
    "        wrist_velocity_small_polar = cartesian_to_polar_features(wrist_velocity_small)\n",
    "        wrist_velocity_large_polar = cartesian_to_polar_features(wrist_velocity_large)\n",
    "        \n",
    "        # Calculate average confidence for each hand across both windows\n",
    "        dom_avg_conf = (dom_small_conf + dom_large_conf) / 2.0\n",
    "        non_dom_avg_conf = (non_dom_small_conf + non_dom_large_conf) / 2.0\n",
    "        \n",
    "        # Calculate velocityCalculationConfidence using method weight and source quality\n",
    "        dom_small_vel_calc_conf = dom_small_method_weight * dom_small_source_quality\n",
    "        dom_large_vel_calc_conf = dom_large_method_weight * dom_large_source_quality\n",
    "        non_dom_small_vel_calc_conf = non_dom_small_method_weight * non_dom_small_source_quality\n",
    "        non_dom_large_vel_calc_conf = non_dom_large_method_weight * non_dom_large_source_quality\n",
    "        \n",
    "        # Average across windows for each hand\n",
    "        dom_vel_calc_conf = (dom_small_vel_calc_conf + dom_large_vel_calc_conf) / 2.0\n",
    "        non_dom_vel_calc_conf = (non_dom_small_vel_calc_conf + non_dom_large_vel_calc_conf) / 2.0\n",
    "        \n",
    "        # Prepare arrays\n",
    "        velocity_confidence = np.array([dom_avg_conf, non_dom_avg_conf])\n",
    "        velocity_calculation_confidence = np.array([dom_vel_calc_conf, non_dom_vel_calc_conf])\n",
    "        \n",
    "        # Save back to the NPZ file\n",
    "        modifications = {\n",
    "            'dom_velocity_small': dom_velocity_small,\n",
    "            'dom_velocity_large': dom_velocity_large,\n",
    "            'non_dom_velocity_small': non_dom_velocity_small,\n",
    "            'non_dom_velocity_large': non_dom_velocity_large,\n",
    "            'velocity_confidence': velocity_confidence,\n",
    "            'velocity_calculation_confidence': velocity_calculation_confidence,\n",
    "            'wrist_velocity_small': wrist_velocity_small_polar,\n",
    "            'wrist_velocity_large': wrist_velocity_large_polar,\n",
    "            \n",
    "        }\n",
    "        \n",
    "        modify_npz_file(current_file_path, modifications)\n",
    "        processed_count += 1\n",
    "        \n",
    "\n",
    "    \n",
    "    print(f\"Velocity computation complete. Processed {processed_count} frames.\")\n",
    "    return processed_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing velocities for 30 files...\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000030_00m30s000ms.npz\n",
      "Frame 30 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000031_00m31s000ms.npz\n",
      "Frame 31 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000032_00m32s000ms.npz\n",
      "Frame 32 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000033_00m33s000ms.npz\n",
      "Frame 33 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000034_00m34s000ms.npz\n",
      "Frame 34 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000035_00m35s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000037_00m37s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000038_00m38s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000039_00m39s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000040_00m40s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000041_00m41s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000042_00m42s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000043_00m43s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000044_00m44s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000045_00m45s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000046_00m46s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000047_00m47s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000048_00m48s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000049_00m49s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000050_00m50s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000051_00m51s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000052_00m52s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000053_00m53s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000054_00m54s000ms.npz\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000055_00m55s000ms.npz\n",
      "Frame 55 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000056_00m56s000ms.npz\n",
      "Frame 56 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000057_00m57s000ms.npz\n",
      "Frame 57 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000058_00m58s000ms.npz\n",
      "Frame 58 too close to video boundary - setting zero velocities\n",
      "Adding new array 'dom_velocity_small' to the file\n",
      "Adding new array 'dom_velocity_large' to the file\n",
      "Adding new array 'non_dom_velocity_small' to the file\n",
      "Adding new array 'non_dom_velocity_large' to the file\n",
      "Adding new array 'velocity_confidence' to the file\n",
      "Adding new array 'velocity_calculation_confidence' to the file\n",
      "Adding new array 'wrist_velocity_small' to the file\n",
      "Adding new array 'wrist_velocity_large' to the file\n",
      "Successfully modified/added 8 arrays in youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000059_00m59s000ms.npz\n",
      "Frame 59 too close to video boundary - setting zero velocities\n",
      "Velocity computation complete. Processed 30 frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_landmark_velocities(directory_path=\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frame_data_with_velocities(npz_path):\n",
    "    \"\"\"\n",
    "    Load saved frame data from an NPZ file.\n",
    "    \n",
    "    Args:\n",
    "        npz_path (str): Path to the saved .npz file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: All the detection results for the frame\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path)\n",
    "    \n",
    "    # Extract all arrays from the npz file\n",
    "    dom_landmarks = data['dom_landmarks']\n",
    "    non_dom_landmarks = data['non_dom_landmarks']\n",
    "    confidence_scores = data['confidence_scores']\n",
    "    interpolation_scores = data['interpolation_scores']\n",
    "    detection_status = data['detection_status']\n",
    "    blendshape_scores = data['blendshape_scores']\n",
    "    face_detected = data['face_detected'].item()  # Convert 0-d array to scalar\n",
    "    nose_to_wrist_dist = data['nose_to_wrist_dist']\n",
    "    frame_idx = data['frame_idx'].item()\n",
    "    timestamp_ms = data['timestamp_ms'].item()\n",
    "    dom_velocity_small = data['dom_velocity_small']\n",
    "    dom_velocity_large = data['dom_velocity_large']\n",
    "    non_dom_velocity_small = data['non_dom_velocity_small']\n",
    "    non_dom_velocity_large = data['non_dom_velocity_large']\n",
    "    velocity_confidence = data['velocity_confidence']\n",
    "    velocity_calculation_confidence = data['velocity_calculation_confidence']\n",
    "    nose_to_wrist_velocity_small = data['wrist_velocity_small']\n",
    "    nose_to_wrist_velocity_large = data['wrist_velocity_large']\n",
    "    \n",
    "    return (dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores,\n",
    "            detection_status, blendshape_scores, face_detected, \n",
    "            nose_to_wrist_dist, frame_idx, timestamp_ms, dom_velocity_small, dom_velocity_large, non_dom_velocity_small, non_dom_velocity_large, velocity_confidence, velocity_calculation_confidence, nose_to_wrist_velocity_small, nose_to_wrist_velocity_large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_30 = load_frame_data_with_velocities(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000030_00m30s000ms.npz\")\n",
    "frame_37 = load_frame_data_with_velocities(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000037_00m37s000ms.npz\")\n",
    "frame_42 = load_frame_data_with_velocities(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000042_00m42s000ms.npz\")\n",
    "frame_32 = load_frame_data_with_velocities(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000032_00m32s000ms.npz\")\n",
    "frame_36 = load_frame_data_with_velocities(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\")\n",
    "frame_38 = load_frame_data_with_velocities(\"youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000038_00m38s000ms.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_videos_df(directory_path):\n",
    "    \"\"\"\n",
    "    Process video files in a directory and return information in a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    directory_path (str): Path to the directory containing video files\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: DataFrame with video name, frame count, fps, Right/Left designation, and file path\n",
    "    \"\"\"\n",
    "    # Lists to store video information\n",
    "    data = []\n",
    "    \n",
    "    # Common video extensions\n",
    "    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv']\n",
    "    \n",
    "    # Walk through the directory\n",
    "    for root, _, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            # Check if the file is a video\n",
    "            _, ext = os.path.splitext(file)\n",
    "            if ext.lower() in video_extensions:\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Extract video name (without extension)\n",
    "                video_name = os.path.splitext(file)[0]\n",
    "                \n",
    "                # Determine if it's Right or Left\n",
    "                if video_name.endswith(\"_R\"):\n",
    "                    dom_hand = \"Right\"\n",
    "                elif video_name.endswith(\"_L\"):\n",
    "                    dom_hand = \"Left\"\n",
    "                else:\n",
    "                    dom_hand = None\n",
    "                \n",
    "                # Open the video file\n",
    "                try:\n",
    "                    cap = cv2.VideoCapture(file_path)\n",
    "                    \n",
    "                    # Get frames per second\n",
    "                    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "                    \n",
    "                    # Get total number of frames\n",
    "                    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                    \n",
    "                    # Release the video capture object\n",
    "                    cap.release()\n",
    "                    \n",
    "                    # Add row to data\n",
    "                    data.append({\n",
    "                        'Video Name': video_name,\n",
    "                        'Frame Count': frame_count,\n",
    "                        'FPS': fps,\n",
    "                        'dom_hand': dom_hand,\n",
    "                        'file_path': file_path  # Added file_path to the DataFrame\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {file}: {e}\")\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_df = make_videos_df(directory_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "Name: Frame Count, dtype: bool"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df['Frame Count'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_new_2(video_path, adaptive_detect_func=adaptive_detect, hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                 min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5,\n",
    "                 min_face_detection_confidence=0.5, min_face_presence_confidence=0.5,\n",
    "                 num_hands=2, output_face_blendshapes=True,\n",
    "                 max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2, \n",
    "                 frame_step=1, start_time_seconds=0, end_time_seconds=None,\n",
    "                 save_failure_screenshots=False,\n",
    "                 num_workers=None,  # Added parameter for parallel processing\n",
    "                 batch_mode=False):  # Added parameter to indicate batch processing\n",
    "    \"\"\"\n",
    "    Process a video frame-by-frame using the adaptive_detect function and save results.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the video file\n",
    "        adaptive_detect_func: The adaptive detection function to use\n",
    "        min_hand_detection_confidence (float): Initial confidence threshold for hand detection\n",
    "        min_hand_presence_confidence (float): Initial confidence threshold for hand presence\n",
    "        min_face_detection_confidence (float): Initial confidence threshold for face detection\n",
    "        min_face_presence_confidence (float): Initial confidence threshold for face presence\n",
    "        num_hands (int): Maximum number of hands to detect\n",
    "        dominand_hand (str): Dominant hand preference ('Left' or 'Right')\n",
    "        output_face_blendshapes (bool): Whether to detect face blendshapes\n",
    "        max_attempts (int): Maximum detection attempts for adaptive detection\n",
    "        threshold_reduction_factor (float): Factor to reduce thresholds by\n",
    "        min_threshold (float): Minimum threshold limit\n",
    "        frame_step (int): Process every Nth frame (1 = all frames)\n",
    "        start_time_seconds (float): Time in seconds to start processing from\n",
    "        end_time_seconds (float): Time in seconds to end processing (None = process until end)\n",
    "        save_failure_screenshots (bool): Save screenshots for all frames with any detection failures\n",
    "        num_workers (int): Number of parallel workers to use (None = auto-detect based on CPU cores)\n",
    "        batch_mode (bool): Whether this is being run as part of a batch process\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the directory containing saved frame results\n",
    "    \"\"\"\n",
    "    # Import additional libraries for parallel processing\n",
    "\n",
    "    import threading\n",
    "    from queue import Queue\n",
    "\n",
    "\n",
    "    # Extract video name for directory creation\n",
    "    video_path = Path(video_path)\n",
    "    video_dir = video_path.parent\n",
    "    video_name = video_path.stem  # Get filename without extension\n",
    "    \n",
    "    # Extract dominant hand information from filename\n",
    "    if video_name.endswith(\"_R\"):\n",
    "        extracted_dominant_hand = \"Right\"\n",
    "    elif video_name.endswith(\"_L\"):\n",
    "        extracted_dominant_hand = \"Left\"\n",
    "    else:\n",
    "        # Default if not specified in filename\n",
    "        extracted_dominant_hand = \"Right\"\n",
    "        print(f\"Warning: Could not determine dominant hand from filename, using default: {extracted_dominant_hand}\")\n",
    "\n",
    "    # Use the extracted dominant hand instead of the parameter\n",
    "    dominand_hand = extracted_dominant_hand\n",
    "    if not batch_mode:\n",
    "        print(f\"Detected dominant hand from filename: {dominand_hand}\")\n",
    "    else:\n",
    "        print(f\"[{os.path.basename(str(video_path))}] Dominant hand: {dominand_hand}\")\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = video_dir / f\"{video_name}_landmarks\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create screenshots directory if screenshot option is enabled\n",
    "    screenshots_dir = None\n",
    "    if save_failure_screenshots:\n",
    "        screenshots_dir = output_dir / \"failure_screenshots\"\n",
    "        screenshots_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create a log file to track processing\n",
    "    log_file = output_dir / \"processing_log.txt\"\n",
    "    \n",
    "    # Create a detailed statistics file\n",
    "    stats_file = output_dir / \"detection_statistics.json\"\n",
    "\n",
    "    # Initialize statistics tracking\n",
    "    stats = {\n",
    "        \"video_info\": {\n",
    "            \"name\": video_name,\n",
    "            \"path\": str(video_path),\n",
    "            \"total_frames\": 0,\n",
    "            \"processed_frames\": 0,\n",
    "            \"fps\": 0,\n",
    "            \"duration_seconds\": 0,\n",
    "            \"start_time\": start_time_seconds,\n",
    "            \"end_time\": end_time_seconds,\n",
    "            \"dominant_hand\": dominand_hand,\n",
    "            \"processing_started\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"processing_completed\": None\n",
    "        },\n",
    "        \"detection_rates\": {\n",
    "            \"dominant_hand\": {\n",
    "                \"detected\": 0,\n",
    "                \"failed\": 0,\n",
    "                \"detection_rate\": 0\n",
    "            },\n",
    "            \"non_dominant_hand\": {\n",
    "                \"detected\": 0,\n",
    "                \"failed\": 0,\n",
    "                \"detection_rate\": 0\n",
    "            },\n",
    "            \"face\": {\n",
    "                \"detected\": 0,\n",
    "                \"failed\": 0,\n",
    "                \"detection_rate\": 0\n",
    "            },\n",
    "            \"overall\": {\n",
    "                \"all_detected\": 0,\n",
    "                \"partial_detections\": 0,\n",
    "                \"no_detections\": 0,\n",
    "                \"success_rate\": 0\n",
    "            }\n",
    "        },\n",
    "        \"failed_frames\": {\n",
    "            \"dominant_hand_failures\": [],\n",
    "            \"non_dominant_hand_failures\": [],\n",
    "            \"face_failures\": [],\n",
    "            \"all_failures\": []\n",
    "        },\n",
    "        \"processing_performance\": {\n",
    "            \"average_processing_time_ms\": 0,\n",
    "            \"total_processing_time_seconds\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Setup logging\n",
    "    with open(log_file, \"w\") as log:\n",
    "        log.write(f\"Processing video: {video_path}\\n\")\n",
    "        log.write(f\"Started at: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        log.write(f\"Parameters:\\n\")\n",
    "        log.write(f\"  - frame_step: {frame_step}\\n\")\n",
    "        log.write(f\"  - start_time: {start_time_seconds} seconds\\n\")\n",
    "        if end_time_seconds is not None:\n",
    "            log.write(f\"  - end_time: {end_time_seconds} seconds\\n\")\n",
    "        log.write(f\"  - dominand_hand: {dominand_hand}\\n\")\n",
    "        log.write(f\"  - num_hands: {num_hands}\\n\")\n",
    "        log.write(f\"  - detection confidence thresholds: {min_hand_detection_confidence}, {min_face_detection_confidence}\\n\")\n",
    "        log.write(f\"  - batch_mode: {batch_mode}\\n\")\n",
    "        log.write(\"\\n--- Frame processing log ---\\n\")\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration_seconds = total_frames / fps if fps > 0 else 0\n",
    "    \n",
    "    # Update stats with video info\n",
    "    stats[\"video_info\"][\"total_frames\"] = total_frames\n",
    "    stats[\"video_info\"][\"fps\"] = fps\n",
    "    stats[\"video_info\"][\"duration_seconds\"] = duration_seconds\n",
    "    if end_time_seconds==None:\n",
    "        stats[\"video_info\"][\"end_time\"] = duration_seconds\n",
    "    \n",
    "    # Convert time to frame indices\n",
    "    start_frame = int(max(0, start_time_seconds * fps))\n",
    "    \n",
    "    # Set end frame if specified\n",
    "    if end_time_seconds is not None:\n",
    "        end_frame = min(total_frames, int(end_time_seconds * fps))\n",
    "    else:\n",
    "        end_frame = total_frames\n",
    "    \n",
    "    # Set the number of worker threads if not specified\n",
    "    if num_workers is None:\n",
    "        # More conservative thread allocation to prevent system overload\n",
    "        # Use 50% of available cores (minimum 2, maximum 6) to leave resources for other processes\n",
    "        num_workers = max(2, min(multiprocessing.cpu_count() // 2, 6))\n",
    "    \n",
    "    # When in batch mode, conserve resources even more and limit output\n",
    "    if batch_mode:\n",
    "        # Further reduce threads in batch mode to ensure stability\n",
    "        num_workers = 1\n",
    "        print(f\"[{os.path.basename(str(video_path))}] Using {num_workers} worker threads\")\n",
    "    else:\n",
    "        print(f\"Video: {video_name}\")\n",
    "        print(f\"Total frames: {total_frames}\")\n",
    "        print(f\"FPS: {fps}\")\n",
    "        print(f\"Duration: {duration_seconds:.2f} seconds\")\n",
    "        print(f\"Processing frames {start_frame} to {end_frame} (time {start_time_seconds:.2f}s to {end_time_seconds if end_time_seconds is not None else duration_seconds:.2f}s)\")\n",
    "        print(f\"Output directory: {output_dir}\")\n",
    "        print(f\"Using {num_workers} worker threads for parallel processing\")\n",
    "    \n",
    "    # Function to process a single frame\n",
    "    def process_single_frame(args):\n",
    "        frame, frame_idx, temp_dir = args\n",
    "        \n",
    "        # Get timestamp in milliseconds\n",
    "        timestamp_ms = int(frame_idx * 1000 / fps)\n",
    "        timestamp_formatted = f\"{timestamp_ms//60000:02d}m{(timestamp_ms//1000)%60:02d}s{timestamp_ms%1000:03d}ms\"\n",
    "        \n",
    "        # Temporary frame path\n",
    "        temp_frame_path = Path(temp_dir) / f\"temp_frame_{frame_idx}.jpg\"\n",
    "        \n",
    "        # Save the current frame as an image\n",
    "        cv2.imwrite(str(temp_frame_path), frame)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            with SuppressOutput():\n",
    "                # Use adaptive_detect on the frame\n",
    "                results = adaptive_detect_func(\n",
    "                    str(temp_frame_path), hand_model_path, face_model_path,\n",
    "                    min_hand_detection_confidence=min_hand_detection_confidence,\n",
    "                    min_hand_presence_confidence=min_hand_presence_confidence,\n",
    "                    min_face_detection_confidence=min_face_detection_confidence,\n",
    "                    min_face_presence_confidence=min_face_presence_confidence,\n",
    "                    num_hands=num_hands,\n",
    "                    dominand_hand=dominand_hand,\n",
    "                    visualize=False,\n",
    "                    output_face_blendshapes=output_face_blendshapes,\n",
    "                    max_attempts=max_attempts,\n",
    "                    threshold_reduction_factor=threshold_reduction_factor,\n",
    "                    min_threshold=min_threshold\n",
    "                )\n",
    "            \n",
    "            # Calculate processing time\n",
    "            proc_time = time.time() - start_time\n",
    "            \n",
    "            # Create output filename with frame info\n",
    "            output_filename = f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}.npz\"\n",
    "            output_path = output_dir / output_filename\n",
    "            \n",
    "            # Unpack results\n",
    "            dom_landmarks, non_dom_landmarks, confidence_scores, interpolation_scores, detection_status, blendshape_scores, face_detected, nose_to_wrist_dist = results\n",
    "            \n",
    "            # Save screenshot if any detection failed and screenshots are enabled\n",
    "            if save_failure_screenshots and (detection_status[0] != 1 or detection_status[1] != 1 or face_detected != 1):\n",
    "                # Create a detailed failure type description for the filename\n",
    "                failure_type = []\n",
    "                if detection_status[0] != 1:\n",
    "                    failure_type.append(\"DomHand\")\n",
    "                if detection_status[1] != 1:\n",
    "                    failure_type.append(\"NonDomHand\")\n",
    "                if face_detected != 1:\n",
    "                    failure_type.append(\"Face\")\n",
    "                \n",
    "                failure_str = \"_\".join(failure_type)\n",
    "                screenshot_filename = f\"{video_name}_frame{frame_idx:06d}_{timestamp_formatted}_missing_{failure_str}.jpg\"\n",
    "                screenshot_path = screenshots_dir / screenshot_filename\n",
    "                \n",
    "                # Copy the frame to the screenshots directory\n",
    "                cv2.imwrite(str(screenshot_path), frame)\n",
    "            \n",
    "            # Save all results in a single .npz file\n",
    "            np.savez(\n",
    "                output_path,\n",
    "                dom_landmarks=dom_landmarks,\n",
    "                non_dom_landmarks=non_dom_landmarks,\n",
    "                confidence_scores=confidence_scores,\n",
    "                interpolation_scores=interpolation_scores,\n",
    "                detection_status=detection_status,\n",
    "                blendshape_scores=blendshape_scores,\n",
    "                face_detected=face_detected,\n",
    "                nose_to_wrist_dist=nose_to_wrist_dist,\n",
    "                frame_idx=np.array([frame_idx]),\n",
    "                timestamp_ms=np.array([timestamp_ms])\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"frame_idx\": frame_idx,\n",
    "                \"timestamp_ms\": timestamp_ms,\n",
    "                \"timestamp_formatted\": timestamp_formatted,\n",
    "                \"detection_status\": detection_status,\n",
    "                \"face_detected\": face_detected,\n",
    "                \"proc_time\": proc_time\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"frame_idx\": frame_idx,\n",
    "                \"timestamp_ms\": timestamp_ms,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "        finally:\n",
    "            # Clean up temporary frame file\n",
    "            if temp_frame_path.exists():\n",
    "                try:\n",
    "                    temp_frame_path.unlink()\n",
    "                except:\n",
    "                    pass  # Ignore errors during cleanup\n",
    "    \n",
    "    # Create a thread-safe lock for updating the progress bar to avoid output issues\n",
    "    progress_lock = threading.Lock()\n",
    "    \n",
    "    # Collect frames to process\n",
    "    frames_to_process = []\n",
    "    frame_idx = start_frame\n",
    "    \n",
    "    # Skip to start_frame\n",
    "    if start_frame > 0:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    \n",
    "    # Process frames\n",
    "    processed_count = 0\n",
    "    total_processing_time = 0\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        if not batch_mode:\n",
    "            print(\"Reading frames to process...\")\n",
    "        \n",
    "        # First phase: Read all frames to process\n",
    "        while frame_idx < end_frame:\n",
    "            # Read the next frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break  # End of video\n",
    "            \n",
    "            # Only process every frame_step frames\n",
    "            if (frame_idx - start_frame) % frame_step == 0:\n",
    "                frames_to_process.append((frame.copy(), frame_idx, temp_dir))\n",
    "            \n",
    "            frame_idx += 1\n",
    "        \n",
    "        # Release the video capture to free resources\n",
    "        cap.release()\n",
    "        \n",
    "        if not batch_mode:\n",
    "            print(f\"Starting parallel processing of {len(frames_to_process)} frames with {num_workers} workers...\")\n",
    "        \n",
    "        try:\n",
    "            # Process frames in parallel using ThreadPoolExecutor\n",
    "            # Use a context manager to ensure all resources are properly released\n",
    "            with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "                # Submit all frame processing tasks\n",
    "                futures = [executor.submit(process_single_frame, args) for args in frames_to_process]\n",
    "                \n",
    "                # Process results as they complete\n",
    "                for i, future in enumerate(as_completed(futures)):\n",
    "                    result = future.result()\n",
    "                    \n",
    "                    if result[\"success\"]:\n",
    "                        frame_idx = result[\"frame_idx\"]\n",
    "                        detection_status = result[\"detection_status\"]\n",
    "                        face_detected = result[\"face_detected\"]\n",
    "                        proc_time = result[\"proc_time\"]\n",
    "                        \n",
    "                        # Update detection statistics\n",
    "                        dom_hand_detected = detection_status[0] == 1\n",
    "                        non_dom_hand_detected = detection_status[1] == 1\n",
    "                        face_was_detected = face_detected == 1\n",
    "                        \n",
    "                        if dom_hand_detected:\n",
    "                            stats[\"detection_rates\"][\"dominant_hand\"][\"detected\"] += 1\n",
    "                        else:\n",
    "                            stats[\"detection_rates\"][\"dominant_hand\"][\"failed\"] += 1\n",
    "                            stats[\"failed_frames\"][\"dominant_hand_failures\"].append({\n",
    "                                \"frame\": frame_idx,\n",
    "                                \"timestamp_ms\": result[\"timestamp_ms\"],\n",
    "                                \"file\": f\"{video_name}_frame{frame_idx:06d}_{result['timestamp_formatted']}.npz\"\n",
    "                            })\n",
    "                        \n",
    "                        if non_dom_hand_detected:\n",
    "                            stats[\"detection_rates\"][\"non_dominant_hand\"][\"detected\"] += 1\n",
    "                        else:\n",
    "                            stats[\"detection_rates\"][\"non_dominant_hand\"][\"failed\"] += 1\n",
    "                            stats[\"failed_frames\"][\"non_dominant_hand_failures\"].append({\n",
    "                                \"frame\": frame_idx,\n",
    "                                \"timestamp_ms\": result[\"timestamp_ms\"],\n",
    "                                \"file\": f\"{video_name}_frame{frame_idx:06d}_{result['timestamp_formatted']}.npz\"\n",
    "                            })\n",
    "                        \n",
    "                        if face_was_detected:\n",
    "                            stats[\"detection_rates\"][\"face\"][\"detected\"] += 1\n",
    "                        else:\n",
    "                            stats[\"detection_rates\"][\"face\"][\"failed\"] += 1\n",
    "                            stats[\"failed_frames\"][\"face_failures\"].append({\n",
    "                                \"frame\": frame_idx,\n",
    "                                \"timestamp_ms\": result[\"timestamp_ms\"],\n",
    "                                \"file\": f\"{video_name}_frame{frame_idx:06d}_{result['timestamp_formatted']}.npz\"\n",
    "                            })\n",
    "                        \n",
    "                        # Track combined detection status\n",
    "                        detection_count = dom_hand_detected + non_dom_hand_detected + face_was_detected\n",
    "                        \n",
    "                        if detection_count == 3:\n",
    "                            stats[\"detection_rates\"][\"overall\"][\"all_detected\"] += 1\n",
    "                        elif detection_count == 0:\n",
    "                            stats[\"detection_rates\"][\"overall\"][\"no_detections\"] += 1\n",
    "                            stats[\"failed_frames\"][\"all_failures\"].append({\n",
    "                                \"frame\": frame_idx,\n",
    "                                \"timestamp_ms\": result[\"timestamp_ms\"],\n",
    "                                \"file\": f\"{video_name}_frame{frame_idx:06d}_{result['timestamp_formatted']}.npz\"\n",
    "                            })\n",
    "                        else:\n",
    "                            stats[\"detection_rates\"][\"overall\"][\"partial_detections\"] += 1\n",
    "                        \n",
    "                        # Update processing log\n",
    "                        detection_summary = f\"Dom: {detection_status[0]}, Non-dom: {detection_status[1]}, Face: {face_detected}\"\n",
    "                        log_entry = f\"Frame {frame_idx}: {detection_summary} (proc time: {proc_time:.2f}s)\\n\"\n",
    "                        \n",
    "                        with open(log_file, \"a\") as log:\n",
    "                            log.write(log_entry)\n",
    "                        \n",
    "                        total_processing_time += proc_time\n",
    "                        processed_count += 1\n",
    "                        \n",
    "                        # Update progress with thread safety, but only if not in batch mode\n",
    "                        # This prevents console output conflicts when running in batch\n",
    "                        if not batch_mode:\n",
    "                            with progress_lock:\n",
    "                                update_progress(frame_idx, total_frames, result[\"timestamp_formatted\"])\n",
    "                                \n",
    "                    else:\n",
    "                        # Handle error\n",
    "                        with open(log_file, \"a\") as log:\n",
    "                            log.write(f\"Error on frame {result['frame_idx']}: {result['error']}\\n\")\n",
    "                        \n",
    "                        # Update progress (even for errors), but only if not in batch mode\n",
    "                        if not batch_mode:\n",
    "                            with progress_lock:\n",
    "                                update_progress(result['frame_idx'], total_frames, \"ERROR\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during parallel processing: {str(e)}\")\n",
    "            # Continue with cleanup to ensure resources are released\n",
    "        finally:\n",
    "            # Clear the frames_to_process list to free memory\n",
    "            frames_to_process.clear()\n",
    "    \n",
    "    # Update final statistics\n",
    "    stats[\"video_info\"][\"processed_frames\"] = processed_count\n",
    "    stats[\"video_info\"][\"processing_completed\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # Calculate detection rates\n",
    "    if processed_count > 0:\n",
    "        stats[\"detection_rates\"][\"dominant_hand\"][\"detection_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"dominant_hand\"][\"detected\"] / processed_count * 100\n",
    "        )\n",
    "        stats[\"detection_rates\"][\"non_dominant_hand\"][\"detection_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"non_dominant_hand\"][\"detected\"] / processed_count * 100\n",
    "        )\n",
    "        stats[\"detection_rates\"][\"face\"][\"detection_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"face\"][\"detected\"] / processed_count * 100\n",
    "        )\n",
    "        stats[\"detection_rates\"][\"overall\"][\"success_rate\"] = (\n",
    "            stats[\"detection_rates\"][\"overall\"][\"all_detected\"] / processed_count * 100\n",
    "        )\n",
    "    \n",
    "    # Calculate processing performance\n",
    "    if processed_count > 0:\n",
    "        stats[\"processing_performance\"][\"average_processing_time_ms\"] = (\n",
    "            total_processing_time / processed_count * 1000\n",
    "        )\n",
    "    stats[\"processing_performance\"][\"total_processing_time_seconds\"] = total_processing_time\n",
    "    \n",
    "    # Save statistics to JSON file\n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    \n",
    "    # Add summary statistics to log file\n",
    "    with open(log_file, \"a\") as log:\n",
    "        log.write(f\"\\n\\n===== PROCESSING SUMMARY =====\\n\")\n",
    "        log.write(f\"Completed at: {stats['video_info']['processing_completed']}\\n\")\n",
    "        log.write(f\"Frames processed: {processed_count} from {start_frame} to {min(end_frame, frame_idx-1)}\\n\\n\")\n",
    "        \n",
    "        log.write(\"DETECTION RATES:\\n\")\n",
    "        log.write(f\"  Dominant hand ({dominand_hand}): {stats['detection_rates']['dominant_hand']['detection_rate']:.1f}%\\n\")\n",
    "        log.write(f\"  Non-dominant hand: {stats['detection_rates']['non_dominant_hand']['detection_rate']:.1f}%\\n\")\n",
    "        log.write(f\"  Face: {stats['detection_rates']['face']['detection_rate']:.1f}%\\n\")\n",
    "        log.write(f\"  All parts detected: {stats['detection_rates']['overall']['success_rate']:.1f}%\\n\\n\")\n",
    "        \n",
    "        log.write(\"DETECTION FAILURES:\\n\")\n",
    "        log.write(f\"  Frames with dominant hand failures: {len(stats['failed_frames']['dominant_hand_failures'])}\\n\")\n",
    "        log.write(f\"  Frames with non-dominant hand failures: {len(stats['failed_frames']['non_dominant_hand_failures'])}\\n\")\n",
    "        log.write(f\"  Frames with face failures: {len(stats['failed_frames']['face_failures'])}\\n\")\n",
    "        log.write(f\"  Frames with all parts missing: {len(stats['failed_frames']['all_failures'])}\\n\\n\")\n",
    "        \n",
    "        log.write(\"PERFORMANCE:\\n\")\n",
    "        log.write(f\"  Average processing time per frame: {stats['processing_performance']['average_processing_time_ms']:.2f} ms\\n\")\n",
    "        log.write(f\"  Total processing time: {stats['processing_performance']['total_processing_time_seconds']:.2f} seconds\\n\")\n",
    "    \n",
    "    # Adjust summary output based on batch mode\n",
    "    if batch_mode:\n",
    "        print(f\"[{os.path.basename(str(video_path))}] Processed {processed_count} frames: \" +\n",
    "              f\"Dom: {stats['detection_rates']['dominant_hand']['detection_rate']:.1f}%, \" +\n",
    "              f\"Non-dom: {stats['detection_rates']['non_dominant_hand']['detection_rate']:.1f}%, \" +\n",
    "              f\"Face: {stats['detection_rates']['face']['detection_rate']:.1f}%\")\n",
    "    else:\n",
    "        print(f\"\\n===== PROCESSING SUMMARY =====\")\n",
    "        print(f\"Processed {processed_count} frames\")\n",
    "        print(f\"Detection rates: Dom hand: {stats['detection_rates']['dominant_hand']['detection_rate']:.1f}%, \" +\n",
    "              f\"Non-dom hand: {stats['detection_rates']['non_dominant_hand']['detection_rate']:.1f}%, \" +\n",
    "              f\"Face: {stats['detection_rates']['face']['detection_rate']:.1f}%\")\n",
    "        print(f\"All parts detected in {stats['detection_rates']['overall']['success_rate']:.1f}% of frames\")\n",
    "        print(f\"Full statistics saved to: {stats_file}\")\n",
    "        print(f\"Results saved to: {output_dir}\")\n",
    "        \n",
    "    # Force garbage collection to free memory\n",
    "    # This is especially important in batch processing\n",
    "    gc.collect()\n",
    "    \n",
    "    return str(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "process_video_new_2(video_path=\"./youtube_DNViaspA8hM_1920x1080_h264_fps10.mp4\", adaptive_detect_func=adaptive_detect, hand_model_path=hand_model_path, face_model_path=face_model_path,\n",
    "                 min_hand_detection_confidence=0.5, min_hand_presence_confidence=0.5,\n",
    "                 min_face_detection_confidence=0.5, min_face_presence_confidence=0.5,\n",
    "                 num_hands=2, output_face_blendshapes=True,\n",
    "                 max_attempts=3, threshold_reduction_factor=0.7, min_threshold=0.2, \n",
    "                 frame_step=1, start_time_seconds=0, end_time_seconds=None,\n",
    "                 save_failure_screenshots=False,\n",
    "                 num_workers=None,  # Added parameter for parallel processing\n",
    "                 batch_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_call_process_video(video_path, start_time_seconds=0, end_time_seconds=None):\n",
    "    \"\"\"\n",
    "    Wrapper function to call process_video with optimized settings for batch processing\n",
    "    with improved output visibility\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    \n",
    "    # Print directly with flush to ensure output is visible immediately\n",
    "    print(f\"\\nStarting processing of video: {os.path.basename(video_path)}\", flush=True)\n",
    "    \n",
    "    # Set batch_mode to True and use conservative worker count\n",
    "    result = process_video_new_2(\n",
    "        video_path=video_path,\n",
    "        adaptive_detect_func=adaptive_detect,  # Use your actual adaptive_detect function\n",
    "        hand_model_path=hand_model_path,  # Use your actual path\n",
    "        face_model_path=face_model_path,  # Use your actual path\n",
    "        start_time_seconds=start_time_seconds,\n",
    "        end_time_seconds=end_time_seconds,\n",
    "        # Enable batch mode for reduced console output and resource usage\n",
    "        batch_mode=True,  \n",
    "        # Conservative worker count to prevent system overload\n",
    "        num_workers=1\n",
    "    )\n",
    "    \n",
    "    # Print completion confirmation with flush to ensure visibility\n",
    "    print(f\"Completed processing of video: {os.path.basename(video_path)}\", flush=True)\n",
    "    \n",
    "    # Force stdout to flush\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_call_process_video_with_output(video_path, start_time_seconds=0, end_time_seconds=None):\n",
    "    \"\"\"Wrapper with explicit console output\"\"\"\n",
    "    import sys\n",
    "    \n",
    "    print(f\"\\nStarting processing of video: {os.path.basename(video_path)}\", flush=True)\n",
    "    \n",
    "    # Call the original function\n",
    "    result = batch_call_process_video(video_path, start_time_seconds, end_time_seconds)\n",
    "    \n",
    "    print(f\"Completed processing of video: {os.path.basename(video_path)}\", flush=True)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_videos(video_df, process_video_func, detection_threshold_dom, detection_threshold_non_dom, \n",
    "                         detection_threshold_dom_small_length, detection_threshold_non_dom_small_length, report_dir, \n",
    "                         start_time_seconds=0, end_time_seconds=None, delete_videos=False, \n",
    "                         start_from_row=0):\n",
    "    \"\"\"\n",
    "    Process multiple videos from a pandas dataframe with memory-efficient operation.\n",
    "    \n",
    "    This function processes videos one by one, storing detailed results on disk rather than in memory.\n",
    "    This approach prevents memory growth regardless of how many videos are processed, making it\n",
    "    suitable for processing thousands of videos in a single run.\n",
    "    \n",
    "\n",
    "    \n",
    "    Args:\n",
    "        video_df (pandas.DataFrame): DataFrame with 'file_path', 'FPS', and 'Frame Count' columns\n",
    "        process_video_func: The process_video function to use for processing each video\n",
    "        detection_threshold_dom (float): Minimum detection rate (%) for dominant hand\n",
    "        detection_threshold_non_dom (float): Minimum detection rate (%) for non-dominant hand\n",
    "        detection_threshold_dom_small_length (float): Threshold for short videos (dominant hand)\n",
    "        detection_threshold_non_dom_small_length (float): Threshold for short videos (non-dominant hand)\n",
    "        start_time_seconds (float): Start time for video processing\n",
    "        end_time_seconds (float): End time for video processing\n",
    "        delete_videos (bool): Whether to delete original videos after processing\n",
    "        start_from_row (int): Index to start processing from (for resuming previous runs)\n",
    "        report_dir (str): Directory to store reports and detailed results\n",
    "        \n",
    "    Returns:\n",
    "        str: Path to the generated report JSON file\n",
    "    \"\"\"\n",
    "    # Create report directory structure\n",
    "    os.makedirs(report_dir, exist_ok=True)\n",
    "    details_dir = os.path.join(report_dir, \"video_details\")\n",
    "    os.makedirs(details_dir, exist_ok=True)\n",
    "    \n",
    "    # Define report file paths\n",
    "    current_report_path = os.path.join(report_dir, \"video_processing_report_current.json\")\n",
    "    temp_report_path = os.path.join(report_dir, \"video_processing_report_temp.json\")\n",
    "    \n",
    "    # Initialize statistics for logging\n",
    "    if start_from_row > 0 and os.path.exists(current_report_path):\n",
    "        # Load previous summary statistics if resuming\n",
    "        print(f\"Loading previous report from {current_report_path}\")\n",
    "        try:\n",
    "            with open(current_report_path, \"r\") as f:\n",
    "                stats = json.load(f)\n",
    "            \n",
    "            # Update resume information\n",
    "            stats[\"processing_info\"][\"resume_time\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            stats[\"processing_info\"][\"resumed_from_row\"] = start_from_row\n",
    "            \n",
    "            print(f\"Successfully loaded previous report summary\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading previous report: {e}\")\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        stats = None\n",
    "        \n",
    "    # Create new statistics if not resuming or if loading failed\n",
    "    if stats is None:\n",
    "        stats = {\n",
    "            \"processing_info\": {\n",
    "                \"start_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"end_time\": None,\n",
    "                \"total_videos\": len(video_df),\n",
    "                \"videos_processed\": 0,\n",
    "                \"directories_deleted\": 0,\n",
    "                \"videos_deleted\": 0,\n",
    "                \"detection_threshold_dom\": detection_threshold_dom,\n",
    "                \"detection_threshold_non_dom\": detection_threshold_non_dom,\n",
    "                \"detection_threshold_dom_small_length\": detection_threshold_dom_small_length,\n",
    "                \"detection_threshold_non_dom_small_length\": detection_threshold_non_dom_small_length,\n",
    "                \"last_processed_row\": -1,\n",
    "            },\n",
    "            \"deleted_directories_summary\": {\n",
    "                \"count\": 0\n",
    "            }\n",
    "        }\n",
    "\n",
    "    if start_from_row > 0:\n",
    "        last_processed_row = stats[\"processing_info\"].get(\"last_processed_row\", -1)\n",
    "        if last_processed_row >= 0 and start_from_row <= last_processed_row:\n",
    "            print(f\"Resuming from row {start_from_row} (last processed row was {last_processed_row})\")\n",
    "        elif last_processed_row >= 0 and start_from_row > last_processed_row + 1:\n",
    "            print(f\"Warning: Skipping rows {last_processed_row+1} to {start_from_row-1}\") \n",
    "    \n",
    "    # Calculate the number of videos to process\n",
    "    total_videos = len(video_df)\n",
    "    remaining_videos = total_videos - start_from_row\n",
    "    \n",
    "    print(f\"Starting batch processing from row {start_from_row} ({remaining_videos} videos remaining)\")\n",
    "    print(f\"Detection thresholds (normal): Dom={detection_threshold_dom}%, Non-Dom={detection_threshold_non_dom}%\")\n",
    "    print(f\"Detection thresholds (short videos): Dom={detection_threshold_dom_small_length}%, Non-Dom={detection_threshold_non_dom_small_length}%\")\n",
    "    print(f\"Using memory-efficient processing - detailed results stored in: {details_dir}\")\n",
    "    \n",
    "    # Helper function to save the current report using atomic operations\n",
    "    def save_current_report():\n",
    "        stats[\"processing_info\"][\"last_updated\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        # Write to temporary file first to avoid corruption\n",
    "        with open(temp_report_path, \"w\") as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        \n",
    "        # Atomic rename to ensure file integrity\n",
    "        if os.path.exists(temp_report_path):\n",
    "            os.rename(temp_report_path, current_report_path)\n",
    "    \n",
    "    # Save initial report\n",
    "    save_current_report()\n",
    "    \n",
    "    # Process each video starting from the specified row\n",
    "    for idx in range(start_from_row, total_videos):\n",
    "        row = video_df.iloc[idx]\n",
    "        video_path = row['file_path']\n",
    "        video_fps = row['FPS']\n",
    "        video_framecount = row['Frame Count']\n",
    "        video_length = video_framecount / video_fps\n",
    "        \n",
    "\n",
    "        # Skip if file doesn't exist\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Video not found: {video_path}\")\n",
    "            \n",
    "            # Create video detail file for skipped video\n",
    "            video_detail = {\n",
    "                \"video_path\": video_path,\n",
    "                \"status\": \"skipped\",\n",
    "                \"reason\": \"file_not_found\",\n",
    "                \"processed_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"row_index\": idx\n",
    "            }\n",
    "            \n",
    "            # Save detail to separate file\n",
    "            path_hash = hashlib.md5(video_path.encode()).hexdigest()[:8]\n",
    "            detail_filename = f\"video_detail_{idx}_{path_hash}.json\"\n",
    "            with open(os.path.join(details_dir, detail_filename), 'w') as f:\n",
    "                json.dump(video_detail, f, indent=2)\n",
    "                \n",
    "            # Mark as processed\n",
    "            stats[\"processing_info\"][\"last_processed_row\"] = idx\n",
    "            \n",
    "            # Save summary report\n",
    "            save_current_report()\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing video {idx-start_from_row+1}/{remaining_videos} (overall: {idx+1}/{total_videos}): {video_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Determine output directory path (before actually processing)\n",
    "            video_dir = os.path.dirname(video_path)\n",
    "            video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "            output_dir = os.path.join(video_dir, f\"{video_name}_landmarks\")\n",
    "            \n",
    "            # Process the video\n",
    "            process_start_time = datetime.now()\n",
    "            process_video_func(video_path, start_time_seconds=start_time_seconds, end_time_seconds=end_time_seconds)\n",
    "            process_end_time = datetime.now()\n",
    "            process_duration = (process_end_time - process_start_time).total_seconds()\n",
    "            \n",
    "            stats[\"processing_info\"][\"videos_processed\"] += 1\n",
    "            \n",
    "            # Check detection statistics\n",
    "            stats_file = os.path.join(output_dir, \"detection_statistics.json\")\n",
    "            \n",
    "            if not os.path.exists(stats_file):\n",
    "                print(f\"Warning: Statistics file not found for {video_path}\")\n",
    "                \n",
    "                # Create video detail file for error\n",
    "                video_detail = {\n",
    "                    \"video_path\": video_path,\n",
    "                    \"status\": \"error\",\n",
    "                    \"reason\": \"statistics_file_not_found\",\n",
    "                    \"processed_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"processing_time_seconds\": process_duration,\n",
    "                    \"row_index\": idx\n",
    "                }\n",
    "                \n",
    "                # Save detail to separate file\n",
    "                path_hash = hashlib.md5(video_path.encode()).hexdigest()[:8]\n",
    "                detail_filename = f\"video_detail_{idx}_{path_hash}.json\"\n",
    "                with open(os.path.join(details_dir, detail_filename), 'w') as f:\n",
    "                    json.dump(video_detail, f, indent=2)\n",
    "                    \n",
    "                \n",
    "                stats[\"processing_info\"][\"last_processed_row\"] = idx\n",
    "                \n",
    "                # Save summary report\n",
    "                save_current_report()\n",
    "                continue\n",
    "                \n",
    "            # Read detection statistics\n",
    "            with open(stats_file, \"r\") as f:\n",
    "                detection_stats = json.load(f)\n",
    "            \n",
    "            # Check detection rates\n",
    "            dom_hand_rate = detection_stats[\"detection_rates\"][\"dominant_hand\"][\"detection_rate\"]\n",
    "            non_dom_hand_rate = detection_stats[\"detection_rates\"][\"non_dominant_hand\"][\"detection_rate\"]\n",
    "            face_rate = detection_stats[\"detection_rates\"][\"face\"][\"detection_rate\"]\n",
    "            \n",
    "            # Create video details\n",
    "            video_detail = {\n",
    "                \"video_path\": video_path,\n",
    "                \"output_dir\": output_dir,\n",
    "                \"dominant_hand_rate\": dom_hand_rate,\n",
    "                \"non_dominant_hand_rate\": non_dom_hand_rate,\n",
    "                \"face_rate\": face_rate,\n",
    "                \"processed_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"processing_time_seconds\": process_duration,\n",
    "                \"row_index\": idx,\n",
    "                \"video_length_seconds\": video_length\n",
    "            }\n",
    "            \n",
    "            # Apply appropriate thresholds based on video length\n",
    "            current_detection_threshold_dom = detection_threshold_dom\n",
    "            current_detection_threshold_non_dom = detection_threshold_non_dom\n",
    "            \n",
    "            if video_length < 10: \n",
    "                current_detection_threshold_dom = detection_threshold_dom_small_length\n",
    "                current_detection_threshold_non_dom = detection_threshold_non_dom_small_length\n",
    "                video_detail[\"thresholds_used\"] = \"short_video\"\n",
    "            else:\n",
    "                video_detail[\"thresholds_used\"] = \"normal\"\n",
    "                \n",
    "            # Check if detection rates are below threshold\n",
    "            if dom_hand_rate < current_detection_threshold_dom or non_dom_hand_rate < current_detection_threshold_non_dom:\n",
    "                print(f\"Low detection rate for {video_name}: Dom={dom_hand_rate:.1f}%, Non-Dom={non_dom_hand_rate:.1f}%\")\n",
    "                print(f\"Deleting directory: {output_dir}\")\n",
    "                \n",
    "                # Delete the directory\n",
    "                shutil.rmtree(output_dir)\n",
    "                \n",
    "                # Update statistics\n",
    "                stats[\"processing_info\"][\"directories_deleted\"] += 1\n",
    "                stats[\"deleted_directories_summary\"][\"count\"] += 1\n",
    "                \n",
    "                video_detail[\"status\"] = \"deleted\"\n",
    "                video_detail[\"reason\"] = \"low_detection_rate\"\n",
    "            else:\n",
    "                print(f\"Detection rates acceptable: Dom={dom_hand_rate:.1f}%, Non-Dom={non_dom_hand_rate:.1f}%\")\n",
    "                video_detail[\"status\"] = \"kept\"\n",
    "            \n",
    "            # Save detail to separate file\n",
    "            path_hash = hashlib.md5(video_path.encode()).hexdigest()[:8]\n",
    "            detail_filename = f\"video_detail_{idx}_{path_hash}.json\"\n",
    "            with open(os.path.join(details_dir, detail_filename), 'w') as f:\n",
    "                json.dump(video_detail, f, indent=2)\n",
    "            \n",
    "            stats[\"processing_info\"][\"last_processed_row\"] = idx\n",
    "            \n",
    "            # Delete original video if requested\n",
    "            if delete_videos:\n",
    "                os.remove(video_path)\n",
    "                stats[\"processing_info\"][\"videos_deleted\"] += 1\n",
    "                print(f\"Deleted original video: {video_path}\")\n",
    "            \n",
    "            # Save report after each video\n",
    "            save_current_report()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {video_path}: {str(e)}\")\n",
    "            \n",
    "            # Create video detail file for error\n",
    "            video_detail = {\n",
    "                \"video_path\": video_path,\n",
    "                \"status\": \"error\",\n",
    "                \"reason\": str(e),\n",
    "                \"processed_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"row_index\": idx\n",
    "            }\n",
    "            \n",
    "            # Save detail to separate file\n",
    "            path_hash = hashlib.md5(video_path.encode()).hexdigest()[:8]\n",
    "            detail_filename = f\"video_detail_{idx}_{path_hash}.json\"\n",
    "            with open(os.path.join(details_dir, detail_filename), 'w') as f:\n",
    "                json.dump(video_detail, f, indent=2)\n",
    "                \n",
    "            \n",
    "            stats[\"processing_info\"][\"last_processed_row\"] = idx\n",
    "            \n",
    "            # Save report even when errors occur\n",
    "            save_current_report()\n",
    "    \n",
    "    # Complete statistics\n",
    "    stats[\"processing_info\"][\"end_time\"] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    \n",
    "    # Save final current report\n",
    "    save_current_report()\n",
    "    \n",
    "    # Also save a timestamped archive copy\n",
    "    archive_report_path = os.path.join(report_dir, f\"video_processing_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "    shutil.copy(current_report_path, archive_report_path)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n===== PROCESSING SUMMARY =====\")\n",
    "    print(f\"Total videos: {stats['processing_info']['total_videos']}\")\n",
    "    print(f\"Videos processed (this run + previous): {stats['processing_info']['videos_processed']}\")\n",
    "    print(f\"Directories deleted (low detection rate): {stats['processing_info']['directories_deleted']}\")\n",
    "    if delete_videos:\n",
    "        print(f\"Original videos deleted: {stats['processing_info']['videos_deleted']}\")\n",
    "    print(f\"Current report saved to: {current_report_path}\")\n",
    "    print(f\"Archive report saved to: {archive_report_path}\")\n",
    "    print(f\"Detailed results stored in: {details_dir}\")\n",
    "    \n",
    "    return archive_report_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_videos_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m videos_df \u001b[38;5;241m=\u001b[39m \u001b[43mmake_videos_df\u001b[49m(directory_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_videos_df' is not defined"
     ]
    }
   ],
   "source": [
    "videos_df = make_videos_df(directory_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Frame Count</th>\n",
       "      <th>FPS</th>\n",
       "      <th>dom_hand</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_...</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youtube_DNViaspA8hM_1920x1080_h264_fps10</td>\n",
       "      <td>652</td>\n",
       "      <td>10.0</td>\n",
       "      <td>None</td>\n",
       "      <td>./youtube_DNViaspA8hM_1920x1080_h264_fps10.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Video Name  Frame Count   FPS  \\\n",
       "0  youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_...           65   1.0   \n",
       "1           youtube_DNViaspA8hM_1920x1080_h264_fps10          652  10.0   \n",
       "\n",
       "  dom_hand                                          file_path  \n",
       "0     None  ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps...  \n",
       "1     None     ./youtube_DNViaspA8hM_1920x1080_h264_fps10.mp4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing from row 0 (2 videos remaining)\n",
      "Detection thresholds (normal): Dom=70%, Non-Dom=50%\n",
      "Detection thresholds (short videos): Dom=5%, Non-Dom=-1%\n",
      "Using memory-efficient processing - detailed results stored in: ./report/video_details\n",
      "\n",
      "Processing video 1/2 (overall: 1/2): ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right.mp4\n",
      "\n",
      "Starting processing of video: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right.mp4\n",
      "\n",
      "Starting processing of video: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right.mp4\n",
      "Warning: Could not determine dominant hand from filename, using default: Right\n",
      "[youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right.mp4] Dominant hand: Right\n",
      "[youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right.mp4] Using 2 worker threads\n",
      "Dominant hand (Right) detected: True\n",
      "Non-dominant hand detected: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744203464.267891   16019 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1744203464.270511   17437 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 Mesa 24.3~git2407250600.76ae27~oibaf~j (git-76ae27e 2024-07-25 jammy-oibaf-ppa)), renderer: AMD Radeon Graphics (radeonsi, renoir, LLVM 15.0.7, DRM 3.42, 5.15.0-131-generic)\n",
      "W0000 00:00:1744203464.271041   16019 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n",
      "W0000 00:00:1744203464.276611   17438 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744203464.300564   17443 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "batch_process_videos(\n",
    "    video_df=videos_df, \n",
    "    process_video_func=batch_call_process_video_with_output,\n",
    "    detection_threshold_dom=70, \n",
    "    detection_threshold_non_dom=50,\n",
    "    detection_threshold_dom_small_length=5,\n",
    "    detection_threshold_non_dom_small_length=-1,\n",
    "    start_from_row=0, report_dir=\"./report\", delete_videos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./report/video_processing_report_current.json\", \"r\") as f:\n",
    "    current_report = json.load(f)\n",
    "    last_row = current_report[\"processing_info\"][\"last_processed_row\"]\n",
    "    next_row = last_row + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing from row 0 (2 videos remaining)\n",
      "Detection thresholds (normal): Dom=70%, Non-Dom=50%\n",
      "Detection thresholds (short videos): Dom=5%, Non-Dom=5%\n",
      "Using memory-efficient processing - detailed results stored in: ./report/video_details\n",
      "\n",
      "Processing video 1/2 (overall: 1/2): ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right.mp4\n",
      "Warning: Could not determine dominant hand from filename, using default: Right\n",
      "Detected dominant hand from filename: Right\n",
      "Video: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right\n",
      "Total frames: 65\n",
      "FPS: 1.0\n",
      "Duration: 65.00 seconds\n",
      "Processing frames 0 to 65 (time 0.00s to 65.00s)\n",
      "Output directory: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Processing frame 64/65 (timestamp: 01m04s000ms)                                 \n",
      "===== PROCESSING SUMMARY =====\n",
      "Processed 65 frames\n",
      "Detection rates: Dom hand: 93.8%, Non-dom hand: 89.2%, Face: 83.1%\n",
      "All parts detected in 0.0% of frames\n",
      "Full statistics saved to: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/detection_statistics.json\n",
      "Results saved to: youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Detection rates acceptable: Dom=93.8%, Non-Dom=89.2%\n",
      "\n",
      "Processing video 2/2 (overall: 2/2): ./youtube_DNViaspA8hM_1920x1080_h264_fps10.mp4\n",
      "Warning: Could not determine dominant hand from filename, using default: Right\n",
      "Detected dominant hand from filename: Right\n",
      "Video: youtube_DNViaspA8hM_1920x1080_h264_fps10\n",
      "Total frames: 652\n",
      "FPS: 10.0\n",
      "Duration: 65.20 seconds\n",
      "Processing frames 0 to 652 (time 0.00s to 65.20s)\n",
      "Output directory: youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks\n",
      "Processing frame 650/652 (timestamp: 01m05s000ms)                               "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./report/video_processing_report_20250404_145311.json'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frame 651/652 (timestamp: 01m05s100ms)                               \n",
      "===== PROCESSING SUMMARY =====\n",
      "Processed 652 frames\n",
      "Detection rates: Dom hand: 94.0%, Non-dom hand: 90.5%, Face: 90.0%\n",
      "All parts detected in 0.0% of frames\n",
      "Full statistics saved to: youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/detection_statistics.json\n",
      "Results saved to: youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks\n",
      "Detection rates acceptable: Dom=94.0%, Non-Dom=90.5%\n",
      "\n",
      "===== PROCESSING SUMMARY =====\n",
      "Total videos: 2\n",
      "Videos processed (this run + previous): 2\n",
      "Directories deleted (low detection rate): 0\n",
      "Current report saved to: ./report/video_processing_report_current.json\n",
      "Archive report saved to: ./report/video_processing_report_20250404_145311.json\n",
      "Detailed results stored in: ./report/video_details\n",
      "Found 2 unique directories to process\n",
      "Using 5 concurrent processes\n",
      "\n",
      "Processing batch 1/1 (2 directories)\n",
      "Starting interpolation for directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Starting interpolation for directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks\n",
      "Processing frames range: 0 to 65\n",
      "Processing non-dominant hand failures...\n",
      "Skipping frame 3 - too close to video boundary\n",
      "Skipping frame 4 - too close to video boundary\n",
      "Processing frames range: 0 to 652\n",
      "Processing non-dominant hand failures...\n",
      "Frame 27: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000027_00m27s000ms.npz\n",
      "Frame 6: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000006_00m00s600ms.npz\n",
      "Frame 7: Interpolated with confidence 0.66\n",
      "Frame 36: Interpolated with confidence 0.94\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000007_00m00s700ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\n",
      "Frame 39: Interpolated with confidence 0.62\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000039_00m39s000ms.npz\n",
      "Frame 40: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000040_00m40s000ms.npz\n",
      "Frame 14: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000014_00m01s400ms.npz\n",
      "Frame 54: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000054_00m54s000ms.npz\n",
      "Interpolated 5 non-dominant hand frames\n",
      "Processing dominant hand failures...\n",
      "Skipping frame 0 - too close to video boundary\n",
      "Frame 13: Interpolated with confidence 0.91\n",
      "Frame 30: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000013_00m13s000ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000030_00m03s000ms.npz\n",
      "Frame 15: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000015_00m15s000ms.npz\n",
      "Frame 28: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000028_00m28s000ms.npz\n",
      "Interpolated 3 dominant hand frames\n",
      "Total interpolated: 8 frames\n",
      "Directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Interpolated frames: 8\n",
      "Progress: 1/2 dirs (50.0%)\n",
      "Rate: 2.21 dirs/sec, Est. remaining: 0.0 minutes\n",
      "Frame 42: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000042_00m04s200ms.npz\n",
      "Frame 106: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000106_00m10s600ms.npz\n",
      "Frame 113: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000113_00m11s300ms.npz\n",
      "Frame 145: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000145_00m14s500ms.npz\n",
      "Frame 151: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000151_00m15s100ms.npz\n",
      "Frame 152: Interpolated with confidence 0.19\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000152_00m15s200ms.npz\n",
      "Frame 153: Interpolated with confidence 0.15\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000153_00m15s300ms.npz\n",
      "Frame 154: Interpolated with confidence 0.19\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000154_00m15s400ms.npz\n",
      "Frame 155: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000155_00m15s500ms.npz\n",
      "Frame 167: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000167_00m16s700ms.npz\n",
      "Frame 168: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000168_00m16s800ms.npz\n",
      "Frame 231: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000231_00m23s100ms.npz\n",
      "Frame 232: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000232_00m23s200ms.npz\n",
      "Frame 262: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000262_00m26s200ms.npz\n",
      "Frame 269: Interpolated with confidence 0.62\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000269_00m26s900ms.npz\n",
      "Frame 270: Interpolated with confidence 0.57\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000270_00m27s000ms.npz\n",
      "Frame 272: Interpolated with confidence 0.88\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000272_00m27s200ms.npz\n",
      "Frame 283: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000283_00m28s300ms.npz\n",
      "Frame 326: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000326_00m32s600ms.npz\n",
      "Frame 327: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000327_00m32s700ms.npz\n",
      "Frame 337: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000337_00m33s700ms.npz\n",
      "Frame 359: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000359_00m35s900ms.npz\n",
      "Frame 360: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000360_00m36s000ms.npz\n",
      "Frame 369: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000369_00m36s900ms.npz\n",
      "Frame 373: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000373_00m37s300ms.npz\n",
      "Frame 389: Interpolated with confidence 0.56\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000389_00m38s900ms.npz\n",
      "Frame 390: Interpolated with confidence 0.28\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000390_00m39s000ms.npz\n",
      "Frame 391: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000391_00m39s100ms.npz\n",
      "Frame 394: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000394_00m39s400ms.npz\n",
      "Frame 395: Interpolated with confidence 0.27\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000395_00m39s500ms.npz\n",
      "Frame 396: Interpolated with confidence 0.52\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000396_00m39s600ms.npz\n",
      "Frame 400: Interpolated with confidence 0.52\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000400_00m40s000ms.npz\n",
      "Frame 401: Interpolated with confidence 0.28\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000401_00m40s100ms.npz\n",
      "Frame 402: Interpolated with confidence 0.52\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000402_00m40s200ms.npz\n",
      "Frame 405: Interpolated with confidence 0.84\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000405_00m40s500ms.npz\n",
      "Frame 407: Interpolated with confidence 0.90\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000407_00m40s700ms.npz\n",
      "Frame 453: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000453_00m45s300ms.npz\n",
      "Frame 455: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000455_00m45s500ms.npz\n",
      "Frame 462: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000462_00m46s200ms.npz\n",
      "Frame 464: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000464_00m46s400ms.npz\n",
      "Frame 511: Interpolated with confidence 0.96\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000511_00m51s100ms.npz\n",
      "Frame 515: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000515_00m51s500ms.npz\n",
      "Frame 516: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000516_00m51s600ms.npz\n",
      "Frame 540: Interpolated with confidence 0.56\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000540_00m54s000ms.npz\n",
      "Frame 541: Interpolated with confidence 0.28\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000541_00m54s100ms.npz\n",
      "Frame 542: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000542_00m54s200ms.npz\n",
      "Frame 545: Interpolated with confidence 0.59\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000545_00m54s500ms.npz\n",
      "Frame 546: Interpolated with confidence 0.61\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000546_00m54s600ms.npz\n",
      "Frame 551: Interpolated with confidence 0.99\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000551_00m55s100ms.npz\n",
      "Frame 603: Interpolated with confidence 0.59\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000603_01m00s300ms.npz\n",
      "Frame 604: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000604_01m00s400ms.npz\n",
      "Frame 606: Interpolated with confidence 0.45\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000606_01m00s600ms.npz\n",
      "Frame 607: Interpolated with confidence 0.24\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000607_01m00s700ms.npz\n",
      "Frame 608: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000608_01m00s800ms.npz\n",
      "Frame 612: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000612_01m01s200ms.npz\n",
      "Frame 613: Interpolated with confidence 0.22\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000613_01m01s300ms.npz\n",
      "Frame 614: Interpolated with confidence 0.23\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000614_01m01s400ms.npz\n",
      "Frame 615: Interpolated with confidence 0.54\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000615_01m01s500ms.npz\n",
      "Interpolated 62 non-dominant hand frames\n",
      "Processing dominant hand failures...\n",
      "Skipping frame 2 - too close to video boundary\n",
      "Frame 11: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000011_00m01s100ms.npz\n",
      "Frame 46: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000046_00m04s600ms.npz\n",
      "Frame 84: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000084_00m08s400ms.npz\n",
      "Frame 128: Interpolated with confidence 0.40\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000128_00m12s800ms.npz\n",
      "Frame 129: Interpolated with confidence 0.13\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000129_00m12s900ms.npz\n",
      "Frame 130: Interpolated with confidence 0.06\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000130_00m13s000ms.npz\n",
      "Frame 131: Interpolated with confidence 0.05\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000131_00m13s100ms.npz\n",
      "Frame 132: Interpolated with confidence 0.05\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000132_00m13s200ms.npz\n",
      "Frame 133: Interpolated with confidence 0.06\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000133_00m13s300ms.npz\n",
      "Frame 134: Interpolated with confidence 0.13\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000134_00m13s400ms.npz\n",
      "Frame 135: Interpolated with confidence 0.40\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000135_00m13s500ms.npz\n",
      "Frame 150: Interpolated with confidence 0.99\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000150_00m15s000ms.npz\n",
      "Frame 155: Interpolated with confidence 0.99\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000155_00m15s500ms.npz\n",
      "Frame 166: Interpolated with confidence 0.99\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000166_00m16s600ms.npz\n",
      "Frame 171: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000171_00m17s100ms.npz\n",
      "Frame 172: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000172_00m17s200ms.npz\n",
      "Frame 194: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000194_00m19s400ms.npz\n",
      "Frame 195: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000195_00m19s500ms.npz\n",
      "Frame 224: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000224_00m22s400ms.npz\n",
      "Frame 228: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000228_00m22s800ms.npz\n",
      "Frame 248: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000248_00m24s800ms.npz\n",
      "Frame 255: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000255_00m25s500ms.npz\n",
      "Frame 256: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000256_00m25s600ms.npz\n",
      "Frame 261: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000261_00m26s100ms.npz\n",
      "Frame 262: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000262_00m26s200ms.npz\n",
      "Frame 335: Interpolated with confidence 0.57\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000335_00m33s500ms.npz\n",
      "Frame 336: Interpolated with confidence 0.32\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000336_00m33s600ms.npz\n",
      "Frame 337: Interpolated with confidence 0.57\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000337_00m33s700ms.npz\n",
      "Frame 343: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000343_00m34s300ms.npz\n",
      "Frame 499: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000499_00m49s900ms.npz\n",
      "Frame 543: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000543_00m54s300ms.npz\n",
      "Frame 547: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000547_00m54s700ms.npz\n",
      "Frame 588: Interpolated with confidence 0.96\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000588_00m58s800ms.npz\n",
      "Frame 592: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000592_00m59s200ms.npz\n",
      "Frame 593: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000593_00m59s300ms.npz\n",
      "Frame 640: Interpolated with confidence 0.57\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000640_01m04s000ms.npz\n",
      "Frame 641: Interpolated with confidence 0.32\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000641_01m04s100ms.npz\n",
      "Frame 642: Interpolated with confidence 0.57\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000642_01m04s200ms.npz\n",
      "Interpolated 38 dominant hand frames\n",
      "Total interpolated: 100 frames\n",
      "Directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks\n",
      "Interpolated frames: 100\n",
      "Progress: 2/2 dirs (100.0%)\n",
      "Rate: 1.45 dirs/sec, Est. remaining: 0.0 minutes\n",
      "\n",
      "Processing completed in 0.0 minutes\n",
      "Total directories processed: 2/2\n",
      "Total frames interpolated: 108\n",
      "Successful directories: 2\n",
      "Failed directories: 0\n",
      "Found 2 unique directories to process\n",
      "Using 5 concurrent processes\n",
      "\n",
      "Processing batch 1/1 (2 directories)\n",
      "Starting interpolation for directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Starting interpolation for directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks\n",
      "Processing frames range: 0 to 65\n",
      "Processing non-dominant hand failures...\n",
      "Skipping frame 3 - too close to video boundary\n",
      "Skipping frame 4 - too close to video boundary\n",
      "Processing frames range: 0 to 652\n",
      "Processing non-dominant hand failures...\n",
      "Frame 27: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000027_00m27s000ms.npz\n",
      "Frame 6: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000006_00m00s600ms.npz\n",
      "Frame 36: Interpolated with confidence 0.94\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000036_00m36s000ms.npz\n",
      "Frame 39: Interpolated with confidence 0.62\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000039_00m39s000ms.npz\n",
      "Frame 7: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000007_00m00s700ms.npz\n",
      "Frame 40: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000040_00m40s000ms.npz\n",
      "Frame 14: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000014_00m01s400ms.npz\n",
      "Frame 54: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000054_00m54s000ms.npz\n",
      "Interpolated 5 non-dominant hand frames\n",
      "Processing dominant hand failures...\n",
      "Frame 30: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000013_00m13s000ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000030_00m03s000ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000015_00m15s000ms.npz\n",
      "Frame 42: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_frame000028_00m28s000ms.npz\n",
      "Interpolated 3 dominant hand frames\n",
      "Total interpolated: 8 frames\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000042_00m04s200ms.npz\n",
      "Directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarks\n",
      "Interpolated frames: 8\n",
      "Progress: 1/2 dirs (50.0%)\n",
      "Rate: 1.73 dirs/sec, Est. remaining: 0.0 minutes\n",
      "Frame 106: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000106_00m10s600ms.npz\n",
      "Frame 113: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000113_00m11s300ms.npz\n",
      "Frame 145: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000145_00m14s500ms.npz\n",
      "Frame 151: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000151_00m15s100ms.npz\n",
      "Frame 152: Interpolated with confidence 0.19\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000152_00m15s200ms.npz\n",
      "Frame 153: Interpolated with confidence 0.15\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000153_00m15s300ms.npz\n",
      "Frame 154: Interpolated with confidence 0.19\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000154_00m15s400ms.npz\n",
      "Frame 155: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000155_00m15s500ms.npz\n",
      "Frame 167: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000167_00m16s700ms.npz\n",
      "Frame 168: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000168_00m16s800ms.npz\n",
      "Frame 231: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000231_00m23s100ms.npz\n",
      "Frame 232: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000232_00m23s200ms.npz\n",
      "Frame 262: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000262_00m26s200ms.npz\n",
      "Frame 269: Interpolated with confidence 0.62\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000269_00m26s900ms.npz\n",
      "Frame 270: Interpolated with confidence 0.57\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000270_00m27s000ms.npz\n",
      "Frame 272: Interpolated with confidence 0.88\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000272_00m27s200ms.npz\n",
      "Frame 283: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000283_00m28s300ms.npz\n",
      "Frame 326: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000326_00m32s600ms.npz\n",
      "Frame 327: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000327_00m32s700ms.npz\n",
      "Frame 337: Interpolated with confidence 1.00\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000337_00m33s700ms.npz\n",
      "Frame 359: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000359_00m35s900ms.npz\n",
      "Frame 360: Interpolated with confidence 0.66\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000360_00m36s000ms.npz\n",
      "Frame 369: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000369_00m36s900ms.npz\n",
      "Frame 373: Interpolated with confidence 0.98\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000373_00m37s300ms.npz\n",
      "Frame 389: Interpolated with confidence 0.56\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000389_00m38s900ms.npz\n",
      "Frame 390: Interpolated with confidence 0.28\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000390_00m39s000ms.npz\n",
      "Frame 391: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000391_00m39s100ms.npz\n",
      "Frame 394: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000394_00m39s400ms.npz\n",
      "Frame 395: Interpolated with confidence 0.27\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000395_00m39s500ms.npz\n",
      "Frame 396: Interpolated with confidence 0.52\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000396_00m39s600ms.npz\n",
      "Frame 400: Interpolated with confidence 0.52\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000400_00m40s000ms.npz\n",
      "Frame 401: Interpolated with confidence 0.28\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000401_00m40s100ms.npz\n",
      "Frame 402: Interpolated with confidence 0.52\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000402_00m40s200ms.npz\n",
      "Frame 405: Interpolated with confidence 0.84\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000405_00m40s500ms.npz\n",
      "Frame 407: Interpolated with confidence 0.90\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000407_00m40s700ms.npz\n",
      "Frame 453: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000453_00m45s300ms.npz\n",
      "Frame 455: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000455_00m45s500ms.npz\n",
      "Frame 462: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000462_00m46s200ms.npz\n",
      "Frame 464: Interpolated with confidence 0.91\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000464_00m46s400ms.npz\n",
      "Frame 511: Interpolated with confidence 0.96\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000511_00m51s100ms.npz\n",
      "Frame 515: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000515_00m51s500ms.npz\n",
      "Frame 516: Interpolated with confidence 0.64\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000516_00m51s600ms.npz\n",
      "Frame 540: Interpolated with confidence 0.56\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000540_00m54s000ms.npz\n",
      "Frame 541: Interpolated with confidence 0.28\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000541_00m54s100ms.npz\n",
      "Frame 542: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000542_00m54s200ms.npz\n",
      "Frame 545: Interpolated with confidence 0.59\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000545_00m54s500ms.npz\n",
      "Frame 546: Interpolated with confidence 0.61\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000546_00m54s600ms.npz\n",
      "Frame 551: Interpolated with confidence 0.99\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000551_00m55s100ms.npz\n",
      "Frame 603: Interpolated with confidence 0.59\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000603_01m00s300ms.npz\n",
      "Frame 604: Interpolated with confidence 0.51\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000604_01m00s400ms.npz\n",
      "Frame 606: Interpolated with confidence 0.45\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000606_01m00s600ms.npz\n",
      "Frame 607: Interpolated with confidence 0.24\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000607_01m00s700ms.npz\n",
      "Frame 608: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000608_01m00s800ms.npz\n",
      "Frame 612: Interpolated with confidence 0.50\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000612_01m01s200ms.npz\n",
      "Frame 613: Interpolated with confidence 0.22\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000613_01m01s300ms.npz\n",
      "Frame 614: Interpolated with confidence 0.23\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000614_01m01s400ms.npz\n",
      "Frame 615: Interpolated with confidence 0.54\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000615_01m01s500ms.npz\n",
      "Interpolated 62 non-dominant hand frames\n",
      "Processing dominant hand failures...\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000011_00m01s100ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000046_00m04s600ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000084_00m08s400ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000128_00m12s800ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000129_00m12s900ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000130_00m13s000ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000131_00m13s100ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000132_00m13s200ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000133_00m13s300ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000134_00m13s400ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000135_00m13s500ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000150_00m15s000ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000155_00m15s500ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000166_00m16s600ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000171_00m17s100ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000172_00m17s200ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000194_00m19s400ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000195_00m19s500ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000224_00m22s400ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000228_00m22s800ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000248_00m24s800ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000255_00m25s500ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000256_00m25s600ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000261_00m26s100ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000262_00m26s200ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000335_00m33s500ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000336_00m33s600ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000337_00m33s700ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000343_00m34s300ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000499_00m49s900ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000543_00m54s300ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000547_00m54s700ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000588_00m58s800ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000592_00m59s200ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000593_00m59s300ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000640_01m04s000ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000641_01m04s100ms.npz\n",
      "Successfully modified/added 3 arrays in ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks/youtube_DNViaspA8hM_1920x1080_h264_fps10_frame000642_01m04s200ms.npz\n",
      "Interpolated 38 dominant hand frames\n",
      "Total interpolated: 100 frames\n",
      "Directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks\n",
      "Interpolated frames: 100\n",
      "Progress: 2/2 dirs (100.0%)\n",
      "Rate: 0.89 dirs/sec, Est. remaining: 0.0 minutes\n",
      "\n",
      "Processing completed in 0.0 minutes\n",
      "Total directories processed: 2/2\n",
      "Total frames interpolated: 108\n",
      "Successful directories: 2\n",
      "Failed directories: 0\n"
     ]
    }
   ],
   "source": [
    "batch_process_videos(\n",
    "    video_df=videos_df, \n",
    "    process_video_func=process_video,\n",
    "    detection_threshold_dom=70, \n",
    "    detection_threshold_non_dom=50,\n",
    "    detection_threshold_dom_small_length=5,\n",
    "    detection_threshold_non_dom_small_length=5,\n",
    "    start_from_row=0, report_dir=\"./report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_single_video(video_info):\n",
    "    \"\"\"Helper function to resample a single video\"\"\"\n",
    "    gc.collect()\n",
    "    video_path, desired_fps = video_info\n",
    "    try:\n",
    "        # Get original video properties\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"path: {video_path}, error opening video, message: {str(e)}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        \n",
    "        current_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / current_fps\n",
    "        output_total_frames = int(duration * desired_fps)\n",
    "        \n",
    "        # Generate output path\n",
    "        video_dir = os.path.dirname(video_path)\n",
    "        video_filename = os.path.basename(video_path)\n",
    "        base_name, ext = os.path.splitext(video_filename)\n",
    "        output_path = os.path.join(video_dir, f\"{base_name}_fps{int(desired_fps)}{ext}\")\n",
    "        \n",
    "        # Create VideoWriter\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, desired_fps, (width, height))\n",
    "        \n",
    "        # Process frames\n",
    "        for i in range(output_total_frames):\n",
    "            original_frame_idx = round(i * current_fps / desired_fps)\n",
    "            if original_frame_idx >= total_frames:\n",
    "                break\n",
    "                \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, original_frame_idx)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            out.write(frame)\n",
    "        \n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "        # Get new video metadata\n",
    "        new_cap = cv2.VideoCapture(output_path)\n",
    "        new_frame_count = int(new_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        new_fps = new_cap.get(cv2.CAP_PROP_FPS)\n",
    "        if round(new_fps) != round(desired_fps):\n",
    "            print(f\"Error lowering fps, desired {desired_fps} but got {new_fps}\")\n",
    "            sys.exit(1)\n",
    "        new_cap.release()\n",
    "        gc.collect()\n",
    "        return {\n",
    "            \"path\": video_path,\n",
    "            \"new_path\": output_path,\n",
    "            \"status\": \"success\",\n",
    "            \"frame_count\": new_frame_count,\n",
    "            \"fps\": new_fps\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"path: {video_path}, status: error, message: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def resample_videos_in_dataframe(df, desired_fps, batch_size, save_checkpoint=False, checkpoint_file='resampling_progress.csv', file_path_col='file_path', \n",
    "                                delete_originals=False, inplace=False):\n",
    "    \"\"\"\n",
    "    Efficiently resamples videos in a dataframe with parallel processing and batching.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): Dataframe containing video paths\n",
    "        desired_fps (float): The desired FPS for the output videos\n",
    "        file_path_col (str): Name of the column containing file paths\n",
    "        delete_originals (bool): Whether to delete original videos after resampling\n",
    "        inplace (bool): Whether to modify the original dataframe or return a copy\n",
    "        max_workers (int): Max number of parallel processes (None = auto-detect)\n",
    "        batch_size (int): Size of batches for processing\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Updated dataframe with new file paths and metadata\n",
    "    \"\"\"\n",
    "    # Use original dataframe or create a copy\n",
    "    result_df = df if inplace else df.copy()\n",
    "    \n",
    "    # Check if metadata columns exist\n",
    "    has_frame_count_col = 'Frame Count' in result_df.columns\n",
    "    has_fps_col = 'FPS' in result_df.columns\n",
    "    \n",
    "    # Get all valid video paths\n",
    "    video_paths = []\n",
    "    for idx, path in enumerate(result_df[file_path_col]):\n",
    "        if isinstance(path, str) and os.path.exists(path):\n",
    "            video_paths.append((path, desired_fps))\n",
    "    \n",
    "    total_videos = len(video_paths)\n",
    "    print(f\"Found {total_videos} valid videos to process\")\n",
    "    \n",
    "    # Process in batches to manage memory\n",
    "    results = []\n",
    "    for i in range(0, len(video_paths), batch_size):\n",
    "        batch = video_paths[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1}/{(total_videos-1)//batch_size + 1} ({len(batch)} videos)\")\n",
    "        \n",
    "        # Process batch in parallel\n",
    "        with ProcessPoolExecutor(max_workers=batch_size) as executor:\n",
    "            futures = [executor.submit(resample_single_video, video_info) for video_info in batch]\n",
    "            \n",
    "            # Collect results with progress bar\n",
    "            for future in tqdm(as_completed(futures), total=len(batch), desc=\"Resampling\"):\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "                \n",
    "                # Update dataframe as results come in\n",
    "                if result[\"status\"] == \"success\":\n",
    "                    # Find the corresponding row\n",
    "                    row_idx = result_df[result_df[file_path_col] == result[\"path\"]].index\n",
    "                    if len(row_idx) > 0:\n",
    "                        idx = row_idx[0]\n",
    "                        # Update file path\n",
    "                        result_df.at[idx, file_path_col] = result[\"new_path\"]\n",
    "                        \n",
    "                        # Update metadata if columns exist\n",
    "                        if has_frame_count_col:\n",
    "                            result_df.at[idx, 'Frame Count'] = result[\"frame_count\"]\n",
    "                        if has_fps_col:\n",
    "                            result_df.at[idx, 'FPS'] = result[\"fps\"]\n",
    "                        \n",
    "                        # Delete original if requested\n",
    "                        if delete_originals:\n",
    "                            try:\n",
    "                                os.remove(result[\"path\"])\n",
    "                            except Exception as e:\n",
    "                                print(f\"Warning: Could not delete {result['path']}: {e}\")\n",
    "        if save_checkpoint:\n",
    "            result_df.to_csv(checkpoint_file, index=False)\n",
    "            print(f\"Saved checkpoint to {checkpoint_file}\")\n",
    "    \n",
    "    # Summarize results\n",
    "    successful = sum(1 for r in results if r[\"status\"] == \"success\")\n",
    "    failed = sum(1 for r in results if r[\"status\"] == \"error\")\n",
    "    \n",
    "    print(f\"\\nResampling complete:\")\n",
    "    print(f\"  - Successfully processed: {successful}/{total_videos} videos\")\n",
    "    print(f\"  - Failed: {failed}/{total_videos} videos\")\n",
    "    \n",
    "    if failed > 0:\n",
    "        print(\"\\nFailed videos:\")\n",
    "        for r in results:\n",
    "            if r[\"status\"] == \"error\":\n",
    "                print(f\"  - {os.path.basename(r['path'])}: {r.get('message', 'Unknown error')}\")\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Frame Count</th>\n",
       "      <th>FPS</th>\n",
       "      <th>dom_hand</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>836681859074-DISAGREEMENT</td>\n",
       "      <td>78</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>./836681859074-DISAGREEMENT.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>824925993024-NEAR</td>\n",
       "      <td>48</td>\n",
       "      <td>29.925187</td>\n",
       "      <td>None</td>\n",
       "      <td>./824925993024-NEAR.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0636580316216-SHUT OUT</td>\n",
       "      <td>62</td>\n",
       "      <td>29.799000</td>\n",
       "      <td>None</td>\n",
       "      <td>./0636580316216-SHUT OUT.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701606421745-PERCEIVE</td>\n",
       "      <td>88</td>\n",
       "      <td>29.921795</td>\n",
       "      <td>None</td>\n",
       "      <td>./701606421745-PERCEIVE.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.7299129501965353e-7-seedSOUR</td>\n",
       "      <td>98</td>\n",
       "      <td>30.406000</td>\n",
       "      <td>None</td>\n",
       "      <td>./4.7299129501965353e-7-seedSOUR.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Video Name  Frame Count        FPS dom_hand  \\\n",
       "0       836681859074-DISAGREEMENT           78  30.000000     None   \n",
       "1               824925993024-NEAR           48  29.925187     None   \n",
       "2          0636580316216-SHUT OUT           62  29.799000     None   \n",
       "3           701606421745-PERCEIVE           88  29.921795     None   \n",
       "4  4.7299129501965353e-7-seedSOUR           98  30.406000     None   \n",
       "\n",
       "                              file_path  \n",
       "0       ./836681859074-DISAGREEMENT.mp4  \n",
       "1               ./824925993024-NEAR.mp4  \n",
       "2          ./0636580316216-SHUT OUT.mp4  \n",
       "3           ./701606421745-PERCEIVE.mp4  \n",
       "4  ./4.7299129501965353e-7-seedSOUR.mp4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 valid videos to process\n",
      "Processing batch 1/1 (5 videos)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resampling: 100%|| 5/5 [00:01<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint to resampling_progress.csv\n",
      "\n",
      "Resampling complete:\n",
      "  - Successfully processed: 5/5 videos\n",
      "  - Failed: 0/5 videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_vid = resample_videos_in_dataframe(df=videos_df, desired_fps=12, save_checkpoint=True, checkpoint_file='resampling_progress.csv', file_path_col='file_path', \n",
    "                                delete_originals=True, inplace=False, \n",
    "                                max_workers=None, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Frame Count</th>\n",
       "      <th>FPS</th>\n",
       "      <th>dom_hand</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>836681859074-DISAGREEMENT</td>\n",
       "      <td>31</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>./836681859074-DISAGREEMENT_fps12.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>824925993024-NEAR</td>\n",
       "      <td>19</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>./824925993024-NEAR_fps12.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0636580316216-SHUT OUT</td>\n",
       "      <td>24</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>./0636580316216-SHUT OUT_fps12.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701606421745-PERCEIVE</td>\n",
       "      <td>35</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>./701606421745-PERCEIVE_fps12.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.7299129501965353e-7-seedSOUR</td>\n",
       "      <td>38</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>./4.7299129501965353e-7-seedSOUR_fps12.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Video Name  Frame Count   FPS dom_hand  \\\n",
       "0       836681859074-DISAGREEMENT           31  12.0     None   \n",
       "1               824925993024-NEAR           19  12.0     None   \n",
       "2          0636580316216-SHUT OUT           24  12.0     None   \n",
       "3           701606421745-PERCEIVE           35  12.0     None   \n",
       "4  4.7299129501965353e-7-seedSOUR           38  12.0     None   \n",
       "\n",
       "                                    file_path  \n",
       "0       ./836681859074-DISAGREEMENT_fps12.mp4  \n",
       "1               ./824925993024-NEAR_fps12.mp4  \n",
       "2          ./0636580316216-SHUT OUT_fps12.mp4  \n",
       "3           ./701606421745-PERCEIVE_fps12.mp4  \n",
       "4  ./4.7299129501965353e-7-seedSOUR_fps12.mp4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_landmarks_dataframe_new(dataframe, interpolate_func, batch_size=4, \n",
    "                               report_dir=None, start_from_row=0):\n",
    "    \"\"\"\n",
    "    Process multiple directories from a dataframe with checkpointing and logging.\n",
    "    \n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): DataFrame with a 'landmarks_file_path' column\n",
    "        max_concurrent_dirs (int): Maximum number of directories to process in parallel\n",
    "        batch_size (int): Size of directory batches to process\n",
    "        report_dir (str): Directory to save checkpoint and report files\n",
    "                         If None, no checkpointing or reporting is done\n",
    "        start_from_row (int): Row index to start processing from (for resuming)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The input dataframe with an additional 'interpolated_frames' column\n",
    "    \"\"\"\n",
    "    # Setup logging and checkpointing\n",
    "    checkpoint_file = None\n",
    "    report_data = {\n",
    "        \"start_time\": datetime.now().isoformat(),\n",
    "        \"end_time\": None,\n",
    "        \"duration_seconds\": 0,\n",
    "        \"total_directories\": 0,\n",
    "        \"processed_directories\": 0,\n",
    "        \"successful_interpolations\": 0,\n",
    "        \"failed_interpolations\": 0,\n",
    "        \"last_processed_row\": start_from_row - 1,\n",
    "        \"status\": \"in_progress\"\n",
    "    }\n",
    "    \n",
    "    if report_dir:\n",
    "        os.makedirs(report_dir, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        checkpoint_file = os.path.join(report_dir, f\"landmarks_processing_{timestamp}.json\")\n",
    "        \n",
    "        # Check if we're resuming from a crash\n",
    "        if start_from_row > 0:\n",
    "            print(f\"Resuming from row {start_from_row}\")\n",
    "            report_data[\"notes\"] = f\"Resumed from row {start_from_row}\"\n",
    "        \n",
    "        # Initial write\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(report_data, f, indent=2)\n",
    "    \n",
    "    # Add directory column and reset index to ensure row tracking works correctly\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "    dataframe['directory'] = dataframe['landmarks_file_path'].apply(os.path.dirname)\n",
    "    \n",
    "    # If resuming, apply a filter based on start_from_row\n",
    "    if start_from_row > 0:\n",
    "        working_df = dataframe.iloc[start_from_row:].copy()\n",
    "    else:\n",
    "        working_df = dataframe.copy()\n",
    "    \n",
    "    directory_groups = working_df.groupby('directory')\n",
    "    unique_directories = list(directory_groups.groups.keys())\n",
    "    total_dirs = len(unique_directories)\n",
    "    \n",
    "    report_data[\"total_directories\"] = total_dirs\n",
    "    print(f\"Found {total_dirs} unique directories to process\")\n",
    "    \n",
    "    # Limit concurrent directories based on system resources\n",
    "    max_concurrent_dirs = batch_size\n",
    "    print(f\"Using {max_concurrent_dirs} concurrent processes\")\n",
    "    \n",
    "    # Store results and track progress\n",
    "    overall_start_time = time.time()\n",
    "    processed_dirs = 0\n",
    "    successful_interpolations = 0\n",
    "    failed_interpolations = 0\n",
    "    last_processed_row = start_from_row - 1\n",
    "    \n",
    "    # Update checkpoint function\n",
    "    def update_checkpoint():\n",
    "        if checkpoint_file:\n",
    "            current_time = datetime.now()\n",
    "            elapsed = time.time() - overall_start_time\n",
    "            \n",
    "            report_data[\"processed_directories\"] = processed_dirs\n",
    "            report_data[\"successful_interpolations\"] = successful_interpolations\n",
    "            report_data[\"failed_interpolations\"] = failed_interpolations\n",
    "            report_data[\"last_processed_row\"] = last_processed_row\n",
    "            report_data[\"duration_seconds\"] = elapsed\n",
    "            report_data[\"last_updated\"] = current_time.isoformat()\n",
    "            \n",
    "            # Write to a temp file first then rename to avoid corruption if crashed during write\n",
    "            temp_file = checkpoint_file + \".tmp\"\n",
    "            with open(temp_file, 'w') as f:\n",
    "                json.dump(report_data, f, indent=2)\n",
    "            \n",
    "            # Atomic rename operation\n",
    "            if os.path.exists(temp_file):\n",
    "                os.replace(temp_file, checkpoint_file)\n",
    "                \n",
    "    \n",
    "    total_interpolated=0\n",
    "    # Process directories in batches\n",
    "    try:\n",
    "        for batch_idx in range(0, len(unique_directories), batch_size):\n",
    "            batch_directories = unique_directories[batch_idx:batch_idx + batch_size]\n",
    "            print(f\"\\nProcessing batch {batch_idx//batch_size + 1}/{(len(unique_directories) + batch_size - 1)//batch_size} \"\n",
    "                  f\"({len(batch_directories)} directories)\")\n",
    "            \n",
    "            mem_available = psutil.virtual_memory().available / (1024**3)  # GB\n",
    "            if mem_available < 2:  # Less than 2GB available\n",
    "                print(f\"Warning: Only {mem_available:.1f}GB memory available. Waiting 1 second...\")\n",
    "                time.sleep(1)  # Wait for other processes to finish\n",
    "                gc.collect()\n",
    "            \n",
    "            # Process this batch of directories in parallel\n",
    "            with ProcessPoolExecutor(max_workers=max_concurrent_dirs) as executor:\n",
    "                # Submit all directories in this batch\n",
    "                future_to_dir = {\n",
    "                    executor.submit(interpolate_func, dir_path): dir_path \n",
    "                    for dir_path in batch_directories\n",
    "                }\n",
    "                \n",
    "                # Process results as they complete\n",
    "                for future in as_completed(future_to_dir):\n",
    "                    dir_path = future_to_dir[future]\n",
    "                    try:\n",
    "                        # Get interpolation results\n",
    "                        interpolated_frames = future.result()\n",
    "                        dir_indices = dataframe[dataframe['directory'] == dir_path].index\n",
    "                        dataframe.loc[dir_indices, 'interpolated_frames'] = interpolated_frames\n",
    "                        processed_dirs += 1\n",
    "                        total_interpolated += interpolated_frames\n",
    "                        \n",
    "                        # Track successful interpolations\n",
    "                        if interpolated_frames > 0:\n",
    "                            successful_interpolations += 1\n",
    "                        \n",
    "                        # Find the maximum row index for this directory\n",
    "                        dir_rows = working_df[working_df['directory'] == dir_path].index\n",
    "                        if len(dir_rows) > 0:\n",
    "                            last_processed_row = max(last_processed_row, max(dir_rows) + start_from_row)\n",
    "                        \n",
    "\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing directory {dir_path}: {str(e)}\")\n",
    "                        failed_interpolations += 1\n",
    "                        sys.exit(1)\n",
    "            \n",
    "            # Update checkpoint after each batch\n",
    "            update_checkpoint()\n",
    "            \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {str(e)}\")\n",
    "        if checkpoint_file:\n",
    "            report_data[\"status\"] = \"crashed\"\n",
    "            report_data[\"error\"] = str(e)\n",
    "            update_checkpoint()\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    total_elapsed = time.time() - overall_start_time\n",
    "\n",
    "    \n",
    "    print(f\"\\nProcessing completed in {total_elapsed/60:.1f} minutes\")\n",
    "    print(f\"Total directories processed: {processed_dirs}/{total_dirs}\")\n",
    "    print(f\"Total frames interpolated: {total_interpolated}\")\n",
    "    print(f\"Successful directories: {successful_interpolations}\")\n",
    "    print(f\"Failed directories: {failed_interpolations}\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    # Final checkpoint update\n",
    "    if checkpoint_file:\n",
    "        report_data[\"status\"] = \"completed\"\n",
    "        report_data[\"end_time\"] = datetime.now().isoformat()\n",
    "        report_data[\"duration_seconds\"] = total_elapsed\n",
    "        report_data[\"processed_directories\"] = processed_dirs\n",
    "        report_data[\"successful_interpolations\"] = successful_interpolations\n",
    "        report_data[\"failed_interpolations\"] = failed_interpolations\n",
    "        report_data[\"total_interpolated_frames\"] = total_interpolated\n",
    "        update_checkpoint()\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def find_latest_checkpoint(report_dir):\n",
    "    \"\"\"\n",
    "    Find the latest checkpoint file in the report directory.\n",
    "    \n",
    "    Args:\n",
    "        report_dir (str): Directory containing checkpoint files\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (latest_file_path, checkpoint_data) or (None, None) if not found\n",
    "    \"\"\"\n",
    "    if not os.path.exists(report_dir):\n",
    "        return None, None\n",
    "    \n",
    "    checkpoint_files = [f for f in os.listdir(report_dir) \n",
    "                        if f.startswith(\"landmarks_processing_\") and f.endswith(\".json\")]\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        return None, None\n",
    "    \n",
    "    # Sort by modification time (most recent first)\n",
    "    latest_file = max(checkpoint_files, key=lambda f: os.path.getmtime(os.path.join(report_dir, f)))\n",
    "    latest_path = os.path.join(report_dir, latest_file)\n",
    "    \n",
    "    try:\n",
    "        with open(latest_path, 'r') as f:\n",
    "            checkpoint_data = json.load(f)\n",
    "        return checkpoint_data[\"last_processed_row\"], checkpoint_data\n",
    "    except:\n",
    "        print(\"Error loading\")\n",
    "        return \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_landmark_directories(root_path):\n",
    "    \"\"\"\n",
    "    Finds all directories with names ending in '_landmarks' under the given root path.\n",
    "    \n",
    "    Parameters:\n",
    "    root_path (str): The path to the root directory to search in\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with one column 'landmarks_file_path' containing paths to landmark directories\n",
    "    \"\"\"\n",
    "    landmark_paths = []\n",
    "    \n",
    "    # Walk through the directory structure\n",
    "    for dirpath, dirnames, filenames in os.walk(root_path):\n",
    "        # Check each directory name\n",
    "        for dirname in dirnames:\n",
    "            if dirname.endswith(\"_landmarks\"):\n",
    "                # Add the full path to our list\n",
    "                dirname = dirname + f\"/\"\n",
    "                full_path = os.path.join(dirpath, dirname)\n",
    "                landmark_paths.append(full_path)\n",
    "    \n",
    "    # Create a DataFrame from the list of paths\n",
    "    df = pd.DataFrame({'landmarks_file_path': landmark_paths})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_dir_paths_df = find_landmark_directories(root_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 unique directories to process\n",
      "Using 4 concurrent processes\n",
      "\n",
      "Processing batch 1/1 (2 directories)\n",
      "Warning: Only 1.1GB memory available. Waiting 5 seconds...\n",
      "Starting interpolation for directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps1_Right_landmarksStarting interpolation for directory: ./youtube_DNViaspA8hM_1920x1080_h264_fps10_landmarks\n",
      "\n",
      "Total interpolated: 8 frames\n",
      "Total interpolated: 100 frames\n",
      "\n",
      "Processing completed in 0.0 minutes\n",
      "Total directories processed: 2/2\n",
      "Total frames interpolated: 108\n",
      "Successful directories: 2\n",
      "Failed directories: 0\n"
     ]
    }
   ],
   "source": [
    "df_after_interpolation = process_landmarks_dataframe_new(dataframe=landmark_dir_paths_df, interpolate_func=interpolate_undetected_hand_landmarks_new_wrapper, batch_size=4, report_dir='./report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, data = find_latest_checkpoint(report_dir=\"./report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_time': '2025-04-07T18:01:18.319429',\n",
       " 'end_time': '2025-04-07T18:01:20.602669',\n",
       " 'duration_seconds': 2.279578685760498,\n",
       " 'total_directories': 2,\n",
       " 'processed_directories': 2,\n",
       " 'successful_interpolations': 2,\n",
       " 'failed_interpolations': 0,\n",
       " 'last_processed_row': 1,\n",
       " 'status': 'completed',\n",
       " 'last_updated': '2025-04-07T18:01:20.602676',\n",
       " 'total_interpolated_frames': 108}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>landmarks_file_path</th>\n",
       "      <th>directory</th>\n",
       "      <th>interpolated_frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./youtube_DNViaspA8hM_1920x1080_h264_fps10_lan...</td>\n",
       "      <td>./youtube_DNViaspA8hM_1920x1080_h264_fps10_lan...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps...</td>\n",
       "      <td>./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 landmarks_file_path  \\\n",
       "0  ./youtube_DNViaspA8hM_1920x1080_h264_fps10_lan...   \n",
       "1  ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps...   \n",
       "\n",
       "                                           directory  interpolated_frames  \n",
       "0  ./youtube_DNViaspA8hM_1920x1080_h264_fps10_lan...                  0.0  \n",
       "1  ./youtube_DNViaspA8hM_1920x1080_h264_fps10_fps...                  0.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after_interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_detection_directories(df, dom_threshold, non_dom_threshold, column_name='landmarks_file_path', base_dir=None):\n",
    "    \"\"\"\n",
    "    Removes directories where hand detection rates fall below a threshold.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing directory paths\n",
    "        threshold (float): Minimum acceptable detection rate (0.0 to 1.0)\n",
    "        column_name (str): Name of the column containing directory paths\n",
    "        base_dir (str, optional): Base directory to resolve relative paths. If None, paths are used as-is.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Updated DataFrame with rows removed for deleted directories\n",
    "        list: List of removed directory paths\n",
    "    \"\"\"\n",
    "    # Create a copy of the DataFrame to avoid modifying the original during iteration\n",
    "    updated_df = df.copy()\n",
    "    removed_dirs = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        rel_directory_path = row[column_name]\n",
    "        \n",
    "        # Resolve the full path if base_dir is provided\n",
    "        if base_dir:\n",
    "            directory_path = os.path.join(base_dir, rel_directory_path)\n",
    "        else:\n",
    "            directory_path = rel_directory_path\n",
    "            \n",
    "        \n",
    "        directory_path = os.path.normpath(directory_path)\n",
    "        \n",
    "        # Make sure the path exists\n",
    "        if not os.path.exists(directory_path):\n",
    "            print(f\"Warning: Directory not found: {directory_path}\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "        # Construct path to the json file\n",
    "        json_path = os.path.join(directory_path, 'detection_statistics.json')\n",
    "        \n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"Warning: JSON file not found in directory: {json_path}\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "        # Load the JSON file\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                stats = json.load(f)\n",
    "                \n",
    "            # Extract detection rates\n",
    "            dominant_rate = stats['detection_rates']['dominant_hand']['detection_rate']\n",
    "            non_dominant_rate = stats['detection_rates']['non_dominant_hand']['detection_rate']\n",
    "            total_frames = stats['video_info']['total_frames']\n",
    "            processed_frames = stats['video_info']['processed_frames']\n",
    "            \n",
    "            # Check if either rate is below threshold\n",
    "            if (dominant_rate < dom_threshold) or (non_dominant_rate < non_dom_threshold) or (total_frames != processed_frames):\n",
    "                print(f\"Removing directory due to low detection rates: {directory_path}\")\n",
    "                print(f\"  Dominant hand: {dominant_rate}, Non-dominant hand: {non_dominant_rate}\")\n",
    "                \n",
    "                # Remove the directory\n",
    "                shutil.rmtree(directory_path)\n",
    "                \n",
    "                # Track removed directories\n",
    "                removed_dirs.append(rel_directory_path)\n",
    "                \n",
    "                # Mark this row for removal from the DataFrame\n",
    "                updated_df = updated_df.drop(index)\n",
    "                \n",
    "        except (json.JSONDecodeError, KeyError) as e:\n",
    "            print(f\"Error processing {json_path}: {str(e)}\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "    print(f\"Removed {len(removed_dirs)} directories\")\n",
    "    \n",
    "    # Return both the updated DataFrame and the list of removed directories\n",
    "    return updated_df, removed_dirs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
